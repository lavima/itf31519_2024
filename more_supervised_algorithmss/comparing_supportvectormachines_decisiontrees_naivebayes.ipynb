{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing Support Vector Machines, Decision Trees and Naive Bayes for Heart Failure Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notebook for Workshop: Compare Support Vector Machines, DTs and NB\n",
    "# https://hiof.instructure.com/courses/8923/assignments/41776?module_item_id=283971\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix, classification_report\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, RocCurveDisplay\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_columns\", None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I've added some markdown cells that provide some tips into how to discuss results. Note that my comments were made to a\n",
    "particular run. Due the limitations with setup related to random sampling, we get different results each time we run. The discussions might therefore be slightly errornous when discussion concrete numbers, but they still provide valuable tips for how to discuss results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>anaemia</th>\n",
       "      <th>creatinine_phosphokinase</th>\n",
       "      <th>diabetes</th>\n",
       "      <th>ejection_fraction</th>\n",
       "      <th>high_blood_pressure</th>\n",
       "      <th>platelets</th>\n",
       "      <th>serum_creatinine</th>\n",
       "      <th>serum_sodium</th>\n",
       "      <th>sex</th>\n",
       "      <th>smoking</th>\n",
       "      <th>time</th>\n",
       "      <th>DEATH_EVENT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>75.0</td>\n",
       "      <td>0</td>\n",
       "      <td>582</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>265000.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>130</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>55.0</td>\n",
       "      <td>0</td>\n",
       "      <td>7861</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>263358.03</td>\n",
       "      <td>1.1</td>\n",
       "      <td>136</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>65.0</td>\n",
       "      <td>0</td>\n",
       "      <td>146</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>162000.00</td>\n",
       "      <td>1.3</td>\n",
       "      <td>129</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50.0</td>\n",
       "      <td>1</td>\n",
       "      <td>111</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>210000.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>137</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>65.0</td>\n",
       "      <td>1</td>\n",
       "      <td>160</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>327000.00</td>\n",
       "      <td>2.7</td>\n",
       "      <td>116</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    age  anaemia  creatinine_phosphokinase  diabetes  ejection_fraction  \\\n",
       "0  75.0        0                       582         0                 20   \n",
       "1  55.0        0                      7861         0                 38   \n",
       "2  65.0        0                       146         0                 20   \n",
       "3  50.0        1                       111         0                 20   \n",
       "4  65.0        1                       160         1                 20   \n",
       "\n",
       "   high_blood_pressure  platelets  serum_creatinine  serum_sodium  sex  \\\n",
       "0                    1  265000.00               1.9           130    1   \n",
       "1                    0  263358.03               1.1           136    1   \n",
       "2                    0  162000.00               1.3           129    1   \n",
       "3                    0  210000.00               1.9           137    1   \n",
       "4                    0  327000.00               2.7           116    0   \n",
       "\n",
       "   smoking  time  DEATH_EVENT  \n",
       "0        0     4            1  \n",
       "1        0     6            1  \n",
       "2        1     7            1  \n",
       "3        0     7            1  \n",
       "4        0     8            1  "
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dataset and show first 5 rows\n",
    "\n",
    "dataset = pd.read_csv('../data/heart_failure/heart_failure_clinical_records_dataset.csv')\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Analysis and Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[<Axes: title={'center': 'age'}>,\n",
       "        <Axes: title={'center': 'anaemia'}>,\n",
       "        <Axes: title={'center': 'creatinine_phosphokinase'}>,\n",
       "        <Axes: title={'center': 'diabetes'}>],\n",
       "       [<Axes: title={'center': 'ejection_fraction'}>,\n",
       "        <Axes: title={'center': 'high_blood_pressure'}>,\n",
       "        <Axes: title={'center': 'platelets'}>,\n",
       "        <Axes: title={'center': 'serum_creatinine'}>],\n",
       "       [<Axes: title={'center': 'serum_sodium'}>,\n",
       "        <Axes: title={'center': 'sex'}>,\n",
       "        <Axes: title={'center': 'smoking'}>,\n",
       "        <Axes: title={'center': 'time'}>],\n",
       "       [<Axes: title={'center': 'DEATH_EVENT'}>, <Axes: >, <Axes: >,\n",
       "        <Axes: >]], dtype=object)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 16 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Show the distribution of all the columns (both features and targets). We do this \n",
    "# to explore our data so that we better know how to proceed with the training. \n",
    "# This should be improved.\n",
    "\n",
    "dataset.hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We did this analysis to determine which version of naive bayes to use. We can see that some of the features are what we can consider normally distributed and some are binary. The normally distributed features aren't necessarily bell shaped like we would expect for normally distributed data, but they are closer to normally distributed than the alternative (binary/frequency).\n",
    "\n",
    "The fact that we have two different types of distributions in our features means that we might have to create a custom classifier that combines a gaussian and bernoulli classifier to achieve optimal performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training & Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into 60/20/20. 60% for training, 20% validation, and 20% for final testing\n",
    "\n",
    "trainval = dataset.groupby('DEATH_EVENT', group_keys=False)[dataset.columns].apply(lambda x: x.sample(frac=0.8))\n",
    "test = dataset.drop(trainval.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate input features from targets in all partitions\n",
    "\n",
    "trainval_features = trainval.drop('DEATH_EVENT', axis=1)\n",
    "trainval_targets = trainval['DEATH_EVENT']\n",
    "\n",
    "test_features = test.drop('DEATH_EVENT', axis=1)\n",
    "test_targets = test.DEATH_EVENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A custom function for evaluation the performance using accuracy, precision, recall, f1 and roc_auc\n",
    "# The final_eval parameter makes the evaluation include test data\n",
    "def evaluate(model, final_eval=False):\n",
    "\n",
    "    # Store the prediction probabilites and the predictions. We need the probabilities for \n",
    "    # roc_auc_score metric\n",
    "\n",
    "    train_probabilities = model.predict_proba(trainval_features)\n",
    "    # train_predictions = model.predict(train_features)\n",
    "    # This does the same as the statement above without having the model predict again\n",
    "    train_predictions = model.classes_.take(np.argmax(train_probabilities, axis=1), axis=0)\n",
    "    validation_probabilities = model.predict_proba(validation_features)\n",
    "    # validation_predictions = model.predict(validation_features)\n",
    "    validation_predictions = model.classes_.take(np.argmax(validation_probabilities, axis=1), axis=0)\n",
    "\n",
    "    # Print the training and validation scores\n",
    "\n",
    "    print(f'Training Accuracy: {accuracy_score(train_targets, train_predictions)}')\n",
    "    print(f'Training Precision: {precision_score(train_targets, train_predictions)}')\n",
    "    print(f'Training Recall: {recall_score(train_targets, train_predictions)}')\n",
    "    print(f'Training F1: {f1_score(train_targets, train_predictions)}')\n",
    "    print(f'Training ROC AUC: {roc_auc_score(train_targets, train_probabilities[:,1])}')\n",
    "    print(f'Validation Accuracy: {accuracy_score(validation_targets, validation_predictions)}')\n",
    "    print(f'Validation Precision: {precision_score(validation_targets, validation_predictions)}')\n",
    "    print(f'Validation Recall: {recall_score(validation_targets, validation_predictions)}')\n",
    "    print(f'Validation F1: {f1_score(validation_targets, validation_predictions)}')\n",
    "    print(f'Validation ROC AUC: {roc_auc_score(validation_targets, validation_probabilities[:,1])}')\n",
    "    \n",
    "    # Evaluate and print the final test scores if final_eval is True\n",
    "    \n",
    "    if final_eval:\n",
    "        test_probabilities = model.predict_proba(test_features)\n",
    "        test_predictions = model.classes_.take(np.argmax(test_probabilities, axis=1), axis=0)\n",
    "\n",
    "        print(f'Test Accuracy: {accuracy_score(test_targets, test_predictions)}')\n",
    "        print(f'Test Precision: {precision_score(test_targets, test_predictions)}')\n",
    "        print(f'Test Recall: {recall_score(test_targets, test_predictions)}')\n",
    "        print(f'Test F1: {f1_score(test_targets, test_predictions)}')\n",
    "        print(f'Test ROC AUC: {roc_auc_score(test_targets, test_probabilities[:,1])}')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observations:\n",
    "* model1 is highly overfitted, test results for f1 has dropped with almost 28 percentage points, other metrics have dropped significantly\n",
    "* the model has a slignt tendency towards precision, meaning that the it is restrictive in predicting heart failures but that it is quite accurate when making the prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = ['accuracy', 'precision', 'recall', 'f1', 'roc_auc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_criterion</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_accuracy</th>\n",
       "      <th>split1_test_accuracy</th>\n",
       "      <th>split2_test_accuracy</th>\n",
       "      <th>split3_test_accuracy</th>\n",
       "      <th>split4_test_accuracy</th>\n",
       "      <th>mean_test_accuracy</th>\n",
       "      <th>std_test_accuracy</th>\n",
       "      <th>rank_test_accuracy</th>\n",
       "      <th>split0_test_precision</th>\n",
       "      <th>split1_test_precision</th>\n",
       "      <th>split2_test_precision</th>\n",
       "      <th>split3_test_precision</th>\n",
       "      <th>split4_test_precision</th>\n",
       "      <th>mean_test_precision</th>\n",
       "      <th>std_test_precision</th>\n",
       "      <th>rank_test_precision</th>\n",
       "      <th>split0_test_recall</th>\n",
       "      <th>split1_test_recall</th>\n",
       "      <th>split2_test_recall</th>\n",
       "      <th>split3_test_recall</th>\n",
       "      <th>split4_test_recall</th>\n",
       "      <th>mean_test_recall</th>\n",
       "      <th>std_test_recall</th>\n",
       "      <th>rank_test_recall</th>\n",
       "      <th>split0_test_f1</th>\n",
       "      <th>split1_test_f1</th>\n",
       "      <th>split2_test_f1</th>\n",
       "      <th>split3_test_f1</th>\n",
       "      <th>split4_test_f1</th>\n",
       "      <th>mean_test_f1</th>\n",
       "      <th>std_test_f1</th>\n",
       "      <th>rank_test_f1</th>\n",
       "      <th>split0_test_roc_auc</th>\n",
       "      <th>split1_test_roc_auc</th>\n",
       "      <th>split2_test_roc_auc</th>\n",
       "      <th>split3_test_roc_auc</th>\n",
       "      <th>split4_test_roc_auc</th>\n",
       "      <th>mean_test_roc_auc</th>\n",
       "      <th>std_test_roc_auc</th>\n",
       "      <th>rank_test_roc_auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001570</td>\n",
       "      <td>0.000796</td>\n",
       "      <td>0.006661</td>\n",
       "      <td>0.003237</td>\n",
       "      <td>gini</td>\n",
       "      <td>1</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 1}</td>\n",
       "      <td>0.854167</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>0.829787</td>\n",
       "      <td>0.840957</td>\n",
       "      <td>0.043059</td>\n",
       "      <td>1</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.840340</td>\n",
       "      <td>0.100487</td>\n",
       "      <td>1</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.6250</td>\n",
       "      <td>0.5625</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.637500</td>\n",
       "      <td>0.058689</td>\n",
       "      <td>11</td>\n",
       "      <td>0.720000</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.722755</td>\n",
       "      <td>0.065724</td>\n",
       "      <td>1</td>\n",
       "      <td>0.784848</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.786458</td>\n",
       "      <td>0.787595</td>\n",
       "      <td>0.042633</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.001183</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>0.004732</td>\n",
       "      <td>0.000079</td>\n",
       "      <td>gini</td>\n",
       "      <td>2</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 2}</td>\n",
       "      <td>0.854167</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.765957</td>\n",
       "      <td>0.799025</td>\n",
       "      <td>0.060308</td>\n",
       "      <td>6</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.702663</td>\n",
       "      <td>0.122237</td>\n",
       "      <td>6</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.6875</td>\n",
       "      <td>0.6875</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.715000</td>\n",
       "      <td>0.087266</td>\n",
       "      <td>1</td>\n",
       "      <td>0.720000</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.699556</td>\n",
       "      <td>0.066669</td>\n",
       "      <td>5</td>\n",
       "      <td>0.925253</td>\n",
       "      <td>0.917172</td>\n",
       "      <td>0.654297</td>\n",
       "      <td>0.784180</td>\n",
       "      <td>0.807292</td>\n",
       "      <td>0.817638</td>\n",
       "      <td>0.099393</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.001247</td>\n",
       "      <td>0.000041</td>\n",
       "      <td>0.004708</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>gini</td>\n",
       "      <td>3</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 3}</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.729167</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.765957</td>\n",
       "      <td>0.790691</td>\n",
       "      <td>0.054734</td>\n",
       "      <td>7</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.717075</td>\n",
       "      <td>0.110408</td>\n",
       "      <td>5</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.081650</td>\n",
       "      <td>33</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.551724</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.645161</td>\n",
       "      <td>0.650366</td>\n",
       "      <td>0.082708</td>\n",
       "      <td>9</td>\n",
       "      <td>0.913131</td>\n",
       "      <td>0.753535</td>\n",
       "      <td>0.685547</td>\n",
       "      <td>0.736328</td>\n",
       "      <td>0.855208</td>\n",
       "      <td>0.788750</td>\n",
       "      <td>0.083098</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.001308</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.004752</td>\n",
       "      <td>0.000067</td>\n",
       "      <td>gini</td>\n",
       "      <td>4</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 4}</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.765957</td>\n",
       "      <td>0.765691</td>\n",
       "      <td>0.048188</td>\n",
       "      <td>18</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.634443</td>\n",
       "      <td>0.062494</td>\n",
       "      <td>22</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.6250</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.638333</td>\n",
       "      <td>0.129056</td>\n",
       "      <td>9</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.516129</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.645161</td>\n",
       "      <td>0.632818</td>\n",
       "      <td>0.084944</td>\n",
       "      <td>16</td>\n",
       "      <td>0.862626</td>\n",
       "      <td>0.649495</td>\n",
       "      <td>0.472656</td>\n",
       "      <td>0.834961</td>\n",
       "      <td>0.796875</td>\n",
       "      <td>0.723323</td>\n",
       "      <td>0.145302</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.001385</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>0.004798</td>\n",
       "      <td>0.000081</td>\n",
       "      <td>gini</td>\n",
       "      <td>5</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 5}</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.729167</td>\n",
       "      <td>0.787234</td>\n",
       "      <td>0.749113</td>\n",
       "      <td>0.050333</td>\n",
       "      <td>28</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.605803</td>\n",
       "      <td>0.056119</td>\n",
       "      <td>29</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.4375</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.614167</td>\n",
       "      <td>0.154821</td>\n",
       "      <td>22</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.551724</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.604595</td>\n",
       "      <td>0.098213</td>\n",
       "      <td>30</td>\n",
       "      <td>0.797980</td>\n",
       "      <td>0.594949</td>\n",
       "      <td>0.520508</td>\n",
       "      <td>0.772461</td>\n",
       "      <td>0.809375</td>\n",
       "      <td>0.699055</td>\n",
       "      <td>0.118374</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.001422</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>0.004754</td>\n",
       "      <td>0.000103</td>\n",
       "      <td>gini</td>\n",
       "      <td>6</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 6}</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.645833</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.808511</td>\n",
       "      <td>0.749202</td>\n",
       "      <td>0.056581</td>\n",
       "      <td>27</td>\n",
       "      <td>0.647059</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.470588</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>0.609374</td>\n",
       "      <td>0.069544</td>\n",
       "      <td>26</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.5625</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.625833</td>\n",
       "      <td>0.151483</td>\n",
       "      <td>15</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>0.484848</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.742857</td>\n",
       "      <td>0.610733</td>\n",
       "      <td>0.094377</td>\n",
       "      <td>29</td>\n",
       "      <td>0.771717</td>\n",
       "      <td>0.723232</td>\n",
       "      <td>0.546875</td>\n",
       "      <td>0.749023</td>\n",
       "      <td>0.821875</td>\n",
       "      <td>0.722545</td>\n",
       "      <td>0.093644</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.001427</td>\n",
       "      <td>0.000043</td>\n",
       "      <td>0.004736</td>\n",
       "      <td>0.000150</td>\n",
       "      <td>gini</td>\n",
       "      <td>7</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 7}</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.604167</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.744681</td>\n",
       "      <td>0.744770</td>\n",
       "      <td>0.072618</td>\n",
       "      <td>30</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.421053</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>0.578947</td>\n",
       "      <td>0.609295</td>\n",
       "      <td>0.102620</td>\n",
       "      <td>27</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.6875</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.637500</td>\n",
       "      <td>0.081052</td>\n",
       "      <td>11</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.457143</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>0.647059</td>\n",
       "      <td>0.620245</td>\n",
       "      <td>0.083079</td>\n",
       "      <td>24</td>\n",
       "      <td>0.752525</td>\n",
       "      <td>0.739394</td>\n",
       "      <td>0.578125</td>\n",
       "      <td>0.765625</td>\n",
       "      <td>0.741667</td>\n",
       "      <td>0.715467</td>\n",
       "      <td>0.069298</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.001398</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>0.004685</td>\n",
       "      <td>0.000094</td>\n",
       "      <td>gini</td>\n",
       "      <td>8</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 8}</td>\n",
       "      <td>0.770833</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.729167</td>\n",
       "      <td>0.765957</td>\n",
       "      <td>0.728191</td>\n",
       "      <td>0.075178</td>\n",
       "      <td>36</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.388889</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.583462</td>\n",
       "      <td>0.102440</td>\n",
       "      <td>35</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.4375</td>\n",
       "      <td>0.5625</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.100035</td>\n",
       "      <td>31</td>\n",
       "      <td>0.645161</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.411765</td>\n",
       "      <td>0.580645</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.589419</td>\n",
       "      <td>0.093347</td>\n",
       "      <td>37</td>\n",
       "      <td>0.742424</td>\n",
       "      <td>0.739394</td>\n",
       "      <td>0.546875</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>0.757292</td>\n",
       "      <td>0.694697</td>\n",
       "      <td>0.077585</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.001411</td>\n",
       "      <td>0.000055</td>\n",
       "      <td>0.004690</td>\n",
       "      <td>0.000075</td>\n",
       "      <td>gini</td>\n",
       "      <td>9</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 9}</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>0.604167</td>\n",
       "      <td>0.729167</td>\n",
       "      <td>0.765957</td>\n",
       "      <td>0.719858</td>\n",
       "      <td>0.064631</td>\n",
       "      <td>39</td>\n",
       "      <td>0.647059</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>0.421053</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.563537</td>\n",
       "      <td>0.079372</td>\n",
       "      <td>39</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.5625</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.599167</td>\n",
       "      <td>0.113786</td>\n",
       "      <td>34</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.457143</td>\n",
       "      <td>0.580645</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.578391</td>\n",
       "      <td>0.090054</td>\n",
       "      <td>39</td>\n",
       "      <td>0.775758</td>\n",
       "      <td>0.642424</td>\n",
       "      <td>0.578125</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>0.757292</td>\n",
       "      <td>0.688220</td>\n",
       "      <td>0.073010</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.001415</td>\n",
       "      <td>0.000043</td>\n",
       "      <td>0.004638</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>gini</td>\n",
       "      <td>10</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 10}</td>\n",
       "      <td>0.770833</td>\n",
       "      <td>0.770833</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>0.787234</td>\n",
       "      <td>0.724113</td>\n",
       "      <td>0.075389</td>\n",
       "      <td>37</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.388889</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.571951</td>\n",
       "      <td>0.094773</td>\n",
       "      <td>37</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.4375</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.600833</td>\n",
       "      <td>0.127159</td>\n",
       "      <td>30</td>\n",
       "      <td>0.645161</td>\n",
       "      <td>0.620690</td>\n",
       "      <td>0.411765</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.583366</td>\n",
       "      <td>0.102149</td>\n",
       "      <td>38</td>\n",
       "      <td>0.742424</td>\n",
       "      <td>0.724242</td>\n",
       "      <td>0.546875</td>\n",
       "      <td>0.656250</td>\n",
       "      <td>0.790625</td>\n",
       "      <td>0.692083</td>\n",
       "      <td>0.084437</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.001399</td>\n",
       "      <td>0.000054</td>\n",
       "      <td>0.004709</td>\n",
       "      <td>0.000070</td>\n",
       "      <td>gini</td>\n",
       "      <td>11</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 11}</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>0.604167</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.808511</td>\n",
       "      <td>0.736702</td>\n",
       "      <td>0.078975</td>\n",
       "      <td>31</td>\n",
       "      <td>0.647059</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.421053</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.584456</td>\n",
       "      <td>0.105004</td>\n",
       "      <td>33</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.6875</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.650833</td>\n",
       "      <td>0.115722</td>\n",
       "      <td>8</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>0.516129</td>\n",
       "      <td>0.457143</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.615109</td>\n",
       "      <td>0.107529</td>\n",
       "      <td>28</td>\n",
       "      <td>0.775758</td>\n",
       "      <td>0.645455</td>\n",
       "      <td>0.578125</td>\n",
       "      <td>0.765625</td>\n",
       "      <td>0.806250</td>\n",
       "      <td>0.714242</td>\n",
       "      <td>0.087349</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.001424</td>\n",
       "      <td>0.000054</td>\n",
       "      <td>0.004685</td>\n",
       "      <td>0.000071</td>\n",
       "      <td>gini</td>\n",
       "      <td>12</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 12}</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.851064</td>\n",
       "      <td>0.749379</td>\n",
       "      <td>0.091538</td>\n",
       "      <td>26</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.388889</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.722222</td>\n",
       "      <td>0.600556</td>\n",
       "      <td>0.113643</td>\n",
       "      <td>30</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.4375</td>\n",
       "      <td>0.6250</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.665833</td>\n",
       "      <td>0.152625</td>\n",
       "      <td>5</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.411765</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.787879</td>\n",
       "      <td>0.630383</td>\n",
       "      <td>0.128793</td>\n",
       "      <td>17</td>\n",
       "      <td>0.809091</td>\n",
       "      <td>0.709091</td>\n",
       "      <td>0.546875</td>\n",
       "      <td>0.718750</td>\n",
       "      <td>0.855208</td>\n",
       "      <td>0.727803</td>\n",
       "      <td>0.105837</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.001406</td>\n",
       "      <td>0.000047</td>\n",
       "      <td>0.004688</td>\n",
       "      <td>0.000076</td>\n",
       "      <td>gini</td>\n",
       "      <td>13</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 13}</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.604167</td>\n",
       "      <td>0.770833</td>\n",
       "      <td>0.829787</td>\n",
       "      <td>0.753457</td>\n",
       "      <td>0.079892</td>\n",
       "      <td>24</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.421053</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.614963</td>\n",
       "      <td>0.100331</td>\n",
       "      <td>25</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.6250</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.651667</td>\n",
       "      <td>0.134619</td>\n",
       "      <td>6</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.457143</td>\n",
       "      <td>0.645161</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.629623</td>\n",
       "      <td>0.107734</td>\n",
       "      <td>18</td>\n",
       "      <td>0.790909</td>\n",
       "      <td>0.690909</td>\n",
       "      <td>0.578125</td>\n",
       "      <td>0.734375</td>\n",
       "      <td>0.839583</td>\n",
       "      <td>0.726780</td>\n",
       "      <td>0.089755</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.001406</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.004729</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>gini</td>\n",
       "      <td>14</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 14}</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.729167</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.787234</td>\n",
       "      <td>0.728280</td>\n",
       "      <td>0.076126</td>\n",
       "      <td>35</td>\n",
       "      <td>0.647059</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.388889</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.572791</td>\n",
       "      <td>0.095414</td>\n",
       "      <td>36</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.4375</td>\n",
       "      <td>0.6250</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.625833</td>\n",
       "      <td>0.131085</td>\n",
       "      <td>16</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>0.551724</td>\n",
       "      <td>0.411765</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.596374</td>\n",
       "      <td>0.106948</td>\n",
       "      <td>34</td>\n",
       "      <td>0.775758</td>\n",
       "      <td>0.675758</td>\n",
       "      <td>0.546875</td>\n",
       "      <td>0.718750</td>\n",
       "      <td>0.790625</td>\n",
       "      <td>0.701553</td>\n",
       "      <td>0.087552</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.001416</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.004670</td>\n",
       "      <td>0.000118</td>\n",
       "      <td>gini</td>\n",
       "      <td>15</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 15}</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.604167</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.765957</td>\n",
       "      <td>0.736525</td>\n",
       "      <td>0.070029</td>\n",
       "      <td>33</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.421053</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.597367</td>\n",
       "      <td>0.095952</td>\n",
       "      <td>31</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.6250</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.611667</td>\n",
       "      <td>0.085570</td>\n",
       "      <td>25</td>\n",
       "      <td>0.689655</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.457143</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.601979</td>\n",
       "      <td>0.082840</td>\n",
       "      <td>31</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.690909</td>\n",
       "      <td>0.578125</td>\n",
       "      <td>0.718750</td>\n",
       "      <td>0.757292</td>\n",
       "      <td>0.703561</td>\n",
       "      <td>0.068987</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.001412</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>0.004742</td>\n",
       "      <td>0.000133</td>\n",
       "      <td>gini</td>\n",
       "      <td>16</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 16}</td>\n",
       "      <td>0.770833</td>\n",
       "      <td>0.729167</td>\n",
       "      <td>0.604167</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>0.765957</td>\n",
       "      <td>0.715691</td>\n",
       "      <td>0.060400</td>\n",
       "      <td>40</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.421053</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.557782</td>\n",
       "      <td>0.071229</td>\n",
       "      <td>40</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.117379</td>\n",
       "      <td>31</td>\n",
       "      <td>0.645161</td>\n",
       "      <td>0.551724</td>\n",
       "      <td>0.457143</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.685714</td>\n",
       "      <td>0.574615</td>\n",
       "      <td>0.081667</td>\n",
       "      <td>40</td>\n",
       "      <td>0.742424</td>\n",
       "      <td>0.675758</td>\n",
       "      <td>0.578125</td>\n",
       "      <td>0.656250</td>\n",
       "      <td>0.775000</td>\n",
       "      <td>0.685511</td>\n",
       "      <td>0.068892</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.001410</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.004710</td>\n",
       "      <td>0.000080</td>\n",
       "      <td>gini</td>\n",
       "      <td>17</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 17}</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.765957</td>\n",
       "      <td>0.724025</td>\n",
       "      <td>0.086308</td>\n",
       "      <td>38</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.388889</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.566111</td>\n",
       "      <td>0.119930</td>\n",
       "      <td>38</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.4375</td>\n",
       "      <td>0.6875</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.145940</td>\n",
       "      <td>17</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.411765</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>0.685714</td>\n",
       "      <td>0.592265</td>\n",
       "      <td>0.126446</td>\n",
       "      <td>36</td>\n",
       "      <td>0.790909</td>\n",
       "      <td>0.612121</td>\n",
       "      <td>0.546875</td>\n",
       "      <td>0.765625</td>\n",
       "      <td>0.775000</td>\n",
       "      <td>0.698106</td>\n",
       "      <td>0.099346</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.001403</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>0.004657</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>gini</td>\n",
       "      <td>18</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 18}</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>0.770833</td>\n",
       "      <td>0.604167</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.787234</td>\n",
       "      <td>0.744947</td>\n",
       "      <td>0.073303</td>\n",
       "      <td>29</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.421053</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.606360</td>\n",
       "      <td>0.095439</td>\n",
       "      <td>28</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.6250</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.638333</td>\n",
       "      <td>0.114455</td>\n",
       "      <td>9</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.592593</td>\n",
       "      <td>0.457143</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.618059</td>\n",
       "      <td>0.092410</td>\n",
       "      <td>25</td>\n",
       "      <td>0.790909</td>\n",
       "      <td>0.706061</td>\n",
       "      <td>0.578125</td>\n",
       "      <td>0.718750</td>\n",
       "      <td>0.790625</td>\n",
       "      <td>0.716894</td>\n",
       "      <td>0.077836</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.001413</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>0.004657</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>gini</td>\n",
       "      <td>19</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 19}</td>\n",
       "      <td>0.770833</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.604167</td>\n",
       "      <td>0.770833</td>\n",
       "      <td>0.787234</td>\n",
       "      <td>0.736613</td>\n",
       "      <td>0.067269</td>\n",
       "      <td>32</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.421053</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.647059</td>\n",
       "      <td>0.595033</td>\n",
       "      <td>0.088791</td>\n",
       "      <td>32</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.6250</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.611667</td>\n",
       "      <td>0.085570</td>\n",
       "      <td>25</td>\n",
       "      <td>0.645161</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.457143</td>\n",
       "      <td>0.645161</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>0.601279</td>\n",
       "      <td>0.081181</td>\n",
       "      <td>33</td>\n",
       "      <td>0.742424</td>\n",
       "      <td>0.690909</td>\n",
       "      <td>0.578125</td>\n",
       "      <td>0.734375</td>\n",
       "      <td>0.772917</td>\n",
       "      <td>0.703750</td>\n",
       "      <td>0.068065</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.001447</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>0.004684</td>\n",
       "      <td>0.000059</td>\n",
       "      <td>gini</td>\n",
       "      <td>20</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 20}</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>0.604167</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.808511</td>\n",
       "      <td>0.732535</td>\n",
       "      <td>0.072990</td>\n",
       "      <td>34</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>0.421053</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.583570</td>\n",
       "      <td>0.093780</td>\n",
       "      <td>34</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.6250</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.611667</td>\n",
       "      <td>0.120139</td>\n",
       "      <td>25</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.457143</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.595216</td>\n",
       "      <td>0.101550</td>\n",
       "      <td>35</td>\n",
       "      <td>0.757576</td>\n",
       "      <td>0.642424</td>\n",
       "      <td>0.578125</td>\n",
       "      <td>0.718750</td>\n",
       "      <td>0.806250</td>\n",
       "      <td>0.700625</td>\n",
       "      <td>0.081391</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.001104</td>\n",
       "      <td>0.000077</td>\n",
       "      <td>0.004747</td>\n",
       "      <td>0.000129</td>\n",
       "      <td>entropy</td>\n",
       "      <td>1</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 1}</td>\n",
       "      <td>0.854167</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>0.829787</td>\n",
       "      <td>0.840957</td>\n",
       "      <td>0.043059</td>\n",
       "      <td>1</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.840340</td>\n",
       "      <td>0.100487</td>\n",
       "      <td>1</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.6250</td>\n",
       "      <td>0.5625</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.637500</td>\n",
       "      <td>0.058689</td>\n",
       "      <td>11</td>\n",
       "      <td>0.720000</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.722755</td>\n",
       "      <td>0.065724</td>\n",
       "      <td>1</td>\n",
       "      <td>0.784848</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.786458</td>\n",
       "      <td>0.787595</td>\n",
       "      <td>0.042633</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.001157</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.004638</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>entropy</td>\n",
       "      <td>2</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 2}</td>\n",
       "      <td>0.854167</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.829787</td>\n",
       "      <td>0.828457</td>\n",
       "      <td>0.033275</td>\n",
       "      <td>3</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.767144</td>\n",
       "      <td>0.073210</td>\n",
       "      <td>3</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.6250</td>\n",
       "      <td>0.6875</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.689167</td>\n",
       "      <td>0.093897</td>\n",
       "      <td>4</td>\n",
       "      <td>0.720000</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.720190</td>\n",
       "      <td>0.049979</td>\n",
       "      <td>3</td>\n",
       "      <td>0.925253</td>\n",
       "      <td>0.917172</td>\n",
       "      <td>0.777344</td>\n",
       "      <td>0.795898</td>\n",
       "      <td>0.821875</td>\n",
       "      <td>0.847508</td>\n",
       "      <td>0.061872</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.001230</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>0.004741</td>\n",
       "      <td>0.000115</td>\n",
       "      <td>entropy</td>\n",
       "      <td>3</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 3}</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.854167</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.787234</td>\n",
       "      <td>0.819947</td>\n",
       "      <td>0.037072</td>\n",
       "      <td>4</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.745634</td>\n",
       "      <td>0.095599</td>\n",
       "      <td>4</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.6875</td>\n",
       "      <td>0.6250</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.702500</td>\n",
       "      <td>0.059954</td>\n",
       "      <td>2</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.758621</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.717580</td>\n",
       "      <td>0.039965</td>\n",
       "      <td>4</td>\n",
       "      <td>0.913131</td>\n",
       "      <td>0.819192</td>\n",
       "      <td>0.804688</td>\n",
       "      <td>0.783203</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>0.834043</td>\n",
       "      <td>0.045114</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.001301</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>0.004737</td>\n",
       "      <td>0.000073</td>\n",
       "      <td>entropy</td>\n",
       "      <td>4</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 4}</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.729167</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.787234</td>\n",
       "      <td>0.803280</td>\n",
       "      <td>0.041134</td>\n",
       "      <td>5</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.701420</td>\n",
       "      <td>0.064977</td>\n",
       "      <td>7</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.4375</td>\n",
       "      <td>0.6875</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.691667</td>\n",
       "      <td>0.146700</td>\n",
       "      <td>3</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.518519</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.687345</td>\n",
       "      <td>0.086800</td>\n",
       "      <td>6</td>\n",
       "      <td>0.881818</td>\n",
       "      <td>0.732323</td>\n",
       "      <td>0.792969</td>\n",
       "      <td>0.767578</td>\n",
       "      <td>0.860417</td>\n",
       "      <td>0.807021</td>\n",
       "      <td>0.056176</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.001353</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>0.004771</td>\n",
       "      <td>0.000093</td>\n",
       "      <td>entropy</td>\n",
       "      <td>5</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 5}</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.729167</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>0.787234</td>\n",
       "      <td>0.774113</td>\n",
       "      <td>0.030184</td>\n",
       "      <td>15</td>\n",
       "      <td>0.647059</td>\n",
       "      <td>0.562500</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.667453</td>\n",
       "      <td>0.083374</td>\n",
       "      <td>12</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.5625</td>\n",
       "      <td>0.5625</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.066196</td>\n",
       "      <td>19</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>0.580645</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.640296</td>\n",
       "      <td>0.041955</td>\n",
       "      <td>13</td>\n",
       "      <td>0.842424</td>\n",
       "      <td>0.630303</td>\n",
       "      <td>0.697266</td>\n",
       "      <td>0.766602</td>\n",
       "      <td>0.852083</td>\n",
       "      <td>0.757736</td>\n",
       "      <td>0.084909</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.001401</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.004766</td>\n",
       "      <td>0.000094</td>\n",
       "      <td>entropy</td>\n",
       "      <td>6</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 6}</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.787234</td>\n",
       "      <td>0.778280</td>\n",
       "      <td>0.036061</td>\n",
       "      <td>10</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.647059</td>\n",
       "      <td>0.689412</td>\n",
       "      <td>0.076765</td>\n",
       "      <td>8</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.4375</td>\n",
       "      <td>0.5625</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.586667</td>\n",
       "      <td>0.103528</td>\n",
       "      <td>39</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.640000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>0.627405</td>\n",
       "      <td>0.066004</td>\n",
       "      <td>19</td>\n",
       "      <td>0.801010</td>\n",
       "      <td>0.763636</td>\n",
       "      <td>0.666992</td>\n",
       "      <td>0.786133</td>\n",
       "      <td>0.777083</td>\n",
       "      <td>0.758971</td>\n",
       "      <td>0.047571</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.001439</td>\n",
       "      <td>0.000090</td>\n",
       "      <td>0.004800</td>\n",
       "      <td>0.000116</td>\n",
       "      <td>entropy</td>\n",
       "      <td>7</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 7}</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.770833</td>\n",
       "      <td>0.765957</td>\n",
       "      <td>0.769858</td>\n",
       "      <td>0.022905</td>\n",
       "      <td>17</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.657967</td>\n",
       "      <td>0.038677</td>\n",
       "      <td>16</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.5625</td>\n",
       "      <td>0.5625</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.598333</td>\n",
       "      <td>0.056801</td>\n",
       "      <td>36</td>\n",
       "      <td>0.689655</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.620690</td>\n",
       "      <td>0.645161</td>\n",
       "      <td>0.625387</td>\n",
       "      <td>0.040248</td>\n",
       "      <td>20</td>\n",
       "      <td>0.767677</td>\n",
       "      <td>0.690909</td>\n",
       "      <td>0.703125</td>\n",
       "      <td>0.718750</td>\n",
       "      <td>0.739583</td>\n",
       "      <td>0.724009</td>\n",
       "      <td>0.027235</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.001458</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.004716</td>\n",
       "      <td>0.000075</td>\n",
       "      <td>entropy</td>\n",
       "      <td>8</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 8}</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.770833</td>\n",
       "      <td>0.765957</td>\n",
       "      <td>0.778191</td>\n",
       "      <td>0.021713</td>\n",
       "      <td>13</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.668223</td>\n",
       "      <td>0.032298</td>\n",
       "      <td>11</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.5625</td>\n",
       "      <td>0.5625</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.051031</td>\n",
       "      <td>19</td>\n",
       "      <td>0.689655</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.620690</td>\n",
       "      <td>0.645161</td>\n",
       "      <td>0.644435</td>\n",
       "      <td>0.031868</td>\n",
       "      <td>11</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.757576</td>\n",
       "      <td>0.703125</td>\n",
       "      <td>0.718750</td>\n",
       "      <td>0.739583</td>\n",
       "      <td>0.738352</td>\n",
       "      <td>0.025211</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.001403</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>0.004722</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>entropy</td>\n",
       "      <td>9</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 9}</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.765957</td>\n",
       "      <td>0.761525</td>\n",
       "      <td>0.030980</td>\n",
       "      <td>22</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.643571</td>\n",
       "      <td>0.069797</td>\n",
       "      <td>20</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.5625</td>\n",
       "      <td>0.5625</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.598333</td>\n",
       "      <td>0.056801</td>\n",
       "      <td>36</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.645161</td>\n",
       "      <td>0.617604</td>\n",
       "      <td>0.047362</td>\n",
       "      <td>27</td>\n",
       "      <td>0.757576</td>\n",
       "      <td>0.660606</td>\n",
       "      <td>0.703125</td>\n",
       "      <td>0.734375</td>\n",
       "      <td>0.739583</td>\n",
       "      <td>0.719053</td>\n",
       "      <td>0.034088</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.001410</td>\n",
       "      <td>0.000074</td>\n",
       "      <td>0.004759</td>\n",
       "      <td>0.000083</td>\n",
       "      <td>entropy</td>\n",
       "      <td>10</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 10}</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>0.770833</td>\n",
       "      <td>0.729167</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.787234</td>\n",
       "      <td>0.778280</td>\n",
       "      <td>0.027921</td>\n",
       "      <td>10</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.647059</td>\n",
       "      <td>0.657846</td>\n",
       "      <td>0.037585</td>\n",
       "      <td>17</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.6250</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.651667</td>\n",
       "      <td>0.086346</td>\n",
       "      <td>6</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.645161</td>\n",
       "      <td>0.551724</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>0.652146</td>\n",
       "      <td>0.054597</td>\n",
       "      <td>8</td>\n",
       "      <td>0.790909</td>\n",
       "      <td>0.742424</td>\n",
       "      <td>0.671875</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.772917</td>\n",
       "      <td>0.745625</td>\n",
       "      <td>0.040654</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.001385</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.004714</td>\n",
       "      <td>0.000079</td>\n",
       "      <td>entropy</td>\n",
       "      <td>11</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 11}</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.765957</td>\n",
       "      <td>0.757358</td>\n",
       "      <td>0.042658</td>\n",
       "      <td>23</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.632644</td>\n",
       "      <td>0.073656</td>\n",
       "      <td>23</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.4375</td>\n",
       "      <td>0.6250</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.612500</td>\n",
       "      <td>0.088976</td>\n",
       "      <td>23</td>\n",
       "      <td>0.689655</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.645161</td>\n",
       "      <td>0.617944</td>\n",
       "      <td>0.067898</td>\n",
       "      <td>26</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.696970</td>\n",
       "      <td>0.640625</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.739583</td>\n",
       "      <td>0.719981</td>\n",
       "      <td>0.046679</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.001391</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.004728</td>\n",
       "      <td>0.000083</td>\n",
       "      <td>entropy</td>\n",
       "      <td>12</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 12}</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.770833</td>\n",
       "      <td>0.787234</td>\n",
       "      <td>0.786613</td>\n",
       "      <td>0.027562</td>\n",
       "      <td>8</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.647059</td>\n",
       "      <td>0.688752</td>\n",
       "      <td>0.045490</td>\n",
       "      <td>10</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.5625</td>\n",
       "      <td>0.5625</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.066196</td>\n",
       "      <td>17</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.620690</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>0.653067</td>\n",
       "      <td>0.042195</td>\n",
       "      <td>7</td>\n",
       "      <td>0.739394</td>\n",
       "      <td>0.787879</td>\n",
       "      <td>0.703125</td>\n",
       "      <td>0.718750</td>\n",
       "      <td>0.772917</td>\n",
       "      <td>0.744413</td>\n",
       "      <td>0.031907</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.001407</td>\n",
       "      <td>0.000047</td>\n",
       "      <td>0.004767</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>entropy</td>\n",
       "      <td>13</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 13}</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.770833</td>\n",
       "      <td>0.765957</td>\n",
       "      <td>0.774025</td>\n",
       "      <td>0.015968</td>\n",
       "      <td>16</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.663828</td>\n",
       "      <td>0.026749</td>\n",
       "      <td>14</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.5625</td>\n",
       "      <td>0.5625</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.611667</td>\n",
       "      <td>0.046949</td>\n",
       "      <td>28</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.620690</td>\n",
       "      <td>0.645161</td>\n",
       "      <td>0.635075</td>\n",
       "      <td>0.022793</td>\n",
       "      <td>15</td>\n",
       "      <td>0.757576</td>\n",
       "      <td>0.739394</td>\n",
       "      <td>0.703125</td>\n",
       "      <td>0.718750</td>\n",
       "      <td>0.739583</td>\n",
       "      <td>0.731686</td>\n",
       "      <td>0.018842</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.001422</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.004647</td>\n",
       "      <td>0.000083</td>\n",
       "      <td>entropy</td>\n",
       "      <td>14</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 14}</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>0.729167</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.787234</td>\n",
       "      <td>0.761613</td>\n",
       "      <td>0.035649</td>\n",
       "      <td>20</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.645007</td>\n",
       "      <td>0.073385</td>\n",
       "      <td>19</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.5625</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.612500</td>\n",
       "      <td>0.069222</td>\n",
       "      <td>23</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>0.551724</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.623230</td>\n",
       "      <td>0.045818</td>\n",
       "      <td>21</td>\n",
       "      <td>0.757576</td>\n",
       "      <td>0.696970</td>\n",
       "      <td>0.671875</td>\n",
       "      <td>0.734375</td>\n",
       "      <td>0.755208</td>\n",
       "      <td>0.723201</td>\n",
       "      <td>0.033626</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.001405</td>\n",
       "      <td>0.000061</td>\n",
       "      <td>0.004727</td>\n",
       "      <td>0.000098</td>\n",
       "      <td>entropy</td>\n",
       "      <td>15</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 15}</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.770833</td>\n",
       "      <td>0.770833</td>\n",
       "      <td>0.765957</td>\n",
       "      <td>0.778191</td>\n",
       "      <td>0.011146</td>\n",
       "      <td>13</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.663462</td>\n",
       "      <td>0.021644</td>\n",
       "      <td>15</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.6250</td>\n",
       "      <td>0.5625</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.637500</td>\n",
       "      <td>0.040825</td>\n",
       "      <td>11</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.645161</td>\n",
       "      <td>0.620690</td>\n",
       "      <td>0.645161</td>\n",
       "      <td>0.648869</td>\n",
       "      <td>0.017059</td>\n",
       "      <td>10</td>\n",
       "      <td>0.757576</td>\n",
       "      <td>0.757576</td>\n",
       "      <td>0.734375</td>\n",
       "      <td>0.718750</td>\n",
       "      <td>0.739583</td>\n",
       "      <td>0.741572</td>\n",
       "      <td>0.014757</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.001402</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.004678</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>entropy</td>\n",
       "      <td>16</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 16}</td>\n",
       "      <td>0.770833</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.729167</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.787234</td>\n",
       "      <td>0.782447</td>\n",
       "      <td>0.033678</td>\n",
       "      <td>9</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.688828</td>\n",
       "      <td>0.060341</td>\n",
       "      <td>9</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.5625</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.599167</td>\n",
       "      <td>0.063705</td>\n",
       "      <td>35</td>\n",
       "      <td>0.620690</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.551724</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.639245</td>\n",
       "      <td>0.053666</td>\n",
       "      <td>14</td>\n",
       "      <td>0.724242</td>\n",
       "      <td>0.787879</td>\n",
       "      <td>0.671875</td>\n",
       "      <td>0.734375</td>\n",
       "      <td>0.755208</td>\n",
       "      <td>0.734716</td>\n",
       "      <td>0.038223</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.001427</td>\n",
       "      <td>0.000054</td>\n",
       "      <td>0.004681</td>\n",
       "      <td>0.000109</td>\n",
       "      <td>entropy</td>\n",
       "      <td>17</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 17}</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>0.729167</td>\n",
       "      <td>0.770833</td>\n",
       "      <td>0.765957</td>\n",
       "      <td>0.753191</td>\n",
       "      <td>0.030146</td>\n",
       "      <td>25</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.622436</td>\n",
       "      <td>0.046948</td>\n",
       "      <td>24</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.6250</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.585000</td>\n",
       "      <td>0.085049</td>\n",
       "      <td>40</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.551724</td>\n",
       "      <td>0.645161</td>\n",
       "      <td>0.645161</td>\n",
       "      <td>0.601743</td>\n",
       "      <td>0.064558</td>\n",
       "      <td>32</td>\n",
       "      <td>0.757576</td>\n",
       "      <td>0.642424</td>\n",
       "      <td>0.671875</td>\n",
       "      <td>0.734375</td>\n",
       "      <td>0.739583</td>\n",
       "      <td>0.709167</td>\n",
       "      <td>0.044157</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.001410</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>0.004741</td>\n",
       "      <td>0.000123</td>\n",
       "      <td>entropy</td>\n",
       "      <td>18</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 18}</td>\n",
       "      <td>0.770833</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>0.770833</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.787234</td>\n",
       "      <td>0.761613</td>\n",
       "      <td>0.038006</td>\n",
       "      <td>20</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.638095</td>\n",
       "      <td>0.072843</td>\n",
       "      <td>21</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.6250</td>\n",
       "      <td>0.6250</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.610000</td>\n",
       "      <td>0.043906</td>\n",
       "      <td>29</td>\n",
       "      <td>0.620690</td>\n",
       "      <td>0.516129</td>\n",
       "      <td>0.645161</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.623063</td>\n",
       "      <td>0.056092</td>\n",
       "      <td>22</td>\n",
       "      <td>0.724242</td>\n",
       "      <td>0.645455</td>\n",
       "      <td>0.734375</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.755208</td>\n",
       "      <td>0.721856</td>\n",
       "      <td>0.039759</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.001427</td>\n",
       "      <td>0.000063</td>\n",
       "      <td>0.004839</td>\n",
       "      <td>0.000166</td>\n",
       "      <td>entropy</td>\n",
       "      <td>19</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 19}</td>\n",
       "      <td>0.770833</td>\n",
       "      <td>0.729167</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>0.765957</td>\n",
       "      <td>0.765691</td>\n",
       "      <td>0.027560</td>\n",
       "      <td>18</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.650275</td>\n",
       "      <td>0.064986</td>\n",
       "      <td>18</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.5625</td>\n",
       "      <td>0.6250</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.597500</td>\n",
       "      <td>0.046667</td>\n",
       "      <td>38</td>\n",
       "      <td>0.620690</td>\n",
       "      <td>0.551724</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.689655</td>\n",
       "      <td>0.645161</td>\n",
       "      <td>0.621446</td>\n",
       "      <td>0.045905</td>\n",
       "      <td>23</td>\n",
       "      <td>0.724242</td>\n",
       "      <td>0.675758</td>\n",
       "      <td>0.703125</td>\n",
       "      <td>0.765625</td>\n",
       "      <td>0.739583</td>\n",
       "      <td>0.721667</td>\n",
       "      <td>0.030697</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.001469</td>\n",
       "      <td>0.000094</td>\n",
       "      <td>0.004775</td>\n",
       "      <td>0.000123</td>\n",
       "      <td>entropy</td>\n",
       "      <td>20</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 20}</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.787234</td>\n",
       "      <td>0.778280</td>\n",
       "      <td>0.024617</td>\n",
       "      <td>10</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.647059</td>\n",
       "      <td>0.666774</td>\n",
       "      <td>0.040290</td>\n",
       "      <td>13</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.5625</td>\n",
       "      <td>0.6250</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.624167</td>\n",
       "      <td>0.071802</td>\n",
       "      <td>21</td>\n",
       "      <td>0.689655</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>0.643050</td>\n",
       "      <td>0.048350</td>\n",
       "      <td>12</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.690909</td>\n",
       "      <td>0.703125</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.772917</td>\n",
       "      <td>0.737936</td>\n",
       "      <td>0.034650</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0        0.001570      0.000796         0.006661        0.003237   \n",
       "1        0.001183      0.000045         0.004732        0.000079   \n",
       "2        0.001247      0.000041         0.004708        0.000045   \n",
       "3        0.001308      0.000031         0.004752        0.000067   \n",
       "4        0.001385      0.000024         0.004798        0.000081   \n",
       "5        0.001422      0.000030         0.004754        0.000103   \n",
       "6        0.001427      0.000043         0.004736        0.000150   \n",
       "7        0.001398      0.000027         0.004685        0.000094   \n",
       "8        0.001411      0.000055         0.004690        0.000075   \n",
       "9        0.001415      0.000043         0.004638        0.000044   \n",
       "10       0.001399      0.000054         0.004709        0.000070   \n",
       "11       0.001424      0.000054         0.004685        0.000071   \n",
       "12       0.001406      0.000047         0.004688        0.000076   \n",
       "13       0.001406      0.000021         0.004729        0.000039   \n",
       "14       0.001416      0.000026         0.004670        0.000118   \n",
       "15       0.001412      0.000049         0.004742        0.000133   \n",
       "16       0.001410      0.000038         0.004710        0.000080   \n",
       "17       0.001403      0.000029         0.004657        0.000023   \n",
       "18       0.001413      0.000029         0.004657        0.000064   \n",
       "19       0.001447      0.000025         0.004684        0.000059   \n",
       "20       0.001104      0.000077         0.004747        0.000129   \n",
       "21       0.001157      0.000016         0.004638        0.000049   \n",
       "22       0.001230      0.000034         0.004741        0.000115   \n",
       "23       0.001301      0.000027         0.004737        0.000073   \n",
       "24       0.001353      0.000040         0.004771        0.000093   \n",
       "25       0.001401      0.000042         0.004766        0.000094   \n",
       "26       0.001439      0.000090         0.004800        0.000116   \n",
       "27       0.001458      0.000060         0.004716        0.000075   \n",
       "28       0.001403      0.000044         0.004722        0.000052   \n",
       "29       0.001410      0.000074         0.004759        0.000083   \n",
       "30       0.001385      0.000023         0.004714        0.000079   \n",
       "31       0.001391      0.000014         0.004728        0.000083   \n",
       "32       0.001407      0.000047         0.004767        0.000044   \n",
       "33       0.001422      0.000069         0.004647        0.000083   \n",
       "34       0.001405      0.000061         0.004727        0.000098   \n",
       "35       0.001402      0.000038         0.004678        0.000066   \n",
       "36       0.001427      0.000054         0.004681        0.000109   \n",
       "37       0.001410      0.000033         0.004741        0.000123   \n",
       "38       0.001427      0.000063         0.004839        0.000166   \n",
       "39       0.001469      0.000094         0.004775        0.000123   \n",
       "\n",
       "   param_criterion param_max_depth                                     params  \\\n",
       "0             gini               1      {'criterion': 'gini', 'max_depth': 1}   \n",
       "1             gini               2      {'criterion': 'gini', 'max_depth': 2}   \n",
       "2             gini               3      {'criterion': 'gini', 'max_depth': 3}   \n",
       "3             gini               4      {'criterion': 'gini', 'max_depth': 4}   \n",
       "4             gini               5      {'criterion': 'gini', 'max_depth': 5}   \n",
       "5             gini               6      {'criterion': 'gini', 'max_depth': 6}   \n",
       "6             gini               7      {'criterion': 'gini', 'max_depth': 7}   \n",
       "7             gini               8      {'criterion': 'gini', 'max_depth': 8}   \n",
       "8             gini               9      {'criterion': 'gini', 'max_depth': 9}   \n",
       "9             gini              10     {'criterion': 'gini', 'max_depth': 10}   \n",
       "10            gini              11     {'criterion': 'gini', 'max_depth': 11}   \n",
       "11            gini              12     {'criterion': 'gini', 'max_depth': 12}   \n",
       "12            gini              13     {'criterion': 'gini', 'max_depth': 13}   \n",
       "13            gini              14     {'criterion': 'gini', 'max_depth': 14}   \n",
       "14            gini              15     {'criterion': 'gini', 'max_depth': 15}   \n",
       "15            gini              16     {'criterion': 'gini', 'max_depth': 16}   \n",
       "16            gini              17     {'criterion': 'gini', 'max_depth': 17}   \n",
       "17            gini              18     {'criterion': 'gini', 'max_depth': 18}   \n",
       "18            gini              19     {'criterion': 'gini', 'max_depth': 19}   \n",
       "19            gini              20     {'criterion': 'gini', 'max_depth': 20}   \n",
       "20         entropy               1   {'criterion': 'entropy', 'max_depth': 1}   \n",
       "21         entropy               2   {'criterion': 'entropy', 'max_depth': 2}   \n",
       "22         entropy               3   {'criterion': 'entropy', 'max_depth': 3}   \n",
       "23         entropy               4   {'criterion': 'entropy', 'max_depth': 4}   \n",
       "24         entropy               5   {'criterion': 'entropy', 'max_depth': 5}   \n",
       "25         entropy               6   {'criterion': 'entropy', 'max_depth': 6}   \n",
       "26         entropy               7   {'criterion': 'entropy', 'max_depth': 7}   \n",
       "27         entropy               8   {'criterion': 'entropy', 'max_depth': 8}   \n",
       "28         entropy               9   {'criterion': 'entropy', 'max_depth': 9}   \n",
       "29         entropy              10  {'criterion': 'entropy', 'max_depth': 10}   \n",
       "30         entropy              11  {'criterion': 'entropy', 'max_depth': 11}   \n",
       "31         entropy              12  {'criterion': 'entropy', 'max_depth': 12}   \n",
       "32         entropy              13  {'criterion': 'entropy', 'max_depth': 13}   \n",
       "33         entropy              14  {'criterion': 'entropy', 'max_depth': 14}   \n",
       "34         entropy              15  {'criterion': 'entropy', 'max_depth': 15}   \n",
       "35         entropy              16  {'criterion': 'entropy', 'max_depth': 16}   \n",
       "36         entropy              17  {'criterion': 'entropy', 'max_depth': 17}   \n",
       "37         entropy              18  {'criterion': 'entropy', 'max_depth': 18}   \n",
       "38         entropy              19  {'criterion': 'entropy', 'max_depth': 19}   \n",
       "39         entropy              20  {'criterion': 'entropy', 'max_depth': 20}   \n",
       "\n",
       "    split0_test_accuracy  split1_test_accuracy  split2_test_accuracy  \\\n",
       "0               0.854167              0.916667              0.791667   \n",
       "1               0.854167              0.875000              0.708333   \n",
       "2               0.875000              0.833333              0.729167   \n",
       "3               0.833333              0.750000              0.687500   \n",
       "4               0.812500              0.750000              0.666667   \n",
       "5               0.791667              0.750000              0.645833   \n",
       "6               0.791667              0.791667              0.604167   \n",
       "7               0.770833              0.791667              0.583333   \n",
       "8               0.791667              0.708333              0.604167   \n",
       "9               0.770833              0.770833              0.583333   \n",
       "10              0.791667              0.687500              0.604167   \n",
       "11              0.812500              0.750000              0.583333   \n",
       "12              0.812500              0.750000              0.604167   \n",
       "13              0.791667              0.729167              0.583333   \n",
       "14              0.812500              0.750000              0.604167   \n",
       "15              0.770833              0.729167              0.604167   \n",
       "16              0.812500              0.666667              0.583333   \n",
       "17              0.812500              0.770833              0.604167   \n",
       "18              0.770833              0.750000              0.604167   \n",
       "19              0.791667              0.708333              0.604167   \n",
       "20              0.854167              0.916667              0.791667   \n",
       "21              0.854167              0.875000              0.791667   \n",
       "22              0.875000              0.854167              0.791667   \n",
       "23              0.833333              0.833333              0.729167   \n",
       "24              0.791667              0.729167              0.750000   \n",
       "25              0.791667              0.812500              0.708333   \n",
       "26              0.812500              0.750000              0.750000   \n",
       "27              0.812500              0.791667              0.750000   \n",
       "28              0.791667              0.708333              0.750000   \n",
       "29              0.812500              0.770833              0.729167   \n",
       "30              0.812500              0.708333              0.708333   \n",
       "31              0.791667              0.833333              0.750000   \n",
       "32              0.791667              0.791667              0.750000   \n",
       "33              0.791667              0.708333              0.729167   \n",
       "34              0.791667              0.791667              0.770833   \n",
       "35              0.770833              0.833333              0.729167   \n",
       "36              0.791667              0.708333              0.729167   \n",
       "37              0.770833              0.687500              0.770833   \n",
       "38              0.770833              0.729167              0.750000   \n",
       "39              0.812500              0.750000              0.750000   \n",
       "\n",
       "    split3_test_accuracy  split4_test_accuracy  mean_test_accuracy  \\\n",
       "0               0.812500              0.829787            0.840957   \n",
       "1               0.791667              0.765957            0.799025   \n",
       "2               0.750000              0.765957            0.790691   \n",
       "3               0.791667              0.765957            0.765691   \n",
       "4               0.729167              0.787234            0.749113   \n",
       "5               0.750000              0.808511            0.749202   \n",
       "6               0.791667              0.744681            0.744770   \n",
       "7               0.729167              0.765957            0.728191   \n",
       "8               0.729167              0.765957            0.719858   \n",
       "9               0.708333              0.787234            0.724113   \n",
       "10              0.791667              0.808511            0.736702   \n",
       "11              0.750000              0.851064            0.749379   \n",
       "12              0.770833              0.829787            0.753457   \n",
       "13              0.750000              0.787234            0.728280   \n",
       "14              0.750000              0.765957            0.736525   \n",
       "15              0.708333              0.765957            0.715691   \n",
       "16              0.791667              0.765957            0.724025   \n",
       "17              0.750000              0.787234            0.744947   \n",
       "18              0.770833              0.787234            0.736613   \n",
       "19              0.750000              0.808511            0.732535   \n",
       "20              0.812500              0.829787            0.840957   \n",
       "21              0.791667              0.829787            0.828457   \n",
       "22              0.791667              0.787234            0.819947   \n",
       "23              0.833333              0.787234            0.803280   \n",
       "24              0.812500              0.787234            0.774113   \n",
       "25              0.791667              0.787234            0.778280   \n",
       "26              0.770833              0.765957            0.769858   \n",
       "27              0.770833              0.765957            0.778191   \n",
       "28              0.791667              0.765957            0.761525   \n",
       "29              0.791667              0.787234            0.778280   \n",
       "30              0.791667              0.765957            0.757358   \n",
       "31              0.770833              0.787234            0.786613   \n",
       "32              0.770833              0.765957            0.774025   \n",
       "33              0.791667              0.787234            0.761613   \n",
       "34              0.770833              0.765957            0.778191   \n",
       "35              0.791667              0.787234            0.782447   \n",
       "36              0.770833              0.765957            0.753191   \n",
       "37              0.791667              0.787234            0.761613   \n",
       "38              0.812500              0.765957            0.765691   \n",
       "39              0.791667              0.787234            0.778280   \n",
       "\n",
       "    std_test_accuracy  rank_test_accuracy  split0_test_precision  \\\n",
       "0            0.043059                   1               0.900000   \n",
       "1            0.060308                   6               0.900000   \n",
       "2            0.054734                   7               0.909091   \n",
       "3            0.048188                  18               0.684211   \n",
       "4            0.050333                  28               0.666667   \n",
       "5            0.056581                  27               0.647059   \n",
       "6            0.072618                  30               0.666667   \n",
       "7            0.075178                  36               0.625000   \n",
       "8            0.064631                  39               0.647059   \n",
       "9            0.075389                  37               0.625000   \n",
       "10           0.078975                  31               0.647059   \n",
       "11           0.091538                  26               0.666667   \n",
       "12           0.079892                  24               0.687500   \n",
       "13           0.076126                  35               0.647059   \n",
       "14           0.070029                  33               0.714286   \n",
       "15           0.060400                  40               0.625000   \n",
       "16           0.086308                  38               0.687500   \n",
       "17           0.073303                  29               0.687500   \n",
       "18           0.067269                  32               0.625000   \n",
       "19           0.072990                  34               0.666667   \n",
       "20           0.043059                   1               0.900000   \n",
       "21           0.033275                   3               0.900000   \n",
       "22           0.037072                   4               0.909091   \n",
       "23           0.041134                   5               0.684211   \n",
       "24           0.030184                  15               0.647059   \n",
       "25           0.036061                  10               0.666667   \n",
       "26           0.022905                  17               0.714286   \n",
       "27           0.021713                  13               0.714286   \n",
       "28           0.030980                  22               0.666667   \n",
       "29           0.027921                  10               0.687500   \n",
       "30           0.042658                  23               0.714286   \n",
       "31           0.027562                   8               0.692308   \n",
       "32           0.015968                  16               0.666667   \n",
       "33           0.035649                  20               0.666667   \n",
       "34           0.011146                  13               0.666667   \n",
       "35           0.033678                   9               0.642857   \n",
       "36           0.030146                  25               0.666667   \n",
       "37           0.038006                  20               0.642857   \n",
       "38           0.027560                  18               0.642857   \n",
       "39           0.024617                  10               0.714286   \n",
       "\n",
       "    split1_test_precision  split2_test_precision  split3_test_precision  \\\n",
       "0                1.000000               0.714286               0.818182   \n",
       "1                0.764706               0.550000               0.687500   \n",
       "2                0.769231               0.615385               0.666667   \n",
       "3                0.615385               0.533333               0.714286   \n",
       "4                0.615385               0.500000               0.615385   \n",
       "5                0.636364               0.470588               0.642857   \n",
       "6                0.692308               0.421053               0.687500   \n",
       "7                0.692308               0.388889               0.600000   \n",
       "8                0.538462               0.421053               0.600000   \n",
       "9                0.642857               0.388889               0.571429   \n",
       "10               0.500000               0.421053               0.687500   \n",
       "11               0.600000               0.388889               0.625000   \n",
       "12               0.615385               0.421053               0.666667   \n",
       "13               0.571429               0.388889               0.625000   \n",
       "14               0.615385               0.421053               0.625000   \n",
       "15               0.571429               0.421053               0.571429   \n",
       "16               0.466667               0.388889               0.687500   \n",
       "17               0.666667               0.421053               0.625000   \n",
       "18               0.615385               0.421053               0.666667   \n",
       "19               0.538462               0.421053               0.625000   \n",
       "20               1.000000               0.714286               0.818182   \n",
       "21               0.764706               0.714286               0.687500   \n",
       "22               0.785714               0.687500               0.714286   \n",
       "23               0.769231               0.636364               0.785714   \n",
       "24               0.562500               0.642857               0.818182   \n",
       "25               0.800000               0.583333               0.750000   \n",
       "26               0.615385               0.642857               0.692308   \n",
       "27               0.666667               0.642857               0.692308   \n",
       "28               0.533333               0.642857               0.750000   \n",
       "29               0.625000               0.615385               0.714286   \n",
       "30               0.526316               0.583333               0.714286   \n",
       "31               0.769231               0.642857               0.692308   \n",
       "32               0.692308               0.642857               0.692308   \n",
       "33               0.526316               0.615385               0.750000   \n",
       "34               0.666667               0.666667               0.692308   \n",
       "35               0.769231               0.615385               0.750000   \n",
       "36               0.538462               0.615385               0.666667   \n",
       "37               0.500000               0.666667               0.714286   \n",
       "38               0.571429               0.642857               0.769231   \n",
       "39               0.615385               0.642857               0.714286   \n",
       "\n",
       "    split4_test_precision  mean_test_precision  std_test_precision  \\\n",
       "0                0.769231             0.840340            0.100487   \n",
       "1                0.611111             0.702663            0.122237   \n",
       "2                0.625000             0.717075            0.110408   \n",
       "3                0.625000             0.634443            0.062494   \n",
       "4                0.631579             0.605803            0.056119   \n",
       "5                0.650000             0.609374            0.069544   \n",
       "6                0.578947             0.609295            0.102620   \n",
       "7                0.611111             0.583462            0.102440   \n",
       "8                0.611111             0.563537            0.079372   \n",
       "9                0.631579             0.571951            0.094773   \n",
       "10               0.666667             0.584456            0.105004   \n",
       "11               0.722222             0.600556            0.113643   \n",
       "12               0.684211             0.614963            0.100331   \n",
       "13               0.631579             0.572791            0.095414   \n",
       "14               0.611111             0.597367            0.095952   \n",
       "15               0.600000             0.557782            0.071229   \n",
       "16               0.600000             0.566111            0.119930   \n",
       "17               0.631579             0.606360            0.095439   \n",
       "18               0.647059             0.595033            0.088791   \n",
       "19               0.666667             0.583570            0.093780   \n",
       "20               0.769231             0.840340            0.100487   \n",
       "21               0.769231             0.767144            0.073210   \n",
       "22               0.631579             0.745634            0.095599   \n",
       "23               0.631579             0.701420            0.064977   \n",
       "24               0.666667             0.667453            0.083374   \n",
       "25               0.647059             0.689412            0.076765   \n",
       "26               0.625000             0.657967            0.038677   \n",
       "27               0.625000             0.668223            0.032298   \n",
       "28               0.625000             0.643571            0.069797   \n",
       "29               0.647059             0.657846            0.037585   \n",
       "30               0.625000             0.632644            0.073656   \n",
       "31               0.647059             0.688752            0.045490   \n",
       "32               0.625000             0.663828            0.026749   \n",
       "33               0.666667             0.645007            0.073385   \n",
       "34               0.625000             0.663462            0.021644   \n",
       "35               0.666667             0.688828            0.060341   \n",
       "36               0.625000             0.622436            0.046948   \n",
       "37               0.666667             0.638095            0.072843   \n",
       "38               0.625000             0.650275            0.064986   \n",
       "39               0.647059             0.666774            0.040290   \n",
       "\n",
       "    rank_test_precision  split0_test_recall  split1_test_recall  \\\n",
       "0                     1            0.600000            0.733333   \n",
       "1                     6            0.600000            0.866667   \n",
       "2                     5            0.666667            0.666667   \n",
       "3                    22            0.866667            0.533333   \n",
       "4                    29            0.800000            0.533333   \n",
       "5                    26            0.733333            0.466667   \n",
       "6                    27            0.666667            0.600000   \n",
       "7                    35            0.666667            0.600000   \n",
       "8                    39            0.733333            0.466667   \n",
       "9                    37            0.666667            0.600000   \n",
       "10                   33            0.733333            0.533333   \n",
       "11                   30            0.800000            0.600000   \n",
       "12                   25            0.733333            0.533333   \n",
       "13                   36            0.733333            0.533333   \n",
       "14                   31            0.666667            0.533333   \n",
       "15                   40            0.666667            0.533333   \n",
       "16                   38            0.733333            0.466667   \n",
       "17                   28            0.733333            0.533333   \n",
       "18                   32            0.666667            0.533333   \n",
       "19                   34            0.666667            0.466667   \n",
       "20                    1            0.600000            0.733333   \n",
       "21                    3            0.600000            0.866667   \n",
       "22                    4            0.666667            0.733333   \n",
       "23                    7            0.866667            0.666667   \n",
       "24                   12            0.733333            0.600000   \n",
       "25                    8            0.666667            0.533333   \n",
       "26                   16            0.666667            0.533333   \n",
       "27                   11            0.666667            0.666667   \n",
       "28                   20            0.666667            0.533333   \n",
       "29                   17            0.733333            0.666667   \n",
       "30                   23            0.666667            0.666667   \n",
       "31                   10            0.600000            0.666667   \n",
       "32                   14            0.666667            0.600000   \n",
       "33                   19            0.666667            0.666667   \n",
       "34                   15            0.666667            0.666667   \n",
       "35                    9            0.600000            0.666667   \n",
       "36                   24            0.666667            0.466667   \n",
       "37                   21            0.600000            0.533333   \n",
       "38                   18            0.600000            0.533333   \n",
       "39                   13            0.666667            0.533333   \n",
       "\n",
       "    split2_test_recall  split3_test_recall  split4_test_recall  \\\n",
       "0               0.6250              0.5625            0.666667   \n",
       "1               0.6875              0.6875            0.733333   \n",
       "2               0.5000              0.5000            0.666667   \n",
       "3               0.5000              0.6250            0.666667   \n",
       "4               0.4375              0.5000            0.800000   \n",
       "5               0.5000              0.5625            0.866667   \n",
       "6               0.5000              0.6875            0.733333   \n",
       "7               0.4375              0.5625            0.733333   \n",
       "8               0.5000              0.5625            0.733333   \n",
       "9               0.4375              0.5000            0.800000   \n",
       "10              0.5000              0.6875            0.800000   \n",
       "11              0.4375              0.6250            0.866667   \n",
       "12              0.5000              0.6250            0.866667   \n",
       "13              0.4375              0.6250            0.800000   \n",
       "14              0.5000              0.6250            0.733333   \n",
       "15              0.5000              0.5000            0.800000   \n",
       "16              0.4375              0.6875            0.800000   \n",
       "17              0.5000              0.6250            0.800000   \n",
       "18              0.5000              0.6250            0.733333   \n",
       "19              0.5000              0.6250            0.800000   \n",
       "20              0.6250              0.5625            0.666667   \n",
       "21              0.6250              0.6875            0.666667   \n",
       "22              0.6875              0.6250            0.800000   \n",
       "23              0.4375              0.6875            0.800000   \n",
       "24              0.5625              0.5625            0.666667   \n",
       "25              0.4375              0.5625            0.733333   \n",
       "26              0.5625              0.5625            0.666667   \n",
       "27              0.5625              0.5625            0.666667   \n",
       "28              0.5625              0.5625            0.666667   \n",
       "29              0.5000              0.6250            0.733333   \n",
       "30              0.4375              0.6250            0.666667   \n",
       "31              0.5625              0.5625            0.733333   \n",
       "32              0.5625              0.5625            0.666667   \n",
       "33              0.5000              0.5625            0.666667   \n",
       "34              0.6250              0.5625            0.666667   \n",
       "35              0.5000              0.5625            0.666667   \n",
       "36              0.5000              0.6250            0.666667   \n",
       "37              0.6250              0.6250            0.666667   \n",
       "38              0.5625              0.6250            0.666667   \n",
       "39              0.5625              0.6250            0.733333   \n",
       "\n",
       "    mean_test_recall  std_test_recall  rank_test_recall  split0_test_f1  \\\n",
       "0           0.637500         0.058689                11        0.720000   \n",
       "1           0.715000         0.087266                 1        0.720000   \n",
       "2           0.600000         0.081650                33        0.769231   \n",
       "3           0.638333         0.129056                 9        0.764706   \n",
       "4           0.614167         0.154821                22        0.727273   \n",
       "5           0.625833         0.151483                15        0.687500   \n",
       "6           0.637500         0.081052                11        0.666667   \n",
       "7           0.600000         0.100035                31        0.645161   \n",
       "8           0.599167         0.113786                34        0.687500   \n",
       "9           0.600833         0.127159                30        0.645161   \n",
       "10          0.650833         0.115722                 8        0.687500   \n",
       "11          0.665833         0.152625                 5        0.727273   \n",
       "12          0.651667         0.134619                 6        0.709677   \n",
       "13          0.625833         0.131085                16        0.687500   \n",
       "14          0.611667         0.085570                25        0.689655   \n",
       "15          0.600000         0.117379                31        0.645161   \n",
       "16          0.625000         0.145940                17        0.709677   \n",
       "17          0.638333         0.114455                 9        0.709677   \n",
       "18          0.611667         0.085570                25        0.645161   \n",
       "19          0.611667         0.120139                25        0.666667   \n",
       "20          0.637500         0.058689                11        0.720000   \n",
       "21          0.689167         0.093897                 4        0.720000   \n",
       "22          0.702500         0.059954                 2        0.769231   \n",
       "23          0.691667         0.146700                 3        0.764706   \n",
       "24          0.625000         0.066196                19        0.687500   \n",
       "25          0.586667         0.103528                39        0.666667   \n",
       "26          0.598333         0.056801                36        0.689655   \n",
       "27          0.625000         0.051031                19        0.689655   \n",
       "28          0.598333         0.056801                36        0.666667   \n",
       "29          0.651667         0.086346                 6        0.709677   \n",
       "30          0.612500         0.088976                23        0.689655   \n",
       "31          0.625000         0.066196                17        0.642857   \n",
       "32          0.611667         0.046949                28        0.666667   \n",
       "33          0.612500         0.069222                23        0.666667   \n",
       "34          0.637500         0.040825                11        0.666667   \n",
       "35          0.599167         0.063705                35        0.620690   \n",
       "36          0.585000         0.085049                40        0.666667   \n",
       "37          0.610000         0.043906                29        0.620690   \n",
       "38          0.597500         0.046667                38        0.620690   \n",
       "39          0.624167         0.071802                21        0.689655   \n",
       "\n",
       "    split1_test_f1  split2_test_f1  split3_test_f1  split4_test_f1  \\\n",
       "0         0.846154        0.666667        0.666667        0.714286   \n",
       "1         0.812500        0.611111        0.687500        0.666667   \n",
       "2         0.714286        0.551724        0.571429        0.645161   \n",
       "3         0.571429        0.516129        0.666667        0.645161   \n",
       "4         0.571429        0.466667        0.551724        0.705882   \n",
       "5         0.538462        0.484848        0.600000        0.742857   \n",
       "6         0.642857        0.457143        0.687500        0.647059   \n",
       "7         0.642857        0.411765        0.580645        0.666667   \n",
       "8         0.500000        0.457143        0.580645        0.666667   \n",
       "9         0.620690        0.411765        0.533333        0.705882   \n",
       "10        0.516129        0.457143        0.687500        0.727273   \n",
       "11        0.600000        0.411765        0.625000        0.787879   \n",
       "12        0.571429        0.457143        0.645161        0.764706   \n",
       "13        0.551724        0.411765        0.625000        0.705882   \n",
       "14        0.571429        0.457143        0.625000        0.666667   \n",
       "15        0.551724        0.457143        0.533333        0.685714   \n",
       "16        0.466667        0.411765        0.687500        0.685714   \n",
       "17        0.592593        0.457143        0.625000        0.705882   \n",
       "18        0.571429        0.457143        0.645161        0.687500   \n",
       "19        0.500000        0.457143        0.625000        0.727273   \n",
       "20        0.846154        0.666667        0.666667        0.714286   \n",
       "21        0.812500        0.666667        0.687500        0.714286   \n",
       "22        0.758621        0.687500        0.666667        0.705882   \n",
       "23        0.714286        0.518519        0.733333        0.705882   \n",
       "24        0.580645        0.600000        0.666667        0.666667   \n",
       "25        0.640000        0.500000        0.642857        0.687500   \n",
       "26        0.571429        0.600000        0.620690        0.645161   \n",
       "27        0.666667        0.600000        0.620690        0.645161   \n",
       "28        0.533333        0.600000        0.642857        0.645161   \n",
       "29        0.645161        0.551724        0.666667        0.687500   \n",
       "30        0.588235        0.500000        0.666667        0.645161   \n",
       "31        0.714286        0.600000        0.620690        0.687500   \n",
       "32        0.642857        0.600000        0.620690        0.645161   \n",
       "33        0.588235        0.551724        0.642857        0.666667   \n",
       "34        0.666667        0.645161        0.620690        0.645161   \n",
       "35        0.714286        0.551724        0.642857        0.666667   \n",
       "36        0.500000        0.551724        0.645161        0.645161   \n",
       "37        0.516129        0.645161        0.666667        0.666667   \n",
       "38        0.551724        0.600000        0.689655        0.645161   \n",
       "39        0.571429        0.600000        0.666667        0.687500   \n",
       "\n",
       "    mean_test_f1  std_test_f1  rank_test_f1  split0_test_roc_auc  \\\n",
       "0       0.722755     0.065724             1             0.784848   \n",
       "1       0.699556     0.066669             5             0.925253   \n",
       "2       0.650366     0.082708             9             0.913131   \n",
       "3       0.632818     0.084944            16             0.862626   \n",
       "4       0.604595     0.098213            30             0.797980   \n",
       "5       0.610733     0.094377            29             0.771717   \n",
       "6       0.620245     0.083079            24             0.752525   \n",
       "7       0.589419     0.093347            37             0.742424   \n",
       "8       0.578391     0.090054            39             0.775758   \n",
       "9       0.583366     0.102149            38             0.742424   \n",
       "10      0.615109     0.107529            28             0.775758   \n",
       "11      0.630383     0.128793            17             0.809091   \n",
       "12      0.629623     0.107734            18             0.790909   \n",
       "13      0.596374     0.106948            34             0.775758   \n",
       "14      0.601979     0.082840            31             0.772727   \n",
       "15      0.574615     0.081667            40             0.742424   \n",
       "16      0.592265     0.126446            36             0.790909   \n",
       "17      0.618059     0.092410            25             0.790909   \n",
       "18      0.601279     0.081181            33             0.742424   \n",
       "19      0.595216     0.101550            35             0.757576   \n",
       "20      0.722755     0.065724             1             0.784848   \n",
       "21      0.720190     0.049979             3             0.925253   \n",
       "22      0.717580     0.039965             4             0.913131   \n",
       "23      0.687345     0.086800             6             0.881818   \n",
       "24      0.640296     0.041955            13             0.842424   \n",
       "25      0.627405     0.066004            19             0.801010   \n",
       "26      0.625387     0.040248            20             0.767677   \n",
       "27      0.644435     0.031868            11             0.772727   \n",
       "28      0.617604     0.047362            27             0.757576   \n",
       "29      0.652146     0.054597             8             0.790909   \n",
       "30      0.617944     0.067898            26             0.772727   \n",
       "31      0.653067     0.042195             7             0.739394   \n",
       "32      0.635075     0.022793            15             0.757576   \n",
       "33      0.623230     0.045818            21             0.757576   \n",
       "34      0.648869     0.017059            10             0.757576   \n",
       "35      0.639245     0.053666            14             0.724242   \n",
       "36      0.601743     0.064558            32             0.757576   \n",
       "37      0.623063     0.056092            22             0.724242   \n",
       "38      0.621446     0.045905            23             0.724242   \n",
       "39      0.643050     0.048350            12             0.772727   \n",
       "\n",
       "    split1_test_roc_auc  split2_test_roc_auc  split3_test_roc_auc  \\\n",
       "0              0.866667             0.750000             0.750000   \n",
       "1              0.917172             0.654297             0.784180   \n",
       "2              0.753535             0.685547             0.736328   \n",
       "3              0.649495             0.472656             0.834961   \n",
       "4              0.594949             0.520508             0.772461   \n",
       "5              0.723232             0.546875             0.749023   \n",
       "6              0.739394             0.578125             0.765625   \n",
       "7              0.739394             0.546875             0.687500   \n",
       "8              0.642424             0.578125             0.687500   \n",
       "9              0.724242             0.546875             0.656250   \n",
       "10             0.645455             0.578125             0.765625   \n",
       "11             0.709091             0.546875             0.718750   \n",
       "12             0.690909             0.578125             0.734375   \n",
       "13             0.675758             0.546875             0.718750   \n",
       "14             0.690909             0.578125             0.718750   \n",
       "15             0.675758             0.578125             0.656250   \n",
       "16             0.612121             0.546875             0.765625   \n",
       "17             0.706061             0.578125             0.718750   \n",
       "18             0.690909             0.578125             0.734375   \n",
       "19             0.642424             0.578125             0.718750   \n",
       "20             0.866667             0.750000             0.750000   \n",
       "21             0.917172             0.777344             0.795898   \n",
       "22             0.819192             0.804688             0.783203   \n",
       "23             0.732323             0.792969             0.767578   \n",
       "24             0.630303             0.697266             0.766602   \n",
       "25             0.763636             0.666992             0.786133   \n",
       "26             0.690909             0.703125             0.718750   \n",
       "27             0.757576             0.703125             0.718750   \n",
       "28             0.660606             0.703125             0.734375   \n",
       "29             0.742424             0.671875             0.750000   \n",
       "30             0.696970             0.640625             0.750000   \n",
       "31             0.787879             0.703125             0.718750   \n",
       "32             0.739394             0.703125             0.718750   \n",
       "33             0.696970             0.671875             0.734375   \n",
       "34             0.757576             0.734375             0.718750   \n",
       "35             0.787879             0.671875             0.734375   \n",
       "36             0.642424             0.671875             0.734375   \n",
       "37             0.645455             0.734375             0.750000   \n",
       "38             0.675758             0.703125             0.765625   \n",
       "39             0.690909             0.703125             0.750000   \n",
       "\n",
       "    split4_test_roc_auc  mean_test_roc_auc  std_test_roc_auc  \\\n",
       "0              0.786458           0.787595          0.042633   \n",
       "1              0.807292           0.817638          0.099393   \n",
       "2              0.855208           0.788750          0.083098   \n",
       "3              0.796875           0.723323          0.145302   \n",
       "4              0.809375           0.699055          0.118374   \n",
       "5              0.821875           0.722545          0.093644   \n",
       "6              0.741667           0.715467          0.069298   \n",
       "7              0.757292           0.694697          0.077585   \n",
       "8              0.757292           0.688220          0.073010   \n",
       "9              0.790625           0.692083          0.084437   \n",
       "10             0.806250           0.714242          0.087349   \n",
       "11             0.855208           0.727803          0.105837   \n",
       "12             0.839583           0.726780          0.089755   \n",
       "13             0.790625           0.701553          0.087552   \n",
       "14             0.757292           0.703561          0.068987   \n",
       "15             0.775000           0.685511          0.068892   \n",
       "16             0.775000           0.698106          0.099346   \n",
       "17             0.790625           0.716894          0.077836   \n",
       "18             0.772917           0.703750          0.068065   \n",
       "19             0.806250           0.700625          0.081391   \n",
       "20             0.786458           0.787595          0.042633   \n",
       "21             0.821875           0.847508          0.061872   \n",
       "22             0.850000           0.834043          0.045114   \n",
       "23             0.860417           0.807021          0.056176   \n",
       "24             0.852083           0.757736          0.084909   \n",
       "25             0.777083           0.758971          0.047571   \n",
       "26             0.739583           0.724009          0.027235   \n",
       "27             0.739583           0.738352          0.025211   \n",
       "28             0.739583           0.719053          0.034088   \n",
       "29             0.772917           0.745625          0.040654   \n",
       "30             0.739583           0.719981          0.046679   \n",
       "31             0.772917           0.744413          0.031907   \n",
       "32             0.739583           0.731686          0.018842   \n",
       "33             0.755208           0.723201          0.033626   \n",
       "34             0.739583           0.741572          0.014757   \n",
       "35             0.755208           0.734716          0.038223   \n",
       "36             0.739583           0.709167          0.044157   \n",
       "37             0.755208           0.721856          0.039759   \n",
       "38             0.739583           0.721667          0.030697   \n",
       "39             0.772917           0.737936          0.034650   \n",
       "\n",
       "    rank_test_roc_auc  \n",
       "0                   6  \n",
       "1                   3  \n",
       "2                   5  \n",
       "3                  20  \n",
       "4                  35  \n",
       "5                  22  \n",
       "6                  28  \n",
       "7                  37  \n",
       "8                  39  \n",
       "9                  38  \n",
       "10                 29  \n",
       "11                 17  \n",
       "12                 18  \n",
       "13                 33  \n",
       "14                 32  \n",
       "15                 40  \n",
       "16                 36  \n",
       "17                 27  \n",
       "18                 31  \n",
       "19                 34  \n",
       "20                  6  \n",
       "21                  1  \n",
       "22                  2  \n",
       "23                  4  \n",
       "24                  9  \n",
       "25                  8  \n",
       "26                 19  \n",
       "27                 13  \n",
       "28                 26  \n",
       "29                 10  \n",
       "30                 25  \n",
       "31                 11  \n",
       "32                 16  \n",
       "33                 21  \n",
       "34                 12  \n",
       "35                 15  \n",
       "36                 30  \n",
       "37                 23  \n",
       "38                 24  \n",
       "39                 14  "
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "dt_params = {\n",
    "    'criterion': ['gini', 'entropy'], \n",
    "    'max_depth': range(1,21)\n",
    "    # Needs to be expanded with more parameters\n",
    "}\n",
    "dt_grid = GridSearchCV(DecisionTreeClassifier(), dt_params, scoring=metrics, refit='f1')\n",
    "\n",
    "dt_grid.fit(trainval_features, trainval_targets)\n",
    "\n",
    "dt_cv_results = pd.DataFrame(dt_grid.cv_results_)\n",
    "dt_cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7a7f509b3790>"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(dt_cv_results['param_max_depth'], dt_cv_results['mean_test_f1'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observations\n",
    "* This model is overfitted as well, but not to the same extent as the dt1 \n",
    "* Like the first model, the model has better precision than recall, but here the tendency is much greater and we can see the trend in both the training and test results\n",
    "* dt2 performs better than dt1 in all metrics (the same for recall) for validation data i.e. we must assume it is the best of the two"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[38,  3],\n",
       "       [ 5, 14]])"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate the confusion matrix for the best decision tree model.\n",
    "\n",
    "confusion_matrix(test_targets, dt_grid.predict(test_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7a7f50998c50>"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# The ConfusionMatrixDisplay class can be used to make confusion matrix plots\n",
    "\n",
    "ConfusionMatrixDisplay.from_estimator(dt_grid, test_features, test_targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The confusion matrix show that dt2 is very accurate in it's predictions (precision), only two false positives. There are however 9 false negatives i.e. 9 failures that wasn't predicted. This could have dramatic consequences in practice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.roc_curve.RocCurveDisplay at 0x7a7f5085d950>"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjcAAAGwCAYAAABVdURTAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAABjAElEQVR4nO3deViUVfsH8O8MMMMiDCCyj+K+pIIrSYuvhpGVmZZabmhmb+5pWu5LlpqmaWn6uuRSmqW/MlNzwyU1l1wwFcRUFFBAkU12mDm/P3AmxwGcgRlGhu/nurhqzpznmXselrk9zznnlgghBIiIiIishNTSARARERGZEpMbIiIisipMboiIiMiqMLkhIiIiq8LkhoiIiKwKkxsiIiKyKkxuiIiIyKrYWjqAyqZWq3H79m04OztDIpFYOhwiIiIygBAC9+/fh6+vL6TSssdmql1yc/v2bSiVSkuHQUREROUQHx8Pf3//MvtUu+TG2dkZQPHFcXFxsXA0REREZIjMzEwolUrt53hZql1yo7kV5eLiwuSGiIioijFkSgknFBMREZFVYXJDREREVoXJDREREVkVJjdERERkVZjcEBERkVVhckNERERWhckNERERWRUmN0RERGRVmNwQERGRVWFyQ0RERFbFosnNH3/8gW7dusHX1xcSiQTbtm177DGHDh1C69atIZfL0aBBA6xbt87scRIREVHVYdHkJjs7G4GBgVi2bJlB/WNjY/HKK6+gU6dOiIyMxAcffIB3330Xe/bsMXOkREREVFVYtHBm165d0bVrV4P7r1ixAnXr1sXChQsBAE2bNsXRo0fx5ZdfIiwszFxhEhERkYHuZOYhK78I9WrVsFgMVaoq+PHjxxEaGqrTFhYWhg8++KDUY/Lz85Gfn699nJmZaa7wiIiIqpWs/CJcSMjA+YR0nI9PR2R8OhIz8tCpcS2sHdzeYnFVqeQmKSkJXl5eOm1eXl7IzMxEbm4uHBwc9I6ZO3cuZs2aVVkhEhERWaVClRoxSfdxPiEdkXHpOJ+Qjn/uZEEI3X4SCZBbqLJMkA9UqeSmPCZNmoRx48ZpH2dmZkKpVFowIiIioiebEALxqbmIfCiRuXgrA/lFar2+vgp7BCpdEaR0RaDSFc39FKght2x6UaWSG29vbyQnJ+u0JScnw8XFpcRRGwCQy+WQy+WVER4REVGVlJpdoL2tpLnFlJZTqNfP2d62OInxL05kAv0V8HSxt0DEZatSyU2HDh2wa9cunbZ9+/ahQ4cOFoqIiIioasktUOHS7YwHiUwGzsenIy41R6+fzEaKpr4uCPJXFCcySlfUrekEqVRigaiNY9HkJisrC1evXtU+jo2NRWRkJNzd3VG7dm1MmjQJt27dwoYNGwAA77//PpYuXYqPPvoI77zzDg4cOICffvoJO3futNRbICIiemKp1AJX72QVj8o8GJG5nHQfKrXQ61uvlhOCNCMySlc09XGG3NbGAlFXnEWTm9OnT6NTp07ax5q5MeHh4Vi3bh0SExMRFxenfb5u3brYuXMnxo4diyVLlsDf3x+rV6/mMnAiIqr2hBBIzMjTJjKRcem4cCsDOQX6k3s9asgRpHRFkFKBIKUbWvgroHCws0DU5iER4tF5ztYtMzMTCoUCGRkZcHFxsXQ4RERE5ZKRW4gLCRmIjE9DZHzxcuy79/P1+jnKbNDywa0lzciMj8IeEsmTf3vpYcZ8flepOTdERETVUX6RCtGJ93E+Pl07MnP9brZePxupBE28nXUSmQaeNWBTBebJmBKTGyIioieIWi0Qey/7oUQmA9G3M1Gg0l+GXdvdUbtqKUjpiqd8FXCQVc15MqbE5IaIiMiC7tzPw/n4DJ2l2PfzivT6uTnaPUhkXBFUu/i/7k4yC0T85GNyQ0REVEmy84tw4daDZdgPvm5n5On1k9tK0dxPod0YL8jfFUp3hyo3T8ZSmNwQERGZwcPlCooTmQz8c+c+Hl2FLZEAjTydEahUaEdmGns7w85GapnArQCTGyIiogp6uFyBZkTm4u0M5BWWXq5Ak8i08Ld8uQJrw6tJRERkpNTsgodGZIp3+k3NLtDr52xv+6BUQfF+Mk9quQJrw+SGiIioDHmFxeUKzsWVXa7AzkaCZj4u2nkyValcgbVhckNERPRAdS1XYG2Y3BARUbX0aLmC8/HpuJCQgezHlCsIVLqipZ8rFI7WU67A2jC5ISKiakFTruB8QvF+MpHxpZcraPHwMuwqWq6gOmNyQ0REVie/SIXLicXLsCPjyi5X0NiruFxBK2X1LVdgbZjcEBFRlaZWC9y4l63dGK+scgVKdwftqiWWK7BeTG6IiKhKebhcgWY5dubjyhUoXdHSX4GaNeQWiJgqG5MbIiJ6YmnKFfybyGTgVnquXj9NuQLNnjKtlG4sV1CNMbkhIqInQpFKjZjk+zgfn4HI+LQyyxU09KyhU0CS5QroYUxuiIio0gkhkJCWi3Pxjy9X4KOw/3djPJYrIAPwp4OIiMzO4HIFctsHm+JpbjG5wovlCshITG6IiMikNOUKIh+a9HvzXunlCjQjMoFKV9TzYLkCqjgmN0REVG4qtcC1u1n/LsOOT0dM0n0UlVSuwMPpQSKjQFBtN5YrILNhckNERAYRQiAps7hcgWauTNnlCv7d5ZflCqgyMbkhIqISZeYVlyvQlCo4H5+OOwaUKwhUusKX5QrIgpjcEBERCorUiE7M1NZdOh+fjmuPKVegKSLZ0NOZ5QroicLkhoiomtGUK9BsihcZn46oMsoVaHb4ZbkCqiqY3BARWbm79/O1q5Y0ozIllStwdbTTSWRYroCqKiY3RERWJDu/CBdvFY/GGFOuIEjpitrujpwnQ1aByQ0RURX1cLkCzcjMleSyyxUEPhiVYbkCsmZMboiIqgBNuYJI7Q6/6bhwq/RyBZpEJlCpQEt/V5YroGqFP+1ERE+gNG25ggxt2YJ7pZQraPmgVIFmKTbLFVB1x+SGiMjCissVZGp3+GW5AqKKYXJDRFSJVGqB63ez/q2GnZCOy4mPL1cQqHRFUx8X2NtxGTbR4zC5ISIyo8SM3AcjMsWTfi/cykBWvv4ybI8asuLbSg9GZFr6K+DqKLNAxERVH5MbIiITebhcgWZUJjlTv1yBg50NWvgrtMlMUG2WKyAyJSY3RETlUFCkxuWkTJ0ikqWVK2jk5axTRLJBrRqw5TJsIrNhckNE9BhCCNy4l4PI+LTHlivwd3PQ7vAbqHTFU74ucJTxTy1RZeJvHBHRIx4tV/B3QgYycgv1+mnKFWiKSLb0d4UHyxUQWRyTGyKq1jTlCh4uIllSuQKZrRTNfV20O/wG+ruiTk2WKyB6EjG5IaJqo0ilxpXkLO2meJHxpZcraFCrxoMdfl3RSumKRl7OkNlyngxRVcDkhoiskqZcwfmEdETGlV2uwNvFXjtHJlCpQAs/BZzt7SwQNRGZQrmSm7i4ONy8eRM5OTmoVasWnnrqKcjlvM9MRJZTnnIFmp1+vRUsV0BkTQxObm7cuIHly5dj8+bNSEhIgBD/juPKZDI899xzeO+99/DGG29AKuXQLRGZz8PlCjSJzI1SyhU09XHRmfRbz6MGyxUQWTmJeDhLKcXo0aOxfv16hIWFoVu3bmjfvj18fX3h4OCA1NRUXLx4EUeOHMHmzZthY2ODtWvXol27dpURv9EyMzOhUCiQkZEBFxcXS4dDRI+hVgtcu5ulrbkUGV96uYK6Hk7aUgVBLFdAZFWM+fw2aOTGyckJ169fR82aNfWe8/T0ROfOndG5c2fMmDEDu3fvRnx8/BOb3BDRky0pIw+RmgKSjylX8HAlbJYrICINg0ZurAlHboieHOUtVxCoVMDP1YHLsImqEZOP3BARVdTD5QoiH0z6vXY3C4/+80oqARp7uyDooUm/DT1ZroCIDGey5CY6OhqvvPIKrl+/bqpTElEVpSlXoNlL5nxCOi7dzkRBUcnlCgKVrgh6kMg092O5AiKqGJP9BSkoKMDNmzdNdToiqkJSsh6UK3hQRLK0cgUKBzvtZF+WKyAiczE4uRk3blyZz9+9e7fCwRDRky+noAgXb2VqR2VYroCInjQGJzdLlixBUFBQqZN4srKyTBYUET0ZilRq/HMnSzvh19ByBUH+rmjszXIFRGQZBic3DRo0wNixY9G/f/8Sn4+MjESbNm1MFhgRVa6HyxUU32LKwIVbGcgtVOn19XaxR6BSoU1kWvizXAERPTkMTm7atm2LM2fOlJrcSCQSVLNV5URVWnpOAc4nZGjnypxPSEdKln65ghpyW7R8aGM8lisgoiedwcnNwoULkZ+vv/+ERmBgINRq/ZUQRGR5eYUqRCX+O0+mtHIFttLicgWajfFYroCIqiKDkxtvb29zxkFEJqJWC1xPycK5uHRtIcnoxMzHlisIVLqiGcsVEJEV4GYSRFWcplyBZq7M3wkllyuo6STTjsgUV8NmuQIisk5MboiqkPuacgUPTfpNyszT6+dgZ4MWfgoEKhUIUrqxXAERVStMboieUAVFasQk3dcmMpHxpZcraOTljFa1XVmugIgITG6InghCCNy8l4PzCenauTIsV0BEVD4W/4u4bNkyLFiwAElJSQgMDMTXX3+N9u3bl9p/8eLFWL58OeLi4uDh4YE333wTc+fOhb09l6ZS1fFwuYLIB8uxyyxX8GDSb0t/V9RyZrkCIqKylCu5+eOPP+Do6Ii2bdtq206fPo2cnBw8//zzBp/nxx9/xLhx47BixQoEBwdj8eLFCAsLQ0xMDDw9PfX6b9q0CRMnTsS3336LkJAQXLlyBYMGDYJEIsGiRYvK81aIzE6nXMGDW0wJaSWXK3jK1wWB/praSyxXQERUHhJRjp33pFIpmjRpgqioKG1b06ZNceXKFahU+ruZliY4OBjt2rXD0qVLAQBqtRpKpRKjRo3CxIkT9fqPHDkS0dHRiIiI0LZ9+OGHOHnyJI4ePVria+Tn5+vsz5OZmQmlUomMjIxSS0kQlZemXIFmU7xzcaWXK6hfq0ZxIlOb5QqIiB4nMzMTCoXCoM/vco3cxMbGws5Od6v1iIgIFBbqD6uXpqCgAGfOnMGkSZO0bVKpFKGhoTh+/HiJx4SEhOD777/HqVOn0L59e1y/fh27du3CgAEDSn2duXPnYtasWQbHRWQoIQRupefifHwGIuPTyixX4OUi/3djPH9XNPdXwIXlCoiIzKJcyU2dOnX02nx9fY06R0pKClQqFby8vHTavby8cPny5RKP6du3L1JSUvDss89CCIGioiK8//77mDx5cqmvM2nSJJ2K5pqRGyJjladcgeYWE8sVEBFVHotPKDbGoUOHMGfOHHzzzTcIDg7G1atXMWbMGMyePRvTpk0r8Ri5XA65nBMwyTgPlysoTmQyEJuSrddPU64gUKlAoL8rWtV2ZbkCIiILMyi5cXNzM3hSY2pqqkH9PDw8YGNjg+TkZJ325OTkUks9TJs2DQMGDMC7774LAGjRogWys7Px3nvvYcqUKZBKOV+BjKcpVxAZn6EdkYlOzEShSn86WkBNx38LSLJcARHRE8mg5Gbx4sUmf2GZTIY2bdogIiICr7/+OoDiCcUREREYOXJkicfk5OToJTA2NsUfLKxIToZKziwuV6ApIHkhIQP3DShX0NJPATcnlisgInrSGZTchIeHm+XFx40bh/DwcLRt2xbt27fH4sWLkZ2djcGDBwMABg4cCD8/P8ydOxcA0K1bNyxatAitWrXS3paaNm0aunXrpk1yiB5WnnIFmrky/m4sV0BEVBWVa87NtWvXsHbtWly7dg1LliyBp6cnfv/9d9SuXRtPPfWUwefp06cP7t69i+nTpyMpKQlBQUHYvXu3dpJxXFyczkjN1KlTIZFIMHXqVNy6dQu1atVCt27d8Nlnn5XnbZCVebRcwfn4dFwto1yBdlTG3xWNvFiugIjIWhi9z83hw4fRtWtXPPPMM/jjjz8QHR2NevXqYd68eTh9+jS2bt1qrlhNwph18vTkerhcgeb20sVSyhX4uTo8SGSKi0iyXAERUdVj1n1uJk6ciE8//RTjxo2Ds7Oztr1z587azfiITC0lKx9/J6QjMj4DkfHp+DshHek5LFdARET6jE5uLly4gE2bNum1e3p6IiUlxSRBUfWWW6DCxdsZiIwzrlxBoNIVASxXQERU7Rmd3Li6uiIxMRF169bVaT937hz8/PxMFhhVDyq1wJXk+9ol2JHxGbiSfB+qR+sVAGjg+aBcwYNJv028XViugIiI9Bid3Lz11lv4+OOPsWXLFkgkEqjVahw7dgzjx4/HwIEDzREjWYmHyxVo5spcvJWBnAL9cgWezv+WK2ilZLkCIiIynNHJzZw5czBixAgolUqoVCo0a9YMKpUKffv2xdSpU80RI1VRGTmFOJ+QrjMqk5KVr9fPSWaDlv6u2s3xWK6AiIgqolxVwYHiZdoXL15EVlYWWrVqhYYNG5o6NrPgainzyCtUIVpTriCheNJvaeUKmvg8WIb9YK5MvVo1YMNyBUREVAazVwUHgNq1a2sLUHICZ/VSXK4gW7sE25ByBYEPRmae8mW5AiIiMq9yJTdr1qzBl19+iX/++QcA0LBhQ3zwwQfamk9kXTTlCjSJzN/xJZcrcNeUK/B31RaSZLkCIiKqbEYnN9OnT8eiRYswatQodOjQAQBw/PhxjB07FnFxcfjkk09MHiRVnvt5hbhwK6N40u+DZCYxQ79cgb2dtLhcwUNzZViugIiIngRGz7mpVasWvvrqK7z99ts67T/88ANGjRr1xO91wzk3/ypUPShX8GBUJvIx5QoC/V0RVJvlCoiIqPKZdc5NYWEh2rZtq9fepk0bFBXp36qgJ4MQAnGpOTrVsC/dzkT+Y8oVBPq7ormfAk5ylisgIqKqwehPrAEDBmD58uVYtGiRTvvKlSvRr18/kwVGFXMvK1+7/Fpze6mkcgUu9rba20qB/q5oqVTA05nLsImIqOoyKLkZN26c9v8lEglWr16NvXv34umnnwYAnDx5EnFxcdzEz8KKVGrM2H4Jf/xzF/GpJZQrsJGima+LThFJlisgIiJrY1Byc+7cOZ3Hbdq0AQBcu3YNAODh4QEPDw9cunTJxOGRMf66kYaNJ+O0j+vXctLu8MtyBUREVF0YlNwcPHjQ3HGQCdy8V7xpXvsAd6we1JblCoiIqFriP+OtSFxqDgCgiY8zExsiIqq2yrUE5vTp0/jpp58QFxeHgoICned+/vlnkwRGxtMkN7XdHS0cCRERkeUYPXKzefNmhISEIDo6Gr/88gsKCwtx6dIlHDhwAAqFwhwxkoHimdwQEREZn9zMmTMHX375JX777TfIZDIsWbIEly9fRu/evVG7dm1zxEgG0o7c1GRyQ0RE1ZfRyc21a9fwyiuvAABkMhmys7MhkUgwduxYrFy50uQBkmEy8wqR9mAfG6UbkxsiIqq+jE5u3NzccP/+fQCAn58fLl68CABIT09HTk6OaaMjg2luSXnUkHE3YSIiqtaM/hR8/vnnsW/fPrRo0QK9evXCmDFjcODAAezbtw8vvPCCOWIkA2iSGyXn2xARUTVndHKzdOlS5OUVV4meMmUK7Ozs8Oeff+KNN97A1KlTTR4gGebmPU4mJiIiAsqR3Li7u2v/XyqVYuLEiSYNiMqHy8CJiIiKGZTcZGZmGnzCx5UhJ/OI420pIiIiAAYmN66uro8triiEgEQigUqlMklgZBzNnJs6TG6IiKiaY20pK6BSCySkFVcB5x43RERU3RmU3HTs2NHccVAFJGbkokgtILORwsvZ3tLhEBERWRQLZ1oBzXwbf3cHSKVl3z4kIiKydkxurABrShEREf2LyY0V4B43RERE/2JyYwW4xw0REdG/ypXcFBUVYf/+/fjf//6nrTN1+/ZtZGVlmTQ4MgxLLxAREf3L6B2Kb968iZdeeglxcXHIz89Hly5d4OzsjM8//xz5+flYsWKFOeKkMnDkhoiI6F9Gj9yMGTMGbdu2RVpaGhwcHLTtPXr0QEREhEmDo8fLzCtEWk4hACY3REREQDlGbo4cOYI///wTMplMpz0gIAC3bt0yWWBkGM0tKY8aMjjJjf52EhERWR2jR27UanWJJRYSEhLg7OxskqDIcJxvQ0REpMvo5ObFF1/E4sWLtY8lEgmysrIwY8YMvPzyy6aMjQzA+TZERES6jL6PsXDhQoSFhaFZs2bIy8tD37598c8//8DDwwM//PCDOWKkMjC5ISIi0mV0cuPv74/z589j8+bN+Pvvv5GVlYUhQ4agX79+OhOMqXJoNvDjbSkiIqJiRic3eXl5sLe3R//+/c0RDxmJpReIiIh0GT3nxtPTE+Hh4di3bx/UarU5YiIDqdQCCWm5AJjcEBERaRid3Kxfvx45OTno3r07/Pz88MEHH+D06dPmiI0eIzEjF0VqAZmNFF4u9pYOh4iI6IlgdHLTo0cPbNmyBcnJyZgzZw6ioqLw9NNPo1GjRvjkk0/MESOVQjOZ2N/dATZSiYWjISIiejKUu3Cms7MzBg8ejL179+Lvv/+Gk5MTZs2aZcrY6DE434aIiEhfuZObvLw8/PTTT3j99dfRunVrpKamYsKECaaMjR6Dy8CJiIj0Gb1aas+ePdi0aRO2bdsGW1tbvPnmm9i7dy+ef/55c8RHZYhL5WRiIiKiRxmd3PTo0QOvvvoqNmzYgJdffhl2dnbmiIsMEHcvGwD3uCEiInqY0clNcnIya0g9IXhbioiISJ9ByU1mZiZcXFwAAEIIZGZmltpX04/MKzOvEGk5hQA4ckNERPQwg5IbNzc3JCYmwtPTE66urpBI9JcdCyEgkUhKrBhOpqdZKVXTSYYacqMH4IiIiKyWQZ+KBw4cgLu7OwDg4MGDZg2IDKNJbjhqQ0REpMug5KZjx47a/69bty6USqXe6I0QAvHx8aaNjkqlmW9TpyaTGyIioocZvc9N3bp1cffuXb321NRU1K1b1yRB0eNxMjEREVHJjE5uNHNrHpWVlQV7e9Y3qiyaPW54W4qIiEiXwTNRx40bBwCQSCSYNm0aHB3//VBVqVQ4efIkgoKCTB4glUyzxw1HboiIiHQZPHJz7tw5nDt3DkIIXLhwQfv43LlzuHz5MgIDA7Fu3TqjA1i2bBkCAgJgb2+P4OBgnDp1qsz+6enpGDFiBHx8fCCXy9GoUSPs2rXL6NetylRqgYQ07k5MRERUEoNHbjSrpAYPHowlS5aYZD+bH3/8EePGjcOKFSsQHByMxYsXIywsDDExMfD09NTrX1BQgC5dusDT0xNbt26Fn58fbt68CVdX1wrHUpUkZuSiSC0gs5HCy4W3AomIiB5m9AYpa9euNdmLL1q0CEOHDsXgwYMBACtWrMDOnTvx7bffYuLEiXr9v/32W6SmpuLPP//Uln0ICAgo8zXy8/ORn5+vfVzWBoRVhWYysb+bA2yk+vOfiIiIqjODkpuePXti3bp1cHFxQc+ePcvs+/PPPxv0wgUFBThz5gwmTZqkbZNKpQgNDcXx48dLPGb79u3o0KEDRowYgV9//RW1atVC37598fHHH8PGxqbEY+bOnYtZs2YZFFNVwT1uiIiISmdQcqNQKLQrpBQKhUleOCUlBSqVCl5eXjrtXl5euHz5conHXL9+HQcOHEC/fv2wa9cuXL16FcOHD0dhYSFmzJhR4jGTJk3SToYGikdulEqlSd6DpXAZOBERUekMSm4evhVlyttSxlKr1fD09MTKlSthY2ODNm3a4NatW1iwYEGpyY1cLodcLq/kSM1LswycG/gRERHpM3rOTW5uLoQQ2qXgN2/exC+//IJmzZrhxRdfNPg8Hh4esLGxQXJysk57cnIyvL29SzzGx8cHdnZ2OregmjZtiqSkJBQUFEAmkxn7dqqkON6WIiIiKpXRm/h1794dGzZsAFC8LLt9+/ZYuHAhunfvjuXLlxt8HplMhjZt2iAiIkLbplarERERgQ4dOpR4zDPPPIOrV69CrVZr265cuQIfH59qk9gA/8654W0pIiIifUYnN2fPnsVzzz0HANi6dSu8vb1x8+ZNbNiwAV999ZVR5xo3bhxWrVqF9evXIzo6GsOGDUN2drZ29dTAgQN1JhwPGzYMqampGDNmDK5cuYKdO3dizpw5GDFihLFvo8q6n1eI1OwCABy5ISIiKonRt6VycnLg7OwMANi7dy969uwJqVSKp59+Gjdv3jTqXH369MHdu3cxffp0JCUlISgoCLt379ZOMo6Li4NU+m/+pVQqsWfPHowdOxYtW7aEn58fxowZg48//tjYt1FlaW5J1XSSoYbc6G8fERGR1TP607FBgwbYtm0bevTooU00AODOnTvl2thv5MiRGDlyZInPHTp0SK+tQ4cOOHHihNGvYy24DJyIiKhsRt+Wmj59OsaPH4+AgAC0b99eOz9m7969aNWqlckDJF1cBk5ERFQ2o0du3nzzTTz77LNITExEYGCgtv2FF15Ajx49TBoc6WNyQ0REVLZyTdrw9vaGt7c3EhISAAD+/v5o3769SQOjkmn2uKnNPW6IiIhKZPRtKbVajU8++QQKhQJ16tRBnTp14OrqitmzZ+ss0Sbz4DJwIiKishk9cjNlyhSsWbMG8+bNwzPPPAMAOHr0KGbOnIm8vDx89tlnJg+SiqnUAglpTG6IiIjKYnRys379eqxevRqvvfaatk2zLHv48OFMbswoMSMXhSoBmY0UXi72lg6HiIjoiWT0banU1FQ0adJEr71JkyZITU01SVBUMs1kYn83B9hIJRaOhoiI6MlkdHITGBiIpUuX6rUvXbpUZ/UUmR73uCEiIno8o29LzZ8/H6+88gr279+v3ePm+PHjiI+Px65du0weIP2Ly8CJiIgez+iRm44dO+LKlSvo2bMn0tPTkZ6ejp49eyImJkZbc4rMQ7sMnMkNERFRqYwaublx4wb27duHgoICvPXWW2jevLm54qISxPG2FBER0WMZnNwcPHgQr776KnJzi0cPbG1t8e2336J///5mC450aebc1OEGfkRERKUy+LbUtGnT0KVLF9y6dQv37t3D0KFD8dFHH5kzNnrI/bxCpGYXAODIDRERUVkMTm4uXryIOXPmwMfHB25ubliwYAHu3LmDe/fumTM+eiD+wXybmk4y1JCXq2oGERFRtWBwcpOZmQkPDw/tY0dHRzg4OCAjI8MsgZGuuNRsABy1ISIiehyjhgD27NkDhUKhfaxWqxEREYGLFy9q2x7euZhMh8vAiYiIDGNUchMeHq7X9t///lf7/xKJBCqVquJRkR4mN0RERIYxOLlhxW/L4h43REREhjF6Ez+yDJZeICIiMoxByc2JEycMPmFOTg4uXbpU7oBIn0otkJD24LYU97ghIiIqk0HJzYABAxAWFoYtW7YgOzu7xD5RUVGYPHky6tevjzNnzpg0yOouKTMPhSoBmY0U3i72lg6HiIjoiWbQnJuoqCgsX74cU6dORd++fdGoUSP4+vrC3t4eaWlpuHz5MrKystCjRw/s3bsXLVq0MHfc1UrcveJRG383B9hIJRaOhoiI6MlmUHJjZ2eH0aNHY/To0Th9+jSOHj2KmzdvIjc3F4GBgRg7diw6deoEd3d3c8dbLXGPGyIiIsMZvdVt27Zt0bZtW3PEQqXgMnAiIiLDcbVUFcBl4ERERIZjclMFxHEZOBERkcGY3FQB8bwtRUREZDAmN0+4+3mFSM0uAAAo3R0sHA0REdGTr0LJTV5enqnioFLEP5hv4+4kg7O9nYWjISIievIZndyo1WrMnj0bfn5+qFGjBq5fvw4AmDZtGtasWWPyAKs7rpQiIiIyjtHJzaeffop169Zh/vz5kMlk2vbmzZtj9erVJg2OON+GiIjIWEYnNxs2bMDKlSvRr18/2NjYaNsDAwNx+fJlkwZHwM0HG/gxuSEiIjKM0cnNrVu30KBBA712tVqNwsJCkwRF/+IeN0RERMYxOrlp1qwZjhw5ote+detWtGrVyiRB0b/iuccNERGRUYwuvzB9+nSEh4fj1q1bUKvV+PnnnxETE4MNGzZgx44d5oix2lKpBRLSHsy5qcnkhoiIyBBGj9x0794dv/32G/bv3w8nJydMnz4d0dHR+O2339ClSxdzxFhtJWXmoVAlYGcjgbeLvaXDISIiqhKMHrkBgOeeew779u0zdSz0iLh7xaM2/m6OsJFKLBwNERFR1WD0yE29evVw7949vfb09HTUq1fPJEFRMc63ISIiMp7Ryc2NGzegUqn02vPz83Hr1i2TBEXFNBv41WFyQ0REZDCDb0tt375d+/979uyBQqHQPlapVIiIiEBAQIBJg6vubnIDPyIiIqMZnNy8/vrrAACJRILw8HCd5+zs7BAQEICFCxeaNLjqLo63pYiIiIxmcHKjVqsBAHXr1sVff/0FDw8PswVFxVh6gYiIyHhGr5aKjY01Rxz0iPt5hUjNLgAAKN0dLBwNERFR1VGupeDZ2dk4fPgw4uLiUFBQoPPc6NGjTRJYdRf/oOyCu5MMzvZ2Fo6GiIio6jA6uTl37hxefvll5OTkIDs7G+7u7khJSYGjoyM8PT2Z3JgI59sQERGVj9FLwceOHYtu3bohLS0NDg4OOHHiBG7evIk2bdrgiy++MEeM1RLn2xAREZWP0clNZGQkPvzwQ0ilUtjY2CA/Px9KpRLz58/H5MmTzRFjtRSnTW4434aIiMgYRic3dnZ2kEqLD/P09ERcXBwAQKFQID4+3rTRVWP/buDnZOFIiIiIqhaj59y0atUKf/31Fxo2bIiOHTti+vTpSElJwXfffYfmzZubI8ZqiXNuiIiIysfokZs5c+bAx8cHAPDZZ5/Bzc0Nw4YNw927d/G///3P5AFWRyq1QELag9tSNZncEBERGcPokZu2bdtq/9/T0xO7d+82aUAEJGXmoVAlYGcjgbeLvaXDISIiqlKMHrkpzdmzZ/Hqq6+a6nTVWty94lEbfzdH2EglFo6GiIioajEqudmzZw/Gjx+PyZMn4/r16wCAy5cv4/XXX0e7du20JRqoYuI534aIiKjcDL4ttWbNGgwdOhTu7u5IS0vD6tWrsWjRIowaNQp9+vTBxYsX0bRpU3PGWm1wGTgREVH5GTxys2TJEnz++edISUnBTz/9hJSUFHzzzTe4cOECVqxYwcTGhOK4gR8REVG5GZzcXLt2Db169QIA9OzZE7a2tliwYAH8/f3NFlx1xeSGiIio/AxObnJzc+HoWPxhK5FIIJfLtUvCK2rZsmUICAiAvb09goODcerUKYOO27x5MyQSCV5//XWTxPGk+De54QZ+RERExjJqKfjq1atRo0YNAEBRURHWrVsHDw8PnT7GFs788ccfMW7cOKxYsQLBwcFYvHgxwsLCEBMTA09Pz1KPu3HjBsaPH4/nnnvOqNd70t3PK0RqdnGldSXn3BARERlNIoQQhnQMCAiARFL2smSJRKJdRWWo4OBgtGvXDkuXLgUAqNVqKJVKjBo1ChMnTizxGJVKheeffx7vvPMOjhw5gvT0dGzbts2g18vMzIRCoUBGRgZcXFyMirUyRN3OxMtfHYG7kwxnp3WxdDhERERPBGM+vw0eublx40ZF49JTUFCAM2fOYNKkSdo2qVSK0NBQHD9+vNTjPvnkE3h6emLIkCE4cuRIma+Rn5+P/Px87ePMzMyKB25GLLtARERUMSbbxK88UlJSoFKp4OXlpdPu5eWFpKSkEo85evQo1qxZg1WrVhn0GnPnzoVCodB+KZXKCsdtTvGcTExERFQhFk1ujHX//n0MGDAAq1at0pvrU5pJkyYhIyND+/WkVy7nHjdEREQVY3RtKVPy8PCAjY0NkpOTddqTk5Ph7e2t1//atWu4ceMGunXrpm3T7Ipsa2uLmJgY1K9fX+cYuVwOuVxuhujNg8vAiYiIKsaiIzcymQxt2rRBRESEtk2tViMiIgIdOnTQ69+kSRNcuHABkZGR2q/XXnsNnTp1QmRk5BN/y8kQLL1ARERUMRYduQGAcePGITw8HG3btkX79u2xePFiZGdnY/DgwQCAgQMHws/PD3PnzoW9vT2aN2+uc7yrqysA6LVXRSq1QEJaLgCgTk3ucUNERFQe5Upurl27hrVr1+LatWtYsmQJPD098fvvv6N27dp46qmnjDpXnz59cPfuXUyfPh1JSUkICgrC7t27tZOM4+LiIJVWqalB5ZaUmYcClRp2NhJ4u9hbOhwiIqIqyeB9bjQOHz6Mrl274plnnsEff/yB6Oho1KtXD/PmzcPp06exdetWc8VqEk/yPjfHr93D26tOoK6HEw6O/4+lwyEiInpiGPP5bfSQyMSJE/Hpp59i3759kMlk2vbOnTvjxIkTxkdLWpxvQ0REVHFGJzcXLlxAjx499No9PT2RkpJikqCqKy4DJyIiqjijkxtXV1ckJibqtZ87dw5+fn4mCaq64jJwIiKiijM6uXnrrbfw8ccfIykpCRKJBGq1GseOHcP48eMxcOBAc8RYbTC5ISIiqjijk5s5c+agSZMmUCqVyMrKQrNmzfD8888jJCQEU6dONUeM1Qbn3BAREVWc0UvBZTIZVq1ahWnTpuHixYvIyspCq1at0LBhQ3PEV21k5RfhXnYBAI7cEBERVYTRyc3Ro0fx7LPPonbt2qhdu7Y5YqqW4u4Vj9q4O8ngbG9n4WiIiIiqLqNvS3Xu3Bl169bF5MmTERUVZY6YqqU43pIiIiIyCaOTm9u3b+PDDz/E4cOH0bx5cwQFBWHBggVISEgwR3zVRjwnExMREZmE0cmNh4cHRo4ciWPHjuHatWvo1asX1q9fj4CAAHTu3NkcMVYL3OOGiIjINCpUtKlu3bqYOHEi5s2bhxYtWuDw4cOmiqva4TJwIiIi0yh3cnPs2DEMHz4cPj4+6Nu3L5o3b46dO3eaMrZqhcvAiYiITMPo1VKTJk3C5s2bcfv2bXTp0gVLlixB9+7d4ejID+XyUqkFEtJyAXDkhoiIqKKMTm7++OMPTJgwAb1794aHh4c5Yqp2kjPzUKBSw1YqgY+Cc26IiIgqwujk5tixY+aIo1rTzLfxd3OAjVRi4WiIiIiqNoOSm+3bt6Nr166ws7PD9u3by+z72muvmSSw6kSzgV/tmk4WjoSIiKjqMyi5ef3115GUlARPT0+8/vrrpfaTSCRQqVSmiq3a4DJwIiIi0zEouVGr1SX+P5kGl4ETERGZjtFLwTds2ID8/Hy99oKCAmzYsMEkQVU3TG6IiIhMx+jkZvDgwcjIyNBrv3//PgYPHmySoKob7nFDRERkOkYnN0IISCT6K3oSEhKgUChMElR1kpVfhHvZBQCY3BAREZmCwUvBW7VqBYlEAolEghdeeAG2tv8eqlKpEBsbi5deesksQVozzaiNm6MdXOztLBwNERFR1WdwcqNZJRUZGYmwsDDUqFFD+5xMJkNAQADeeOMNkwdo7TjfhoiIyLQMTm5mzJgBAAgICECfPn1gb29vtqCqE80eN7wlRUREZBpG71AcHh5ujjiqLc3ITZ2aTG6IiIhMwaDkxt3dHVeuXIGHhwfc3NxKnFCskZqaarLgqgPeliIiIjItg5KbL7/8Es7Oztr/Lyu5IeNwGTgREZFpGZTcPHwratCgQeaKpdpRqQUS0nIBcOSGiIjIVIze5+bs2bO4cOGC9vGvv/6K119/HZMnT0ZBQYFJg7N2yZl5KFCpYSuVwEfBulJERESmYHRy89///hdXrlwBAFy/fh19+vSBo6MjtmzZgo8++sjkAVozzXwbfzcH2Eh5q4+IiMgUjE5urly5gqCgIADAli1b0LFjR2zatAnr1q3D//3f/5k6PqsWx/k2REREJleu8guayuD79+/Hyy+/DABQKpVISUkxbXRWLp4rpYiIiEzO6OSmbdu2+PTTT/Hdd9/h8OHDeOWVVwAAsbGx8PLyMnmA1uzmPSY3REREpmZ0crN48WKcPXsWI0eOxJQpU9CgQQMAwNatWxESEmLyAK0ZN/AjIiIyPaN3KG7ZsqXOaimNBQsWwMbGxiRBVRfc44aIiMj0jE5uNM6cOYPo6GgAQLNmzdC6dWuTBVUdZOUX4V528dJ5JjdERESmY3Ryc+fOHfTp0weHDx+Gq6srACA9PR2dOnXC5s2bUatWLVPHaJU0ozZujnZwsbezcDRERETWw+g5N6NGjUJWVhYuXbqE1NRUpKam4uLFi8jMzMTo0aPNEaNVYk0pIiIi8zB65Gb37t3Yv38/mjZtqm1r1qwZli1bhhdffNGkwVkzzrchIiIyD6NHbtRqNezs9G+j2NnZafe/ocfjyA0REZF5GJ3cdO7cGWPGjMHt27e1bbdu3cLYsWPxwgsvmDQ4a8Y9boiIiMzD6ORm6dKlyMzMREBAAOrXr4/69eujbt26yMzMxNdff22OGK0SdycmIiIyD6Pn3CiVSpw9exYRERHapeBNmzZFaGioyYOzViq1QEJaLgCgNjfwIyIiMimjkpsff/wR27dvR0FBAV544QWMGjXKXHFZteTMPBSo1LCVSuCjcLB0OERERFbF4ORm+fLlGDFiBBo2bAgHBwf8/PPPuHbtGhYsWGDO+KySZjKxv5sDbKQSC0dDRERkXQyec7N06VLMmDEDMTExiIyMxPr16/HNN9+YMzarFcdl4ERERGZjcHJz/fp1hIeHax/37dsXRUVFSExMNEtg1oyTiYmIiMzH4OQmPz8fTk5O/x4olUImkyE3N9csgVkz7nFDRERkPkZNKJ42bRocHf/9QC4oKMBnn30GhUKhbVu0aJHporNSTG6IiIjMx+Dk5vnnn0dMTIxOW0hICK5fv659LJFwcqwh4u5xzg0REZG5GJzcHDp0yIxhVB9Z+UW4l10AgHvcEBERmYPROxRTxWgmE7s52sHFXr9GFxEREVUMk5tKxvk2RERE5sXkppLFc48bIiIis2JyU8k4ckNERGReTG4qGZMbIiIi8ypXcnPkyBH0798fHTp0wK1btwAA3333HY4ePVquIJYtW4aAgADY29sjODgYp06dKrXvqlWr8Nxzz8HNzQ1ubm4IDQ0ts/+ThskNERGReRmd3Pzf//0fwsLC4ODggHPnziE/Px8AkJGRgTlz5hgdwI8//ohx48ZhxowZOHv2LAIDAxEWFoY7d+6U2P/QoUN4++23cfDgQRw/fhxKpRIvvviiNsl6kqnUAgmpxTs6c84NERGReUiEEMKYA1q1aoWxY8di4MCBcHZ2xvnz51GvXj2cO3cOXbt2RVJSklEBBAcHo127dli6dCkAQK1WQ6lUYtSoUZg4ceJjj1epVHBzc8PSpUsxcODAx/bPzMyEQqFARkYGXFxcjIq1om6n5yJk3gHYSiW4PPsl2NrwriAREZEhjPn8NvrTNSYmBs8//7xeu0KhQHp6ulHnKigowJkzZxAaGvpvQFIpQkNDcfz4cYPOkZOTg8LCQri7u5f4fH5+PjIzM3W+LEVzS8rfzYGJDRERkZkY/Qnr7e2Nq1ev6rUfPXoU9erVM+pcKSkpUKlU8PLy0mn38vIyeATo448/hq+vr06C9LC5c+dCoVBov5RKpVExmlIcl4ETERGZndHJzdChQzFmzBicPHkSEokEt2/fxsaNGzF+/HgMGzbMHDGWat68edi8eTN++eUX2Nvbl9hn0qRJyMjI0H7Fx8dXaowPi+dkYiIiIrMzqio4AEycOBFqtRovvPACcnJy8Pzzz0Mul2P8+PEYNWqUUefy8PCAjY0NkpOTddqTk5Ph7e1d5rFffPEF5s2bh/3796Nly5al9pPL5ZDL5UbFZS5cKUVERGR+Ro/cSCQSTJkyBampqbh48SJOnDiBu3fvYvbs2Ua/uEwmQ5s2bRAREaFtU6vViIiIQIcOHUo9bv78+Zg9ezZ2796Ntm3bGv26lsLkhoiIyPyMHrnRkMlkaNasWYUDGDduHMLDw9G2bVu0b98eixcvRnZ2NgYPHgwAGDhwIPz8/DB37lwAwOeff47p06dj06ZNCAgI0M7NqVGjBmrUqFHheMyJpReIiIjMz+jkplOnTpBIJKU+f+DAAaPO16dPH9y9exfTp09HUlISgoKCsHv3bu0k47i4OEil/w4wLV++HAUFBXjzzTd1zjNjxgzMnDnTqNeuTNn5RUjJKgAA1K7J5IaIiMhcjE5ugoKCdB4XFhYiMjISFy9eRHh4eLmCGDlyJEaOHFnic4cOHdJ5fOPGjXK9hqVpbkm5OtrBxd7OwtEQERFZL6OTmy+//LLE9pkzZyIrK6vCAVkrzrchIiKqHCbbSa5///749ttvTXU6q8Nl4ERERJXDZMnN8ePHS91rhjhyQ0REVFmMvi3Vs2dPncdCCCQmJuL06dOYNm2ayQKzNkxuiIiIKofRyY1CodB5LJVK0bhxY3zyySd48cUXTRaYtWFyQ0REVDmMSm5UKhUGDx6MFi1awM3NzVwxWR21WiAhNRcA97ghIiIyN6Pm3NjY2ODFF180uvp3dZd8Pw8FKjVspRL4KDgviYiIyJyMnlDcvHlzXL9+3RyxWK2b94pvSfm5OcDWxmRzuImIiKgERn/Sfvrppxg/fjx27NiBxMREZGZm6nyRPs63ISIiqjwGz7n55JNP8OGHH+Lll18GALz22ms6ZRiEEJBIJFCpVKaPsopjTSkiIqLKY3ByM2vWLLz//vs4ePCgOeOxSpqRmzpMboiIiMzO4ORGCAEA6Nixo9mCsVa8LUVERFR5jJpzU1Y1cCodb0sRERFVHqP2uWnUqNFjE5zU1NQKBWRtsvOLkJJVAACoXZPJDRERkbkZldzMmjVLb4diKlt8WvGojaujHVzs7SwcDRERkfUzKrl566234Onpaa5YrFLcPc63ISIiqkwGz7nhfJvyieN8GyIiokplcHKjWS1FxuFKKSIiospl8G0ptVptzjisFpMbIiKiysVCR2bGDfyIiIgqF5MbM1KrBRJScwFwzg0REVFlYXJjRsn381CgUsNWKoGPwt7S4RAREVULTG7MSLMM3M/NAbY2vNRERESVgZ+4ZsTJxERERJWPyY0ZcY8bIiKiysfkxow4ckNERFT5mNyYEZMbIiKiysfkxozimdwQERFVOiY3ZpKdX4SUrAIAQO2aTG6IiIgqC5MbM4lPKx61cXW0g4u9nYWjISIiqj6Y3JiJZo8b3pIiIiKqXExuzITLwImIiCyDyY2ZcDIxERGRZTC5MZObTG6IiIgsgsmNmXCPGyIiIstgcmMGarVAQmouACY3RERElY3JjRkk389DgUoNW6kEPgp7S4dDRERUrTC5MQPNMnA/NwfY2vASExERVSZ+8poB59sQERFZDpMbM4jnHjdEREQWw+TGDDhyQ0REZDlMbsyAe9wQERFZDpMbM+DuxERERJbD5MbEsvOLkJJVAIBzboiIiCzB1tIBWJv4tOJRG4WDHRQOdhaOhqj6EUKgqKgIKpXK0qEQkZHs7OxgY2NT4fMwuTExzR43vCVFVPkKCgqQmJiInJwcS4dCROUgkUjg7++PGjVqVOg8TG5MTLtSqiaTG6LKpFarERsbCxsbG/j6+kImk0EikVg6LCIykBACd+/eRUJCAho2bFihERwmNybGycREllFQUAC1Wg2lUglHR/7+EVVFtWrVwo0bN1BYWFih5IYTik2Me9wQWZZUyj9rRFWVqUZb+VfAxJjcEBERWRaTGxNSqwXi03IBMLkhIiKyFCY3JpR8Pw8FRWrYSCXwUdhbOhwiIqJqicmNCWmWgfu5OsDWhpeWiCrHoUOHIJFIkJ6eXmqfdevWwdXVtdJiqoiZM2ciKCjI0mFgzZo1ePHFFy0dhtVISUmBp6cnEhISzP5a/AQ2Ic63IaLySkpKwpgxY9CgQQPY29vDy8sLzzzzDJYvX/7YfXtCQkKQmJgIhUJh8OupVCrMmzcPTZo0gYODA9zd3REcHIzVq1dX9K1UmqSkJIwaNQr16tWDXC6HUqlEt27dEBERgYKCAnh4eGDevHklHjt79mx4eXmhsLCwxOfz8vIwbdo0zJgxQ++5hIQEyGQyNG/eXO+5GzduQCKRIDIyUu+5//znP/jggw902s6dO4devXrBy8sL9vb2aNiwIYYOHYorV648/gKUkxAC06dPh4+PDxwcHBAaGop//vmnzGNUKhWmTZuGunXrwsHBAfXr18fs2bMhhND2mTlzJpo0aQInJye4ubkhNDQUJ0+e1D7v4eGBgQMHlnhNTY3JjQnFc48boieKEAI5BUUW+Xr4j/7jXL9+Ha1atcLevXsxZ84cnDt3DsePH8dHH32EHTt2YP/+/aUeW1hYCJlMBm9vb6NWmsyaNQtffvklZs+ejaioKBw8eBDvvfdemaM/plBQUGCS89y4cQNt2rTBgQMHsGDBAly4cAG7d+9Gp06dMGLECMhkMvTv3x9r167VO1YIgXXr1mHgwIGwsyt5J/mtW7fCxcUFzzzzjN5z69atQ+/evZGZmanz4W2sHTt24Omnn0Z+fj42btyI6OhofP/991AoFJg2bVq5z/s48+fPx1dffYUVK1bg5MmTcHJyQlhYGPLy8ko95vPPP8fy5cuxdOlSREdH4/PPP8f8+fPx9ddfa/s0atQIS5cuxYULF3D06FEEBATgxRdfxN27d7V9Bg8ejI0bNyI1NdVs7w/gPjcmxZEboidLbqEKzabvschrR30SBkeZYX9ihw8fDltbW5w+fRpOTk7a9nr16qF79+46iZJEIsE333yD33//HREREZgwYQL+85//oFOnTkhLS9Peelq3bh2mT5+OlJQUhIWF4dlnn9V5ze3bt2P48OHo1auXti0wMFCnj1qtxueff46VK1ciKSkJjRo1wrRp0/Dmm28CKP7X/HvvvYcDBw4gKSkJtWvXxvDhwzFmzBjtOQYNGoT09HS0a9cOy5Ytg1wuR2xsLBISEjBhwgTs2bMH+fn5aNq0KZYtW4bg4GDtsd999x2mTZuGtLQ0dO3aFatWrYKzs7P2mkkkEpw6dUrnmj311FN45513AABDhgzBkiVLcPToUZ33f/jwYVy/fh1Dhgwp9XuyefNmdOvWTa9dCIG1a9fim2++gb+/P9asWaMTs6FycnIwePBgvPzyy/jll1+07XXr1kVwcLDZkkwhBBYvXoypU6eie/fuAIANGzbAy8sL27Ztw1tvvVXicX/++Se6d++OV155BQAQEBCAH374AadOndL26du3r84xixYtwpo1a/D333/jhRdeAFD8/fH19cUvv/xS5vWvqCdi5GbZsmUICAiAvb09goODdS5WSbZs2YImTZrA3t4eLVq0wK5duyop0rIxuSEiY927dw979+7FiBEjdD6kH/boiMzMmTPRo0cPXLhwQftB/rCTJ09iyJAhGDlyJCIjI9GpUyd8+umnOn28vb1x4MABnX9VP2ru3LnYsGEDVqxYgUuXLmHs2LHo378/Dh8+DKA4+fH398eWLVsQFRWF6dOnY/Lkyfjpp590zhMREYGYmBjs27cPO3bsQFZWFjp27Ihbt25h+/btOH/+PD766COo1WrtMdeuXcO2bduwY8cO7NixA4cPH9beYkpNTcXu3btLvWaaBK9FixZo164dvv32W53n165di5CQEDRp0qTU93706FG0bdtWr/3gwYPIyclBaGgo+vfvj82bNyM7O7vU85Rmz549SElJwUcffVTi82XNj3r//fdRo0aNMr9KExsbi6SkJISGhmrbFAoFgoODcfz48VKPCwkJQUREhPZ22fnz53H06FF07dq1xP4FBQVYuXIlFAqFXtLcvn17HDlypNTXMglhYZs3bxYymUx8++234tKlS2Lo0KHC1dVVJCcnl9j/2LFjwsbGRsyfP19ERUWJqVOnCjs7O3HhwgWDXi8jI0MAEBkZGaZ8G0IIIdrM3ifqfLxDXEhIN/m5iahsubm5IioqSuTm5mrb1Gq1yM4vtMiXWq02KO4TJ04IAOLnn3/Waa9Zs6ZwcnISTk5O4qOPPtK2AxAffPCBTt+DBw8KACItLU0IIcTbb78tXn75ZZ0+ffr0EQqFQvv40qVLomnTpkIqlYoWLVqI//73v2LXrl3a5/Py8oSjo6P4888/dc4zZMgQ8fbbb5f6fkaMGCHeeOMN7ePw8HDh5eUl8vPztW3/+9//hLOzs7h3716J55gxY4ZwdHQUmZmZ2rYJEyaI4OBgIYQQJ0+eLPGalWTFihWiRo0a4v79+0IIITIzM4Wjo6NYvXp1qcekpaUJAOKPP/7Qe65v37461z8wMFCsXbtW+zg2NlYAEOfOndM7tmPHjmLMmDFCCCE+//xzAUCkpqY+9j08Kjk5Wfzzzz9lfpXm2LFjAoC4ffu2TnuvXr1E7969Sz1OpVKJjz/+WEgkEmFrayskEomYM2eOXr/ffvtNODk5CYlEInx9fcWpU6f0+owdO1b85z//KfF1Svo91jDm89viIzeLFi3C0KFDMXjwYDRr1gwrVqyAo6OjXqatsWTJErz00kuYMGECmjZtitmzZ6N169ZYunRpJUeuKzu/CClZ+QAAJUduiJ4IEokEjjJbi3xVdKfVU6dOITIyEk899RTy8/N1nitpROFh0dHRerdKOnTooPO4WbNmuHjxIk6cOIF33nkHd+7cQbdu3fDuu+8CAK5evYqcnBx06dJFZ0Rgw4YNuHbtmvY8y5YtQ5s2bVCrVi3UqFEDK1euRFxcnM5rtWjRAjKZTPs4MjISrVq1gru7e6nvISAgQHsLCgB8fHxw584dADBqPtPbb78NlUqlHU368ccfIZVK0adPn1KPyc0t3q/M3l53S4/09HT8/PPP6N+/v7atf//+WLNmjcHxaBjzHh7l6emJBg0alPllaj/99BM2btyITZs24ezZs1i/fj2++OILrF+/Xqdfp06dEBkZiT///BMvvfQSevfurf2+aTg4OJi9uK1F59wUFBTgzJkzmDRpkrZNKpUiNDS01OGx48ePY9y4cTptYWFh2LZtW4n98/Pzdf4wZGZmVjzwEsSnFX+jFA52UDiUPEGNiOhRDRo0gEQiQUxMjE57vXr1ABR/EDyqtNtXxpJKpWjXrh3atWuHDz74AN9//z0GDBiAKVOmICsrCwCwc+dO+Pn56Rwnl8sBFM9LGT9+PBYuXIgOHTrA2dkZCxYs0Jtk+2i8Jb2nRz060VcikWhvWzVs2BASiQSXL19+7HlcXFzw5ptvYu3atXjnnXewdu1a9O7du8xbNzVr1oREIkFaWppO+6ZNm5CXl6eTOAohoFarceXKFTRq1AguLi4AgIyMDL3zpqena1e0NWrUCABw+fJlvcTzcd5//318//33ZfbRfP8e5e3tDQBITk6Gj4+Ptj05ObnM5fcTJkzAxIkTtXNyWrRogZs3b2Lu3LkIDw/X9nNyctImWE8//TQaNmyINWvW6HzOp6amolatWo99nxVh0ZGblJQUqFQqeHl56bR7eXkhKSmpxGOSkpKM6j937lwoFArtl1KpNE3wj0jLLoTCwY7zbYjIKDVr1kSXLl2wdOnScs3dKEnTpk31EowTJ0489rhmzZoBALKzs9GsWTPI5XLExcXpjQpo/o4eO3YMISEhGD58OFq1aoUGDRrojOqUpmXLloiMjCz3ihl3d3eEhYVh2bJlJV6zRyfjDhkyBEePHsWOHTvw559/PnYiq0wmQ7NmzRAVFaXTvmbNGnz44YeIjIzUfp0/fx7PPfec9m6Du7s7PDw8cObMGZ1jMzMzcfXqVW1S8+KLL8LDwwPz588vMYayJhR/8sknOjGU9FWaunXrwtvbGxERETqxnTx5sswkKycnR69um42Njc48qZKo1Wq9kceLFy+iVatWZR5XYY+9cWVGt27dEgD07ulOmDBBtG/fvsRj7OzsxKZNm3Tali1bJjw9PUvsn5eXJzIyMrRf8fHxZptzI4QQuQVFZjkvEZWtrHv1T7qrV68KLy8v0aRJE7F582YRFRUlLl++LL777jvh5eUlxo0bp+0LQPzyyy86xz865+b48eNCKpWKBQsWiCtXroivv/5auLq66sy5eeONN8SiRYvEiRMnxI0bN8TBgwfF008/LRo1aiQKCwuFEEJMmTJF1KxZU6xbt05cvXpVnDlzRnz11Vdi3bp1QgghlixZIlxcXMTu3btFTEyMmDp1qnBxcRGBgYHa1wkPDxfdu3fXiTc/P180atRIPPfcc+Lo0aPi2rVrYuvWrdrPghkzZuicQwghvvzyS1GnTh3t42vXrglvb2/RrFkzsXXrVnHlyhURFRUllixZIpo0aaJzrFqtFg0aNBBubm56z5Vm3LhxOnOHzp07JwCI6Ohovb7ffPON8Pb21l63OXPmiJo1a4rvv/9eXL16VZw8eVK8+uqrIiAgQOTk5GiP27Ztm7CzsxPdunUT+/btE7GxseKvv/4SEyZMEH369DEozvKYN2+ecHV1Fb/++qv4+++/Rffu3UXdunV1fnc6d+4svv76a+3j8PBw4efnJ3bs2CFiY2PFzz//LDw8PLTzwbKyssSkSZPE8ePHxY0bN8Tp06fF4MGDhVwuFxcvXtSeJzs7Wzg4OJQ4n0kI0825sWhyk5+fL2xsbPR+UQcOHChee+21Eo9RKpXiyy+/1GmbPn26aNmypUGvac4JxURkOVU5uRFCiNu3b4uRI0eKunXrCjs7O1GjRg3Rvn17sWDBApGdna3tZ0hyI4QQa9asEf7+/sLBwUF069ZNfPHFFzrJzcqVK0WnTp1ErVq1hEwmE7Vr1xaDBg0SN27c0PZRq9Vi8eLFonHjxsLOzk7UqlVLhIWFicOHDwshiv/xOGjQIKFQKISrq6sYNmyYmDhx4mOTGyGEuHHjhnjjjTeEi4uLcHR0FG3bthUnT54UQhiW3Giu2YgRI0SdOnWETCYTfn5+4rXXXhMHDx7Ue705c+YIAGL+/Pn6F78Ely5dEg4ODiI9vXiByMiRI0WzZs1K7JuYmCikUqn49ddfhRBCFBUVia+++kq0aNFCODo6Cn9/f9GnTx8RGxurd+xff/0levbsKWrVqiXkcrlo0KCBeO+998qcFFxRarVaTJs2TXh5eQm5XC5eeOEFERMTo9OnTp06YsaMGdrHmZmZYsyYMaJ27drC3t5e1KtXT0yZMkU7UTw3N1f06NFD+Pr6CplMJnx8fMRrr72mN6F406ZNonHjxqXGZqrkRiJEBWY1mUBwcDDat2+v3QhIrVajdu3aGDlyJCZOnKjXv0+fPsjJycFvv/2mbQsJCUHLli2xYsWKx75eZmYmFAoFMjIytPdGiajqy8vLQ2xsLOrWras3EZSoPHr16oXWrVvrzBehinn66acxevRovT1xNMr6PTbm89viq6XGjRuHVatWYf369YiOjsawYcOQnZ2NwYMHAwAGDhyo84M1ZswY7N69GwsXLsTly5cxc+ZMnD59GiNHjrTUWyAiIiu0YMGCMicek3FSUlLQs2dPvP3222Z/LYvvUNynTx/cvXsX06dPR1JSEoKCgrB7927tpOG4uDidSUwhISHYtGkTpk6dismTJ6Nhw4bYtm1biTU+iIiIyisgIACjRo2ydBhWw8PDo9RNC03N4relKhtvSxFZJ96WIqr6rOa2FBGRKVWzf68RWRVT/f4yuSEiq6DZ9M3cO58Skfloqsbb2NhU6DwWn3NDRGQKNjY2cHV11W717ujoWOESCERUedRqNe7evQtHR0fY2lYsPWFyQ0RWQ7O1/KO1bIioapBKpahdu3aF/2HC5IaIrIZEIoGPjw88PT1RWFho6XCIyEgymUyvzEN5MLkhIqtjY2NT4Xv2RFR1cUIxERERWRUmN0RERGRVmNwQERGRVal2c240GwRlZmZaOBIiIiIylOZz25CN/qpdcnP//n0AgFKptHAkREREZKz79+9DoVCU2afa1ZZSq9W4ffs2nJ2dTb7BV2ZmJpRKJeLj41m3yox4nSsHr3Pl4HWuPLzWlcNc11kIgfv378PX1/exy8Wr3ciNVCqFv7+/WV/DxcWFvziVgNe5cvA6Vw5e58rDa105zHGdHzdio8EJxURERGRVmNwQERGRVWFyY0JyuRwzZsyAXC63dChWjde5cvA6Vw5e58rDa105noTrXO0mFBMREZF148gNERERWRUmN0RERGRVmNwQERGRVWFyQ0RERFaFyY2Rli1bhoCAANjb2yM4OBinTp0qs/+WLVvQpEkT2Nvbo0WLFti1a1clRVq1GXOdV61aheeeew5ubm5wc3NDaGjoY78vVMzYn2eNzZs3QyKR4PXXXzdvgFbC2Oucnp6OESNGwMfHB3K5HI0aNeLfDgMYe50XL16Mxo0bw8HBAUqlEmPHjkVeXl4lRVs1/fHHH+jWrRt8fX0hkUiwbdu2xx5z6NAhtG7dGnK5HA0aNMC6devMHicEGWzz5s1CJpOJb7/9Vly6dEkMHTpUuLq6iuTk5BL7Hzt2TNjY2Ij58+eLqKgoMXXqVGFnZycuXLhQyZFXLcZe5759+4ply5aJc+fOiejoaDFo0CChUChEQkJCJUdetRh7nTViY2OFn5+feO6550T37t0rJ9gqzNjrnJ+fL9q2bStefvllcfToUREbGysOHTokIiMjKznyqsXY67xx40Yhl8vFxo0bRWxsrNizZ4/w8fERY8eOreTIq5Zdu3aJKVOmiJ9//lkAEL/88kuZ/a9fvy4cHR3FuHHjRFRUlPj666+FjY2N2L17t1njZHJjhPbt24sRI0ZoH6tUKuHr6yvmzp1bYv/evXuLV155RactODhY/Pe//zVrnFWdsdf5UUVFRcLZ2VmsX7/eXCFahfJc56KiIhESEiJWr14twsPDmdwYwNjrvHz5clGvXj1RUFBQWSFaBWOv84gRI0Tnzp112saNGyeeeeYZs8ZpTQxJbj766CPx1FNP6bT16dNHhIWFmTEyIXhbykAFBQU4c+YMQkNDtW1SqRShoaE4fvx4icccP35cpz8AhIWFldqfynedH5WTk4PCwkK4u7ubK8wqr7zX+ZNPPoGnpyeGDBlSGWFWeeW5ztu3b0eHDh0wYsQIeHl5oXnz5pgzZw5UKlVlhV3llOc6h4SE4MyZM9pbV9evX8euXbvw8ssvV0rM1YWlPgerXeHM8kpJSYFKpYKXl5dOu5eXFy5fvlziMUlJSSX2T0pKMlucVV15rvOjPv74Y/j6+ur9QtG/ynOdjx49ijVr1iAyMrISIrQO5bnO169fx4EDB9CvXz/s2rULV69exfDhw1FYWIgZM2ZURthVTnmuc9++fZGSkoJnn30WQggUFRXh/fffx+TJkysj5GqjtM/BzMxM5ObmwsHBwSyvy5Ebsirz5s3D5s2b8csvv8De3t7S4ViN+/fvY8CAAVi1ahU8PDwsHY5VU6vV8PT0xMqVK9GmTRv06dMHU6ZMwYoVKywdmlU5dOgQ5syZg2+++QZnz57Fzz//jJ07d2L27NmWDo1MgCM3BvLw8ICNjQ2Sk5N12pOTk+Ht7V3iMd7e3kb1p/JdZ40vvvgC8+bNw/79+9GyZUtzhlnlGXudr127hhs3bqBbt27aNrVaDQCwtbVFTEwM6tevb96gq6Dy/Dz7+PjAzs4ONjY22ramTZsiKSkJBQUFkMlkZo25KirPdZ42bRoGDBiAd999FwDQokULZGdn47333sOUKVMglfLf/qZQ2uegi4uL2UZtAI7cGEwmk6FNmzaIiIjQtqnVakRERKBDhw4lHtOhQwed/gCwb9++UvtT+a4zAMyfPx+zZ8/G7t270bZt28oItUoz9jo3adIEFy5cQGRkpPbrtddeQ6dOnRAZGQmlUlmZ4VcZ5fl5fuaZZ3D16lVt8ggAV65cgY+PDxObUpTnOufk5OglMJqEUrDkoslY7HPQrNOVrczmzZuFXC4X69atE1FRUeK9994Trq6uIikpSQghxIABA8TEiRO1/Y8dOyZsbW3FF198IaKjo8WMGTO4FNwAxl7nefPmCZlMJrZu3SoSExO1X/fv37fUW6gSjL3Oj+JqKcMYe53j4uKEs7OzGDlypIiJiRE7duwQnp6e4tNPP7XUW6gSjL3OM2bMEM7OzuKHH34Q169fF3v37hX169cXvXv3ttRbqBLu378vzp07J86dOycAiEWLFolz586JmzdvCiGEmDhxohgwYIC2v2Yp+IQJE0R0dLRYtmwZl4I/ib7++mtRu3ZtIZPJRPv27cWJEye0z3Xs2FGEh4fr9P/pp59Eo0aNhEwmE0899ZTYuXNnJUdcNRlznevUqSMA6H3NmDGj8gOvYoz9eX4YkxvDGXud//zzTxEcHCzkcrmoV6+e+Oyzz0RRUVElR131GHOdCwsLxcyZM0X9+vWFvb29UCqVYvjw4SItLa3yA69CDh48WOLfW821DQ8PFx07dtQ7JigoSMhkMlGvXj2xdu1as8cpEYLjb0RERGQ9OOeGiIiIrAqTGyIiIrIqTG6IiIjIqjC5ISIiIqvC5IaIiIisCpMbIiIisipMboiIiMiqMLkhIiIiq8LkhqgE69atg6urq6XDKDeJRIJt27aV2WfQoEF4/fXXKyWeJ820adPw3nvvVcprHTp0CBKJBOnp6WX2CwgIwOLFi80ai7GvYarfA0N+Ho0VFRUFf39/ZGdnm/S8ZB2Y3JDVGjRoECQSid7X1atXLR0a1q1bp41HKpXC398fgwcPxp07d0xy/sTERHTt2hUAcOPGDUgkEkRGRur0WbJkCdatW2eS1yvNzJkzte/TxsYGSqUS7733HlJTU406jykTsaSkJCxZsgRTpkzROb8mTplMhgYNGuCTTz5BUVFRhV8vJCQEiYmJUCgUAEpPGP76669KS7iqgs8++wwhISFwdHQs8Xo1a9YMTz/9NBYtWlT5wdETj8kNWbWXXnoJiYmJOl9169a1dFgAABcXFyQmJiIhIQGrVq3C77//jgEDBpjk3N7e3pDL5WX2USgUlTI69dRTTyExMRFxcXFYu3Ytdu/ejWHDhpn9dUuzevVqhISEoE6dOjrtmp+Vf/75Bx9++CFmzpyJBQsWVPj1ZDIZvL29IZFIyuxXq1YtODo6Vvj1rEVBQQF69epV5s/K4MGDsXz5cpMkoWRdmNyQVZPL5fD29tb5srGxwaJFi9CiRQs4OTlBqVRi+PDhyMrKKvU858+fR6dOneDs7AwXFxe0adMGp0+f1j5/9OhRPPfcc3BwcIBSqcTo0aMfO1wukUjg7e0NX19fdO3aFaNHj8b+/fuRm5sLtVqNTz75BP7+/pDL5QgKCsLu3bu1xxYUFGDkyJHw8fGBvb096tSpg7lz5+qcW3MbQJPMtWrVChKJBP/5z38A6I6GrFy5Er6+vlCr1Toxdu/eHe+884728a+//orWrVvD3t4e9erVw6xZsx77wWJrawtvb2/4+fkhNDQUvXr1wr59+7TPq1QqDBkyBHXr1oWDgwMaN26MJUuWaJ+fOXMm1q9fj19//VU7unLo0CEAQHx8PHr37g1XV1e4u7uje/fuuHHjRpnxbN68Gd26ddNr1/ys1KlTB8OGDUNoaCi2b98OAEhLS8PAgQPh5uYGR0dHdO3aFf/884/22Js3b6Jbt25wc3ODk5MTnnrqKezatQuA7m2pQ4cOYfDgwcjIyNC+l5kzZwLQvWXUt29f9OnTRye+wsJCeHh4YMOGDQAAtVqNuXPnaq9bYGAgtm7dWuZ7f5Shvwfbtm1Dw4YNYW9vj7CwMMTHx+s8X56fi8eZNWsWxo4dixYtWpTap0uXLkhNTcXhw4cr9FpkfZjcULUklUrx1Vdf4dKlS1i/fj0OHDiAjz76qNT+/fr1g7+/P/766y+cOXMGEydOhJ2dHQDg2rVreOmll/DGG2/g77//xo8//oijR49i5MiRRsXk4OAAtVqNoqIiLFmyBAsXLsQXX3yBv//+G2FhYXjttde0H6hfffUVtm/fjp9++gkxMTHYuHEjAgICSjzvqVOnAAD79+9HYmIifv75Z70+vXr1wr1793Dw4EFtW2pqKnbv3o1+/foBAI4cOYKBAwdizJgxiIqKwv/+9z+sW7cOn332mcHv8caNG9izZw9kMpm2Ta1Ww9/fH1u2bEFUVBSmT5+OyZMn46effgIAjB8/Hr1799YZhQsJCUFhYSHCwsLg7OyMI0eO4NixY6hRowZeeuklFBQUlPj6qampiIqKQtu2bR8bq4ODg/Y8gwYNwunTp7F9+3YcP34cQgi8/PLLKCwsBACMGDEC+fn5+OOPP3DhwgV8/vnnqFGjht45Q0JCsHjxYu2oXWJiIsaPH6/Xr1+/fvjtt990Eo09e/YgJycHPXr0AADMnTsXGzZswIoVK3Dp0iWMHTsW/fv3N+qD3pDfg5ycHHz22WfYsGEDjh07hvT0dLz11lva58vzc/Gf//wHgwYNMjjO0shkMgQFBeHIkSMVPhdZGbPXHSeykPDwcGFjYyOcnJy0X2+++WaJfbds2SJq1qypfbx27VqhUCi0j52dncW6detKPHbIkCHivffe02k7cuSIkEqlIjc3t8RjHj3/lStXRKNGjUTbtm2FEEL4+vqKzz77TOeYdu3aieHDhwshhBg1apTo3LmzUKvVJZ4fgPjll1+EEELExsYKAOLcuXM6fcLDw0X37t21j7t37y7eeecd7eP//e9/wtfXV6hUKiGEEC+88IKYM2eOzjm+++474ePjU2IMQggxY8YMIZVKhZOTk7C3txcABACxaNGiUo8RQogRI0aIN954o9RYNa/duHFjnWuQn58vHBwcxJ49e0o877lz5wQAERcXp9P+8PnVarXYt2+fkMvlYvz48eLKlSsCgDh27Ji2f0pKinBwcBA//fSTEEKIFi1aiJkzZ5b4mgcPHhQARFpamhBC/3uvUadOHfHll18KIYQoLCwUHh4eYsOGDdrn3377bdGnTx8hhBB5eXnC0dFR/PnnnzrnGDJkiHj77bdLjOPR1yhJSb8HAMSJEye0bdHR0QKAOHnypBDCsJ+Lh38ehRBiwIABYuLEiaXG8bDSrpdGjx49xKBBgww6F1UftpZKqogqQ6dOnbB8+XLtYycnJwDFoxhz587F5cuXkZmZiaKiIuTl5SEnJ6fEeQ/jxo3Du+++i++++057a6V+/foAim9Z/f3339i4caO2vxACarUasbGxaNq0aYmxZWRkoEaNGlCr1cjLy8Ozzz6L1atXIzMzE7dv38Yzzzyj0/+ZZ57B+fPnARSPJHTp0gWNGzfGSy+9hFdffRUvvvhiha5Vv379MHToUHzzzTeQy+XYuHEj3nrrLUilUu37PHbsmM6/yFUqVZnXDQAaN26M7du3Iy8vD99//z0iIyMxatQonT7Lli3Dt99+i7i4OOTm5qKgoABBQUFlxnv+/HlcvXoVzs7OOu15eXm4du1aicfk5uYCAOzt7fWe27FjB2rUqIHCwkKo1Wr07dsXM2fOREREBGxtbREcHKztW7NmTTRu3BjR0dEAgNGjR2PYsGHYu3cvQkND8cYbb6Bly5Zlxl8WW1tb9O7dGxs3bsSAAQOQnZ2NX3/9FZs3bwYAXL16FTk5OejSpYvOcQUFBWjVqpXBr2PI74GtrS3atWunPaZJkyZwdXVFdHQ02rdvX66fC82tNVNwcHBATk6Oyc5H1oHJDVk1JycnNGjQQKftxo0bePXVVzFs2DB89tlncHd3x9GjRzFkyBAUFBSU+Md45syZ6Nu3L3bu3Inff/8dM2bMwObNm9GjRw9kZWXhv//9L0aPHq13XO3atUuNzdnZGWfPnoVUKoWPjw8cHBwAAJmZmY99X61bt0ZsbCx+//137N+/H71790ZoaKjRcy4e1q1bNwghsHPnTrRr1w5HjhzBl19+qX0+KysLs2bNQs+ePfWOLSlZ0NCsPgKAefPm4ZVXXsGsWbMwe/ZsAMVzYMaPH4+FCxeiQ4cOcHZ2xoIFC3Dy5Mky483KykKbNm10kkqNWrVqlXiMh4cHgOI5NI/20STCMpkMvr6+sLU1/M/ju+++i7CwMOzcuRN79+7F3LlzsXDhQr0kzhj9+vVDx44dcefOHezbtw8ODg546aWXAEB7u2rnzp3w8/PTOe5xE8k1yvN7UJLy/lyYSmpqqvYfGkQaTG6o2jlz5gzUajUWLlyoHZXQzO8oS6NGjdCoUSOMHTsWb7/9NtauXYsePXqgdevWiIqK0kuiHkcqlZZ4jIuLC3x9fXHs2DF07NhR237s2DG0b99ep1+fPn3Qp08fvPnmm3jppZeQmpoKd3d3nfNp5reoVKoy47G3t0fPnj2xceNGXL16FY0bN0br1q21z7du3RoxMTFGv89HTZ06FZ07d8awYcO07zMkJATDhw/X9nl05EUmk+nF37p1a/z444/w9PSEi4uLQa9dv359uLi4ICoqCo0aNdJ5rqREGACaNm2KoqIinDx5EiEhIQCAe/fuISYmBs2aNdP2UyqVeP/99/H+++9j0qRJWLVqVYnJTUnvpSQhISFQKpX48ccf8fvvv6NXr17aeV7NmjWDXC5HXFyczs+IMQz9PSgqKsLp06e1P3sxMTFIT0/Xjkia6ueivC5evIg333zTIq9NTy5OKKZqp0GDBigsLMTXX3+N69ev47vvvsOKFStK7Z+bm4uRI0fi0KFDuHnzJo4dO4a//vpL+8f9448/xp9//omRI0ciMjIS//zzD3799VejJxQ/bMKECfj888/x448/IiYmBhMnTkRkZCTGjBkDoHiVyw8//IDLly/jypUr2LJlC7y9vUtc2u3p6QkHBwfs3r0bycnJyMjIKPV1+/Xrh507d+Lbb7/VTiTWmD59OjZs2IBZs2bh0qVLiI6OxubNmzF16lSj3luHDh3QsmVLzJkzBwDQsGFDnD59Gnv27MGVK1cwbdo0/PXXXzrHBAQE4O+//0ZMTAxSUlJQWFiIfv36wcPDA927d8eRI0cQGxuLQ4cOYfTo0UhISCjxtaVSKUJDQ3H06FGD423YsCG6d++OoUOH4ujRozh//jz69+8PPz8/dO/eHQDwwQcfYM+ePYiNjcXZs2dx8ODBUm9HBgQEICsrCxEREUhJSSnzlkrfvn2xYsUK7Nu3T+f74ezsjPHjx2Ps2LFYv349rl27hrNnz+Lrr7/G+vXrDXpfhv4e2NnZYdSoUTh58iTOnDmDQYMG4emnn9YmO+X5uRg4cCAmTZpUZnxxcXGIjIxEXFwcVCoVIiMjERkZqTPJ+saNG7h16xZCQ0MNes9UjVh60g+RuZQ0CVVj0aJFwsfHRzg4OIiwsDCxYcOGUid95ufni7feeksolUohk8mEr6+vGDlypM5k4VOnTokuXbqIGjVqCCcnJ9GyZUu9CcEPe9wkSZVKJWbOnCn8/PyEnZ2dCAwMFL///rv2+ZUrV4qgoCDh5OQkXFxcxAsvvCDOnj2rfR6PTOBctWqVUCqVQiqVio4dO5Z6fVQqlfDx8REAxLVr1/Ti2r17twgJCREODg7CxcVFtG/fXqxcubLU9zFjxgwRGBio1/7DDz8IuVwu4uLiRF5enhg0aJBQKBTC1dVVDBs2TEycOFHnuDt37mivLwBx8OBBIYQQiYmJYuDAgcLDw0PI5XJRr149MXToUJGRkVFqTLt27RJ+fn7aidKlXYuHpaamigEDBgiFQqH9mbly5Yr2+ZEjR4r69esLuVwuatWqJQYMGCBSUlKEEPoTioUQ4v333xc1a9YUAMSMGTOEECVP9o2KihIARJ06dfQmj6vVarF48WLRuHFjYWdnJ2rVqiXCwsLE4cOHS30fj76Gob8H//d//yfq1asn5HK5CA0NFTdv3tQ57+N+Lh79eezYsaMIDw8vNU4hir8neDAB/eEvzfdeCCHmzJkjwsLCyjwPVU8SIYSwRFJFRGQJQggEBwdrby9S1VRQUICGDRti06ZNepPviXhbioiqFYlEgpUrV3JX2youLi4OkydPZmJDJeLIDREREVkVjtwQERGRVWFyQ0RERFaFyQ0RERFZFSY3REREZFWY3BAREZFVYXJDREREVoXJDREREVkVJjdERERkVZjcEBERkVX5f0Ap3i9/swCAAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the ROC curve for the best decision tree model\n",
    "\n",
    "# These two statements achieves the same thing\n",
    "# RocCurveDisplay.from_predictions(test_targets, dt2.predict_proba(test_features)[:,1])\n",
    "RocCurveDisplay.from_estimator(dt_grid, test_features, test_targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ROC curve show very good performance for all sensitivities. This is also shown by the AUC of 0.84"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lars/.venv/sklearn/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/lars/.venv/sklearn/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/lars/.venv/sklearn/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/lars/.venv/sklearn/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/lars/.venv/sklearn/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/lars/.venv/sklearn/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/lars/.venv/sklearn/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/lars/.venv/sklearn/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/lars/.venv/sklearn/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/lars/.venv/sklearn/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/lars/.venv/sklearn/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/lars/.venv/sklearn/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/lars/.venv/sklearn/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/lars/.venv/sklearn/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/lars/.venv/sklearn/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/lars/.venv/sklearn/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/lars/.venv/sklearn/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/lars/.venv/sklearn/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/lars/.venv/sklearn/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/lars/.venv/sklearn/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/lars/.venv/sklearn/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/lars/.venv/sklearn/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/lars/.venv/sklearn/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/lars/.venv/sklearn/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/lars/.venv/sklearn/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/lars/.venv/sklearn/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/lars/.venv/sklearn/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/lars/.venv/sklearn/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/lars/.venv/sklearn/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/lars/.venv/sklearn/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/lars/.venv/sklearn/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/lars/.venv/sklearn/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/lars/.venv/sklearn/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/lars/.venv/sklearn/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/lars/.venv/sklearn/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/lars/.venv/sklearn/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/lars/.venv/sklearn/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/lars/.venv/sklearn/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/lars/.venv/sklearn/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/lars/.venv/sklearn/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/lars/.venv/sklearn/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/lars/.venv/sklearn/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/lars/.venv/sklearn/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/lars/.venv/sklearn/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/lars/.venv/sklearn/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/lars/.venv/sklearn/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/lars/.venv/sklearn/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/lars/.venv/sklearn/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/lars/.venv/sklearn/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/lars/.venv/sklearn/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/lars/.venv/sklearn/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/lars/.venv/sklearn/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/lars/.venv/sklearn/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/lars/.venv/sklearn/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/lars/.venv/sklearn/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/lars/.venv/sklearn/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/lars/.venv/sklearn/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/lars/.venv/sklearn/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/lars/.venv/sklearn/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/lars/.venv/sklearn/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/lars/.venv/sklearn/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/lars/.venv/sklearn/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/lars/.venv/sklearn/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/lars/.venv/sklearn/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/lars/.venv/sklearn/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/lars/.venv/sklearn/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/lars/.venv/sklearn/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/lars/.venv/sklearn/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/lars/.venv/sklearn/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/lars/.venv/sklearn/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/lars/.venv/sklearn/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/lars/.venv/sklearn/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/lars/.venv/sklearn/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/lars/.venv/sklearn/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/lars/.venv/sklearn/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/lars/.venv/sklearn/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/lars/.venv/sklearn/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/lars/.venv/sklearn/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/lars/.venv/sklearn/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/lars/.venv/sklearn/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/lars/.venv/sklearn/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/lars/.venv/sklearn/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/lars/.venv/sklearn/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/lars/.venv/sklearn/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/lars/.venv/sklearn/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/lars/.venv/sklearn/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/lars/.venv/sklearn/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/lars/.venv/sklearn/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/lars/.venv/sklearn/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/lars/.venv/sklearn/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/lars/.venv/sklearn/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/lars/.venv/sklearn/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/lars/.venv/sklearn/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/lars/.venv/sklearn/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/lars/.venv/sklearn/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/lars/.venv/sklearn/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/lars/.venv/sklearn/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/lars/.venv/sklearn/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/lars/.venv/sklearn/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/lars/.venv/sklearn/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/lars/.venv/sklearn/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/lars/.venv/sklearn/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/lars/.venv/sklearn/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/lars/.venv/sklearn/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/lars/.venv/sklearn/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/lars/.venv/sklearn/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/lars/.venv/sklearn/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/lars/.venv/sklearn/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/lars/.venv/sklearn/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/lars/.venv/sklearn/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/lars/.venv/sklearn/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/lars/.venv/sklearn/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/lars/.venv/sklearn/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/lars/.venv/sklearn/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/lars/.venv/sklearn/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/lars/.venv/sklearn/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/lars/.venv/sklearn/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/lars/.venv/sklearn/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/lars/.venv/sklearn/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/lars/.venv/sklearn/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/lars/.venv/sklearn/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/lars/.venv/sklearn/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/lars/.venv/sklearn/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/lars/.venv/sklearn/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/lars/.venv/sklearn/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/lars/.venv/sklearn/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/lars/.venv/sklearn/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/lars/.venv/sklearn/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/lars/.venv/sklearn/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/lars/.venv/sklearn/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/lars/.venv/sklearn/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/lars/.venv/sklearn/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/lars/.venv/sklearn/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/lars/.venv/sklearn/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/lars/.venv/sklearn/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/lars/.venv/sklearn/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/lars/.venv/sklearn/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/lars/.venv/sklearn/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/lars/.venv/sklearn/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/lars/.venv/sklearn/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/lars/.venv/sklearn/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/lars/.venv/sklearn/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/lars/.venv/sklearn/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/lars/.venv/sklearn/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/lars/.venv/sklearn/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/lars/.venv/sklearn/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/lars/.venv/sklearn/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/lars/.venv/sklearn/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/lars/.venv/sklearn/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/lars/.venv/sklearn/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/lars/.venv/sklearn/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/lars/.venv/sklearn/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/lars/.venv/sklearn/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/lars/.venv/sklearn/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/lars/.venv/sklearn/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/lars/.venv/sklearn/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/lars/.venv/sklearn/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/lars/.venv/sklearn/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/lars/.venv/sklearn/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/lars/.venv/sklearn/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/lars/.venv/sklearn/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/lars/.venv/sklearn/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/lars/.venv/sklearn/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/lars/.venv/sklearn/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/lars/.venv/sklearn/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/lars/.venv/sklearn/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/lars/.venv/sklearn/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/lars/.venv/sklearn/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/lars/.venv/sklearn/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/lars/.venv/sklearn/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/lars/.venv/sklearn/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/lars/.venv/sklearn/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/lars/.venv/sklearn/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/lars/.venv/sklearn/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/lars/.venv/sklearn/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/lars/.venv/sklearn/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/lars/.venv/sklearn/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/lars/.venv/sklearn/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/lars/.venv/sklearn/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/lars/.venv/sklearn/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/lars/.venv/sklearn/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/lars/.venv/sklearn/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/lars/.venv/sklearn/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/lars/.venv/sklearn/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/lars/.venv/sklearn/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/lars/.venv/sklearn/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/lars/.venv/sklearn/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/lars/.venv/sklearn/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/lars/.venv/sklearn/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/lars/.venv/sklearn/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/lars/.venv/sklearn/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/lars/.venv/sklearn/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/lars/.venv/sklearn/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/lars/.venv/sklearn/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/lars/.venv/sklearn/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/lars/.venv/sklearn/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/lars/.venv/sklearn/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/lars/.venv/sklearn/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/lars/.venv/sklearn/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/lars/.venv/sklearn/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_var_smoothing</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_accuracy</th>\n",
       "      <th>split1_test_accuracy</th>\n",
       "      <th>split2_test_accuracy</th>\n",
       "      <th>split3_test_accuracy</th>\n",
       "      <th>split4_test_accuracy</th>\n",
       "      <th>mean_test_accuracy</th>\n",
       "      <th>std_test_accuracy</th>\n",
       "      <th>rank_test_accuracy</th>\n",
       "      <th>split0_test_precision</th>\n",
       "      <th>split1_test_precision</th>\n",
       "      <th>split2_test_precision</th>\n",
       "      <th>split3_test_precision</th>\n",
       "      <th>split4_test_precision</th>\n",
       "      <th>mean_test_precision</th>\n",
       "      <th>std_test_precision</th>\n",
       "      <th>rank_test_precision</th>\n",
       "      <th>split0_test_recall</th>\n",
       "      <th>split1_test_recall</th>\n",
       "      <th>split2_test_recall</th>\n",
       "      <th>split3_test_recall</th>\n",
       "      <th>split4_test_recall</th>\n",
       "      <th>mean_test_recall</th>\n",
       "      <th>std_test_recall</th>\n",
       "      <th>rank_test_recall</th>\n",
       "      <th>split0_test_f1</th>\n",
       "      <th>split1_test_f1</th>\n",
       "      <th>split2_test_f1</th>\n",
       "      <th>split3_test_f1</th>\n",
       "      <th>split4_test_f1</th>\n",
       "      <th>mean_test_f1</th>\n",
       "      <th>std_test_f1</th>\n",
       "      <th>rank_test_f1</th>\n",
       "      <th>split0_test_roc_auc</th>\n",
       "      <th>split1_test_roc_auc</th>\n",
       "      <th>split2_test_roc_auc</th>\n",
       "      <th>split3_test_roc_auc</th>\n",
       "      <th>split4_test_roc_auc</th>\n",
       "      <th>mean_test_roc_auc</th>\n",
       "      <th>std_test_roc_auc</th>\n",
       "      <th>rank_test_roc_auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001201</td>\n",
       "      <td>0.000103</td>\n",
       "      <td>0.005120</td>\n",
       "      <td>0.000393</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{'var_smoothing': 1.0000000000230258}</td>\n",
       "      <td>0.6875</td>\n",
       "      <td>0.6875</td>\n",
       "      <td>0.645833</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.680851</td>\n",
       "      <td>0.67367</td>\n",
       "      <td>0.015862</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.608081</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.664062</td>\n",
       "      <td>0.464844</td>\n",
       "      <td>0.545833</td>\n",
       "      <td>0.563231</td>\n",
       "      <td>0.067904</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.001125</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>0.004824</td>\n",
       "      <td>0.000114</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{'var_smoothing': 1.0000000047217092}</td>\n",
       "      <td>0.6875</td>\n",
       "      <td>0.6875</td>\n",
       "      <td>0.645833</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.680851</td>\n",
       "      <td>0.67367</td>\n",
       "      <td>0.015862</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.608081</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.664062</td>\n",
       "      <td>0.464844</td>\n",
       "      <td>0.545833</td>\n",
       "      <td>0.563231</td>\n",
       "      <td>0.067904</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.001094</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>0.004798</td>\n",
       "      <td>0.000140</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{'var_smoothing': 1.0000000094203925}</td>\n",
       "      <td>0.6875</td>\n",
       "      <td>0.6875</td>\n",
       "      <td>0.645833</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.680851</td>\n",
       "      <td>0.67367</td>\n",
       "      <td>0.015862</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.608081</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.664062</td>\n",
       "      <td>0.464844</td>\n",
       "      <td>0.545833</td>\n",
       "      <td>0.563231</td>\n",
       "      <td>0.067904</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.001075</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>0.004726</td>\n",
       "      <td>0.000107</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{'var_smoothing': 1.000000014119076}</td>\n",
       "      <td>0.6875</td>\n",
       "      <td>0.6875</td>\n",
       "      <td>0.645833</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.680851</td>\n",
       "      <td>0.67367</td>\n",
       "      <td>0.015862</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.608081</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.664062</td>\n",
       "      <td>0.464844</td>\n",
       "      <td>0.545833</td>\n",
       "      <td>0.563231</td>\n",
       "      <td>0.067904</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.001081</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>0.004660</td>\n",
       "      <td>0.000086</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{'var_smoothing': 1.0000000188177594}</td>\n",
       "      <td>0.6875</td>\n",
       "      <td>0.6875</td>\n",
       "      <td>0.645833</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.680851</td>\n",
       "      <td>0.67367</td>\n",
       "      <td>0.015862</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.608081</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.664062</td>\n",
       "      <td>0.464844</td>\n",
       "      <td>0.545833</td>\n",
       "      <td>0.563231</td>\n",
       "      <td>0.067904</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.001076</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>0.004728</td>\n",
       "      <td>0.000124</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{'var_smoothing': 1.0000000235164428}</td>\n",
       "      <td>0.6875</td>\n",
       "      <td>0.6875</td>\n",
       "      <td>0.645833</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.680851</td>\n",
       "      <td>0.67367</td>\n",
       "      <td>0.015862</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.608081</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.664062</td>\n",
       "      <td>0.464844</td>\n",
       "      <td>0.545833</td>\n",
       "      <td>0.563231</td>\n",
       "      <td>0.067904</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.001153</td>\n",
       "      <td>0.000128</td>\n",
       "      <td>0.004841</td>\n",
       "      <td>0.000210</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{'var_smoothing': 1.0000000282151262}</td>\n",
       "      <td>0.6875</td>\n",
       "      <td>0.6875</td>\n",
       "      <td>0.645833</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.680851</td>\n",
       "      <td>0.67367</td>\n",
       "      <td>0.015862</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.608081</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.664062</td>\n",
       "      <td>0.464844</td>\n",
       "      <td>0.545833</td>\n",
       "      <td>0.563231</td>\n",
       "      <td>0.067904</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.001077</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>0.004745</td>\n",
       "      <td>0.000099</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{'var_smoothing': 1.0000000329138097}</td>\n",
       "      <td>0.6875</td>\n",
       "      <td>0.6875</td>\n",
       "      <td>0.645833</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.680851</td>\n",
       "      <td>0.67367</td>\n",
       "      <td>0.015862</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.608081</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.664062</td>\n",
       "      <td>0.464844</td>\n",
       "      <td>0.545833</td>\n",
       "      <td>0.563231</td>\n",
       "      <td>0.067904</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.001098</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.004658</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{'var_smoothing': 1.0000000376124933}</td>\n",
       "      <td>0.6875</td>\n",
       "      <td>0.6875</td>\n",
       "      <td>0.645833</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.680851</td>\n",
       "      <td>0.67367</td>\n",
       "      <td>0.015862</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.608081</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.664062</td>\n",
       "      <td>0.464844</td>\n",
       "      <td>0.545833</td>\n",
       "      <td>0.563231</td>\n",
       "      <td>0.067904</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.001068</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.004648</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{'var_smoothing': 1.0000000423111768}</td>\n",
       "      <td>0.6875</td>\n",
       "      <td>0.6875</td>\n",
       "      <td>0.645833</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.680851</td>\n",
       "      <td>0.67367</td>\n",
       "      <td>0.015862</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.608081</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.664062</td>\n",
       "      <td>0.464844</td>\n",
       "      <td>0.545833</td>\n",
       "      <td>0.563231</td>\n",
       "      <td>0.067904</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.001074</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.004710</td>\n",
       "      <td>0.000086</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{'var_smoothing': 1.0000000470098602}</td>\n",
       "      <td>0.6875</td>\n",
       "      <td>0.6875</td>\n",
       "      <td>0.645833</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.680851</td>\n",
       "      <td>0.67367</td>\n",
       "      <td>0.015862</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.608081</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.664062</td>\n",
       "      <td>0.464844</td>\n",
       "      <td>0.545833</td>\n",
       "      <td>0.563231</td>\n",
       "      <td>0.067904</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.001127</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>0.004720</td>\n",
       "      <td>0.000117</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{'var_smoothing': 1.000000051708544}</td>\n",
       "      <td>0.6875</td>\n",
       "      <td>0.6875</td>\n",
       "      <td>0.645833</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.680851</td>\n",
       "      <td>0.67367</td>\n",
       "      <td>0.015862</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.608081</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.664062</td>\n",
       "      <td>0.464844</td>\n",
       "      <td>0.545833</td>\n",
       "      <td>0.563231</td>\n",
       "      <td>0.067904</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.001067</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>0.004680</td>\n",
       "      <td>0.000129</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{'var_smoothing': 1.0000000564072276}</td>\n",
       "      <td>0.6875</td>\n",
       "      <td>0.6875</td>\n",
       "      <td>0.645833</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.680851</td>\n",
       "      <td>0.67367</td>\n",
       "      <td>0.015862</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.608081</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.664062</td>\n",
       "      <td>0.464844</td>\n",
       "      <td>0.545833</td>\n",
       "      <td>0.563231</td>\n",
       "      <td>0.067904</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.001067</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.004834</td>\n",
       "      <td>0.000319</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{'var_smoothing': 1.000000061105911}</td>\n",
       "      <td>0.6875</td>\n",
       "      <td>0.6875</td>\n",
       "      <td>0.645833</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.680851</td>\n",
       "      <td>0.67367</td>\n",
       "      <td>0.015862</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.608081</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.664062</td>\n",
       "      <td>0.464844</td>\n",
       "      <td>0.545833</td>\n",
       "      <td>0.563231</td>\n",
       "      <td>0.067904</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.001073</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.004677</td>\n",
       "      <td>0.000086</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{'var_smoothing': 1.0000000658045947}</td>\n",
       "      <td>0.6875</td>\n",
       "      <td>0.6875</td>\n",
       "      <td>0.645833</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.680851</td>\n",
       "      <td>0.67367</td>\n",
       "      <td>0.015862</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.608081</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.664062</td>\n",
       "      <td>0.464844</td>\n",
       "      <td>0.545833</td>\n",
       "      <td>0.563231</td>\n",
       "      <td>0.067904</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.001049</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.004637</td>\n",
       "      <td>0.000051</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{'var_smoothing': 1.0000000705032783}</td>\n",
       "      <td>0.6875</td>\n",
       "      <td>0.6875</td>\n",
       "      <td>0.645833</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.680851</td>\n",
       "      <td>0.67367</td>\n",
       "      <td>0.015862</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.608081</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.664062</td>\n",
       "      <td>0.464844</td>\n",
       "      <td>0.545833</td>\n",
       "      <td>0.563231</td>\n",
       "      <td>0.067904</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.001068</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>0.004717</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{'var_smoothing': 1.000000075201962}</td>\n",
       "      <td>0.6875</td>\n",
       "      <td>0.6875</td>\n",
       "      <td>0.645833</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.680851</td>\n",
       "      <td>0.67367</td>\n",
       "      <td>0.015862</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.608081</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.664062</td>\n",
       "      <td>0.464844</td>\n",
       "      <td>0.545833</td>\n",
       "      <td>0.563231</td>\n",
       "      <td>0.067904</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.001073</td>\n",
       "      <td>0.000053</td>\n",
       "      <td>0.004634</td>\n",
       "      <td>0.000086</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{'var_smoothing': 1.0000000799006457}</td>\n",
       "      <td>0.6875</td>\n",
       "      <td>0.6875</td>\n",
       "      <td>0.645833</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.680851</td>\n",
       "      <td>0.67367</td>\n",
       "      <td>0.015862</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.608081</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.664062</td>\n",
       "      <td>0.464844</td>\n",
       "      <td>0.545833</td>\n",
       "      <td>0.563231</td>\n",
       "      <td>0.067904</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.001046</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.004657</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{'var_smoothing': 1.0000000845993295}</td>\n",
       "      <td>0.6875</td>\n",
       "      <td>0.6875</td>\n",
       "      <td>0.645833</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.680851</td>\n",
       "      <td>0.67367</td>\n",
       "      <td>0.015862</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.608081</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.664062</td>\n",
       "      <td>0.464844</td>\n",
       "      <td>0.545833</td>\n",
       "      <td>0.563231</td>\n",
       "      <td>0.067904</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.001063</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.004705</td>\n",
       "      <td>0.000095</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{'var_smoothing': 1.0000000892980132}</td>\n",
       "      <td>0.6875</td>\n",
       "      <td>0.6875</td>\n",
       "      <td>0.645833</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.680851</td>\n",
       "      <td>0.67367</td>\n",
       "      <td>0.015862</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.608081</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.664062</td>\n",
       "      <td>0.464844</td>\n",
       "      <td>0.545833</td>\n",
       "      <td>0.563231</td>\n",
       "      <td>0.067904</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.001053</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.004876</td>\n",
       "      <td>0.000253</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{'var_smoothing': 1.000000093996697}</td>\n",
       "      <td>0.6875</td>\n",
       "      <td>0.6875</td>\n",
       "      <td>0.645833</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.680851</td>\n",
       "      <td>0.67367</td>\n",
       "      <td>0.015862</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.608081</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.664062</td>\n",
       "      <td>0.464844</td>\n",
       "      <td>0.545833</td>\n",
       "      <td>0.563231</td>\n",
       "      <td>0.067904</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.001058</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.004668</td>\n",
       "      <td>0.000080</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{'var_smoothing': 1.0000000986953808}</td>\n",
       "      <td>0.6875</td>\n",
       "      <td>0.6875</td>\n",
       "      <td>0.645833</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.680851</td>\n",
       "      <td>0.67367</td>\n",
       "      <td>0.015862</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.608081</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.664062</td>\n",
       "      <td>0.464844</td>\n",
       "      <td>0.545833</td>\n",
       "      <td>0.563231</td>\n",
       "      <td>0.067904</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.001051</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.004676</td>\n",
       "      <td>0.000112</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{'var_smoothing': 1.0000001033940646}</td>\n",
       "      <td>0.6875</td>\n",
       "      <td>0.6875</td>\n",
       "      <td>0.645833</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.680851</td>\n",
       "      <td>0.67367</td>\n",
       "      <td>0.015862</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.608081</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.664062</td>\n",
       "      <td>0.464844</td>\n",
       "      <td>0.545833</td>\n",
       "      <td>0.563231</td>\n",
       "      <td>0.067904</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.001048</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.004707</td>\n",
       "      <td>0.000116</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{'var_smoothing': 1.0000001080927483}</td>\n",
       "      <td>0.6875</td>\n",
       "      <td>0.6875</td>\n",
       "      <td>0.645833</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.680851</td>\n",
       "      <td>0.67367</td>\n",
       "      <td>0.015862</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.608081</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.664062</td>\n",
       "      <td>0.464844</td>\n",
       "      <td>0.545833</td>\n",
       "      <td>0.563231</td>\n",
       "      <td>0.067904</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.001059</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.004671</td>\n",
       "      <td>0.000089</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{'var_smoothing': 1.0000001127914322}</td>\n",
       "      <td>0.6875</td>\n",
       "      <td>0.6875</td>\n",
       "      <td>0.645833</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.680851</td>\n",
       "      <td>0.67367</td>\n",
       "      <td>0.015862</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.608081</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.664062</td>\n",
       "      <td>0.464844</td>\n",
       "      <td>0.545833</td>\n",
       "      <td>0.563231</td>\n",
       "      <td>0.067904</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.001070</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.004664</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{'var_smoothing': 1.000000117490116}</td>\n",
       "      <td>0.6875</td>\n",
       "      <td>0.6875</td>\n",
       "      <td>0.645833</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.680851</td>\n",
       "      <td>0.67367</td>\n",
       "      <td>0.015862</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.608081</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.664062</td>\n",
       "      <td>0.464844</td>\n",
       "      <td>0.545833</td>\n",
       "      <td>0.563231</td>\n",
       "      <td>0.067904</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.001063</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.004719</td>\n",
       "      <td>0.000111</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{'var_smoothing': 1.0000001221888}</td>\n",
       "      <td>0.6875</td>\n",
       "      <td>0.6875</td>\n",
       "      <td>0.645833</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.680851</td>\n",
       "      <td>0.67367</td>\n",
       "      <td>0.015862</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.608081</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.664062</td>\n",
       "      <td>0.464844</td>\n",
       "      <td>0.545833</td>\n",
       "      <td>0.563231</td>\n",
       "      <td>0.067904</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.001061</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>0.004852</td>\n",
       "      <td>0.000218</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{'var_smoothing': 1.000000126887484}</td>\n",
       "      <td>0.6875</td>\n",
       "      <td>0.6875</td>\n",
       "      <td>0.645833</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.680851</td>\n",
       "      <td>0.67367</td>\n",
       "      <td>0.015862</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.608081</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.664062</td>\n",
       "      <td>0.464844</td>\n",
       "      <td>0.545833</td>\n",
       "      <td>0.563231</td>\n",
       "      <td>0.067904</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.001069</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.004732</td>\n",
       "      <td>0.000099</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{'var_smoothing': 1.000000131586168}</td>\n",
       "      <td>0.6875</td>\n",
       "      <td>0.6875</td>\n",
       "      <td>0.645833</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.680851</td>\n",
       "      <td>0.67367</td>\n",
       "      <td>0.015862</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.608081</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.664062</td>\n",
       "      <td>0.464844</td>\n",
       "      <td>0.545833</td>\n",
       "      <td>0.563231</td>\n",
       "      <td>0.067904</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.001065</td>\n",
       "      <td>0.000043</td>\n",
       "      <td>0.004656</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{'var_smoothing': 1.0000001362848518}</td>\n",
       "      <td>0.6875</td>\n",
       "      <td>0.6875</td>\n",
       "      <td>0.645833</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.680851</td>\n",
       "      <td>0.67367</td>\n",
       "      <td>0.015862</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.608081</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.664062</td>\n",
       "      <td>0.464844</td>\n",
       "      <td>0.545833</td>\n",
       "      <td>0.563231</td>\n",
       "      <td>0.067904</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.001076</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>0.004681</td>\n",
       "      <td>0.000079</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{'var_smoothing': 1.000000140983536}</td>\n",
       "      <td>0.6875</td>\n",
       "      <td>0.6875</td>\n",
       "      <td>0.645833</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.680851</td>\n",
       "      <td>0.67367</td>\n",
       "      <td>0.015862</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.608081</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.664062</td>\n",
       "      <td>0.464844</td>\n",
       "      <td>0.545833</td>\n",
       "      <td>0.563231</td>\n",
       "      <td>0.067904</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.001053</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>0.004685</td>\n",
       "      <td>0.000083</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{'var_smoothing': 1.0000001456822198}</td>\n",
       "      <td>0.6875</td>\n",
       "      <td>0.6875</td>\n",
       "      <td>0.645833</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.680851</td>\n",
       "      <td>0.67367</td>\n",
       "      <td>0.015862</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.608081</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.664062</td>\n",
       "      <td>0.464844</td>\n",
       "      <td>0.545833</td>\n",
       "      <td>0.563231</td>\n",
       "      <td>0.067904</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.001073</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.004782</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{'var_smoothing': 1.000000150380904}</td>\n",
       "      <td>0.6875</td>\n",
       "      <td>0.6875</td>\n",
       "      <td>0.645833</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.680851</td>\n",
       "      <td>0.67367</td>\n",
       "      <td>0.015862</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.608081</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.664062</td>\n",
       "      <td>0.464844</td>\n",
       "      <td>0.545833</td>\n",
       "      <td>0.563231</td>\n",
       "      <td>0.067904</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.001097</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>0.004708</td>\n",
       "      <td>0.000102</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{'var_smoothing': 1.000000155079588}</td>\n",
       "      <td>0.6875</td>\n",
       "      <td>0.6875</td>\n",
       "      <td>0.645833</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.680851</td>\n",
       "      <td>0.67367</td>\n",
       "      <td>0.015862</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.608081</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.664062</td>\n",
       "      <td>0.464844</td>\n",
       "      <td>0.545833</td>\n",
       "      <td>0.563231</td>\n",
       "      <td>0.067904</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.001080</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.004965</td>\n",
       "      <td>0.000216</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{'var_smoothing': 1.000000159778272}</td>\n",
       "      <td>0.6875</td>\n",
       "      <td>0.6875</td>\n",
       "      <td>0.645833</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.680851</td>\n",
       "      <td>0.67367</td>\n",
       "      <td>0.015862</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.608081</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.664062</td>\n",
       "      <td>0.464844</td>\n",
       "      <td>0.545833</td>\n",
       "      <td>0.563231</td>\n",
       "      <td>0.067904</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.001100</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>0.004747</td>\n",
       "      <td>0.000097</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{'var_smoothing': 1.000000164476956}</td>\n",
       "      <td>0.6875</td>\n",
       "      <td>0.6875</td>\n",
       "      <td>0.645833</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.680851</td>\n",
       "      <td>0.67367</td>\n",
       "      <td>0.015862</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.608081</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.664062</td>\n",
       "      <td>0.464844</td>\n",
       "      <td>0.545833</td>\n",
       "      <td>0.563231</td>\n",
       "      <td>0.067904</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.001083</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.004752</td>\n",
       "      <td>0.000075</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{'var_smoothing': 1.0000001691756402}</td>\n",
       "      <td>0.6875</td>\n",
       "      <td>0.6875</td>\n",
       "      <td>0.645833</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.680851</td>\n",
       "      <td>0.67367</td>\n",
       "      <td>0.015862</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.608081</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.664062</td>\n",
       "      <td>0.464844</td>\n",
       "      <td>0.545833</td>\n",
       "      <td>0.563231</td>\n",
       "      <td>0.067904</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.001090</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.004764</td>\n",
       "      <td>0.000078</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{'var_smoothing': 1.0000001738743245}</td>\n",
       "      <td>0.6875</td>\n",
       "      <td>0.6875</td>\n",
       "      <td>0.645833</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.680851</td>\n",
       "      <td>0.67367</td>\n",
       "      <td>0.015862</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.608081</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.664062</td>\n",
       "      <td>0.464844</td>\n",
       "      <td>0.545833</td>\n",
       "      <td>0.563231</td>\n",
       "      <td>0.067904</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.001100</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.004778</td>\n",
       "      <td>0.000138</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{'var_smoothing': 1.0000001785730086}</td>\n",
       "      <td>0.6875</td>\n",
       "      <td>0.6875</td>\n",
       "      <td>0.645833</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.680851</td>\n",
       "      <td>0.67367</td>\n",
       "      <td>0.015862</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.608081</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.664062</td>\n",
       "      <td>0.464844</td>\n",
       "      <td>0.545833</td>\n",
       "      <td>0.563231</td>\n",
       "      <td>0.067904</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.001089</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>0.004764</td>\n",
       "      <td>0.000104</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{'var_smoothing': 1.0000001832716927}</td>\n",
       "      <td>0.6875</td>\n",
       "      <td>0.6875</td>\n",
       "      <td>0.645833</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.680851</td>\n",
       "      <td>0.67367</td>\n",
       "      <td>0.015862</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.608081</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.664062</td>\n",
       "      <td>0.464844</td>\n",
       "      <td>0.545833</td>\n",
       "      <td>0.563231</td>\n",
       "      <td>0.067904</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.001090</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.004777</td>\n",
       "      <td>0.000096</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{'var_smoothing': 1.000000187970377}</td>\n",
       "      <td>0.6875</td>\n",
       "      <td>0.6875</td>\n",
       "      <td>0.645833</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.680851</td>\n",
       "      <td>0.67367</td>\n",
       "      <td>0.015862</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.608081</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.664062</td>\n",
       "      <td>0.464844</td>\n",
       "      <td>0.545833</td>\n",
       "      <td>0.563231</td>\n",
       "      <td>0.067904</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.001130</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>0.004889</td>\n",
       "      <td>0.000139</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{'var_smoothing': 1.0000001926690611}</td>\n",
       "      <td>0.6875</td>\n",
       "      <td>0.6875</td>\n",
       "      <td>0.645833</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.680851</td>\n",
       "      <td>0.67367</td>\n",
       "      <td>0.015862</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.608081</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.664062</td>\n",
       "      <td>0.464844</td>\n",
       "      <td>0.545833</td>\n",
       "      <td>0.563231</td>\n",
       "      <td>0.067904</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.001089</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>0.004705</td>\n",
       "      <td>0.000089</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{'var_smoothing': 1.0000001973677455}</td>\n",
       "      <td>0.6875</td>\n",
       "      <td>0.6875</td>\n",
       "      <td>0.645833</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.680851</td>\n",
       "      <td>0.67367</td>\n",
       "      <td>0.015862</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.608081</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.664062</td>\n",
       "      <td>0.464844</td>\n",
       "      <td>0.545833</td>\n",
       "      <td>0.563231</td>\n",
       "      <td>0.067904</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.001080</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.004720</td>\n",
       "      <td>0.000067</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{'var_smoothing': 1.0000002020664298}</td>\n",
       "      <td>0.6875</td>\n",
       "      <td>0.6875</td>\n",
       "      <td>0.645833</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.680851</td>\n",
       "      <td>0.67367</td>\n",
       "      <td>0.015862</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.608081</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.664062</td>\n",
       "      <td>0.464844</td>\n",
       "      <td>0.545833</td>\n",
       "      <td>0.563231</td>\n",
       "      <td>0.067904</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.001066</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.004789</td>\n",
       "      <td>0.000078</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{'var_smoothing': 1.000000206765114}</td>\n",
       "      <td>0.6875</td>\n",
       "      <td>0.6875</td>\n",
       "      <td>0.645833</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.680851</td>\n",
       "      <td>0.67367</td>\n",
       "      <td>0.015862</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.608081</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.664062</td>\n",
       "      <td>0.464844</td>\n",
       "      <td>0.545833</td>\n",
       "      <td>0.563231</td>\n",
       "      <td>0.067904</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.001107</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>0.004745</td>\n",
       "      <td>0.000095</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{'var_smoothing': 1.0000002114637982}</td>\n",
       "      <td>0.6875</td>\n",
       "      <td>0.6875</td>\n",
       "      <td>0.645833</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.680851</td>\n",
       "      <td>0.67367</td>\n",
       "      <td>0.015862</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.608081</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.664062</td>\n",
       "      <td>0.464844</td>\n",
       "      <td>0.545833</td>\n",
       "      <td>0.563231</td>\n",
       "      <td>0.067904</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.001060</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.004721</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{'var_smoothing': 1.0000002161624826}</td>\n",
       "      <td>0.6875</td>\n",
       "      <td>0.6875</td>\n",
       "      <td>0.645833</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.680851</td>\n",
       "      <td>0.67367</td>\n",
       "      <td>0.015862</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.608081</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.664062</td>\n",
       "      <td>0.464844</td>\n",
       "      <td>0.545833</td>\n",
       "      <td>0.563231</td>\n",
       "      <td>0.067904</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.001073</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.004723</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{'var_smoothing': 1.000000220861167}</td>\n",
       "      <td>0.6875</td>\n",
       "      <td>0.6875</td>\n",
       "      <td>0.645833</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.680851</td>\n",
       "      <td>0.67367</td>\n",
       "      <td>0.015862</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.608081</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.664062</td>\n",
       "      <td>0.464844</td>\n",
       "      <td>0.545833</td>\n",
       "      <td>0.563231</td>\n",
       "      <td>0.067904</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.001205</td>\n",
       "      <td>0.000150</td>\n",
       "      <td>0.004781</td>\n",
       "      <td>0.000113</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{'var_smoothing': 1.0000002255598515}</td>\n",
       "      <td>0.6875</td>\n",
       "      <td>0.6875</td>\n",
       "      <td>0.645833</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.680851</td>\n",
       "      <td>0.67367</td>\n",
       "      <td>0.015862</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.608081</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.664062</td>\n",
       "      <td>0.464844</td>\n",
       "      <td>0.545833</td>\n",
       "      <td>0.563231</td>\n",
       "      <td>0.067904</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.001074</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.004780</td>\n",
       "      <td>0.000041</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{'var_smoothing': 1.0000002302585358}</td>\n",
       "      <td>0.6875</td>\n",
       "      <td>0.6875</td>\n",
       "      <td>0.645833</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.680851</td>\n",
       "      <td>0.67367</td>\n",
       "      <td>0.015862</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.608081</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.664062</td>\n",
       "      <td>0.464844</td>\n",
       "      <td>0.545833</td>\n",
       "      <td>0.563231</td>\n",
       "      <td>0.067904</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0        0.001201      0.000103         0.005120        0.000393   \n",
       "1        0.001125      0.000040         0.004824        0.000114   \n",
       "2        0.001094      0.000037         0.004798        0.000140   \n",
       "3        0.001075      0.000027         0.004726        0.000107   \n",
       "4        0.001081      0.000033         0.004660        0.000086   \n",
       "5        0.001076      0.000034         0.004728        0.000124   \n",
       "6        0.001153      0.000128         0.004841        0.000210   \n",
       "7        0.001077      0.000030         0.004745        0.000099   \n",
       "8        0.001098      0.000020         0.004658        0.000010   \n",
       "9        0.001068      0.000014         0.004648        0.000015   \n",
       "10       0.001074      0.000012         0.004710        0.000086   \n",
       "11       0.001127      0.000040         0.004720        0.000117   \n",
       "12       0.001067      0.000039         0.004680        0.000129   \n",
       "13       0.001067      0.000026         0.004834        0.000319   \n",
       "14       0.001073      0.000023         0.004677        0.000086   \n",
       "15       0.001049      0.000012         0.004637        0.000051   \n",
       "16       0.001068      0.000024         0.004717        0.000069   \n",
       "17       0.001073      0.000053         0.004634        0.000086   \n",
       "18       0.001046      0.000011         0.004657        0.000058   \n",
       "19       0.001063      0.000018         0.004705        0.000095   \n",
       "20       0.001053      0.000015         0.004876        0.000253   \n",
       "21       0.001058      0.000019         0.004668        0.000080   \n",
       "22       0.001051      0.000042         0.004676        0.000112   \n",
       "23       0.001048      0.000007         0.004707        0.000116   \n",
       "24       0.001059      0.000009         0.004671        0.000089   \n",
       "25       0.001070      0.000023         0.004664        0.000060   \n",
       "26       0.001063      0.000015         0.004719        0.000111   \n",
       "27       0.001061      0.000030         0.004852        0.000218   \n",
       "28       0.001069      0.000042         0.004732        0.000099   \n",
       "29       0.001065      0.000043         0.004656        0.000056   \n",
       "30       0.001076      0.000045         0.004681        0.000079   \n",
       "31       0.001053      0.000025         0.004685        0.000083   \n",
       "32       0.001073      0.000031         0.004782        0.000039   \n",
       "33       0.001097      0.000025         0.004708        0.000102   \n",
       "34       0.001080      0.000021         0.004965        0.000216   \n",
       "35       0.001100      0.000052         0.004747        0.000097   \n",
       "36       0.001083      0.000023         0.004752        0.000075   \n",
       "37       0.001090      0.000023         0.004764        0.000078   \n",
       "38       0.001100      0.000012         0.004778        0.000138   \n",
       "39       0.001089      0.000039         0.004764        0.000104   \n",
       "40       0.001090      0.000022         0.004777        0.000096   \n",
       "41       0.001130      0.000037         0.004889        0.000139   \n",
       "42       0.001089      0.000029         0.004705        0.000089   \n",
       "43       0.001080      0.000005         0.004720        0.000067   \n",
       "44       0.001066      0.000018         0.004789        0.000078   \n",
       "45       0.001107      0.000027         0.004745        0.000095   \n",
       "46       0.001060      0.000011         0.004721        0.000031   \n",
       "47       0.001073      0.000014         0.004723        0.000039   \n",
       "48       0.001205      0.000150         0.004781        0.000113   \n",
       "49       0.001074      0.000012         0.004780        0.000041   \n",
       "\n",
       "   param_var_smoothing                                 params  \\\n",
       "0                  1.0  {'var_smoothing': 1.0000000000230258}   \n",
       "1                  1.0  {'var_smoothing': 1.0000000047217092}   \n",
       "2                  1.0  {'var_smoothing': 1.0000000094203925}   \n",
       "3                  1.0   {'var_smoothing': 1.000000014119076}   \n",
       "4                  1.0  {'var_smoothing': 1.0000000188177594}   \n",
       "5                  1.0  {'var_smoothing': 1.0000000235164428}   \n",
       "6                  1.0  {'var_smoothing': 1.0000000282151262}   \n",
       "7                  1.0  {'var_smoothing': 1.0000000329138097}   \n",
       "8                  1.0  {'var_smoothing': 1.0000000376124933}   \n",
       "9                  1.0  {'var_smoothing': 1.0000000423111768}   \n",
       "10                 1.0  {'var_smoothing': 1.0000000470098602}   \n",
       "11                 1.0   {'var_smoothing': 1.000000051708544}   \n",
       "12                 1.0  {'var_smoothing': 1.0000000564072276}   \n",
       "13                 1.0   {'var_smoothing': 1.000000061105911}   \n",
       "14                 1.0  {'var_smoothing': 1.0000000658045947}   \n",
       "15                 1.0  {'var_smoothing': 1.0000000705032783}   \n",
       "16                 1.0   {'var_smoothing': 1.000000075201962}   \n",
       "17                 1.0  {'var_smoothing': 1.0000000799006457}   \n",
       "18                 1.0  {'var_smoothing': 1.0000000845993295}   \n",
       "19                 1.0  {'var_smoothing': 1.0000000892980132}   \n",
       "20                 1.0   {'var_smoothing': 1.000000093996697}   \n",
       "21                 1.0  {'var_smoothing': 1.0000000986953808}   \n",
       "22                 1.0  {'var_smoothing': 1.0000001033940646}   \n",
       "23                 1.0  {'var_smoothing': 1.0000001080927483}   \n",
       "24                 1.0  {'var_smoothing': 1.0000001127914322}   \n",
       "25                 1.0   {'var_smoothing': 1.000000117490116}   \n",
       "26                 1.0     {'var_smoothing': 1.0000001221888}   \n",
       "27                 1.0   {'var_smoothing': 1.000000126887484}   \n",
       "28                 1.0   {'var_smoothing': 1.000000131586168}   \n",
       "29                 1.0  {'var_smoothing': 1.0000001362848518}   \n",
       "30                 1.0   {'var_smoothing': 1.000000140983536}   \n",
       "31                 1.0  {'var_smoothing': 1.0000001456822198}   \n",
       "32                 1.0   {'var_smoothing': 1.000000150380904}   \n",
       "33                 1.0   {'var_smoothing': 1.000000155079588}   \n",
       "34                 1.0   {'var_smoothing': 1.000000159778272}   \n",
       "35                 1.0   {'var_smoothing': 1.000000164476956}   \n",
       "36                 1.0  {'var_smoothing': 1.0000001691756402}   \n",
       "37                 1.0  {'var_smoothing': 1.0000001738743245}   \n",
       "38                 1.0  {'var_smoothing': 1.0000001785730086}   \n",
       "39                 1.0  {'var_smoothing': 1.0000001832716927}   \n",
       "40                 1.0   {'var_smoothing': 1.000000187970377}   \n",
       "41                 1.0  {'var_smoothing': 1.0000001926690611}   \n",
       "42                 1.0  {'var_smoothing': 1.0000001973677455}   \n",
       "43                 1.0  {'var_smoothing': 1.0000002020664298}   \n",
       "44                 1.0   {'var_smoothing': 1.000000206765114}   \n",
       "45                 1.0  {'var_smoothing': 1.0000002114637982}   \n",
       "46                 1.0  {'var_smoothing': 1.0000002161624826}   \n",
       "47                 1.0   {'var_smoothing': 1.000000220861167}   \n",
       "48                 1.0  {'var_smoothing': 1.0000002255598515}   \n",
       "49                 1.0  {'var_smoothing': 1.0000002302585358}   \n",
       "\n",
       "    split0_test_accuracy  split1_test_accuracy  split2_test_accuracy  \\\n",
       "0                 0.6875                0.6875              0.645833   \n",
       "1                 0.6875                0.6875              0.645833   \n",
       "2                 0.6875                0.6875              0.645833   \n",
       "3                 0.6875                0.6875              0.645833   \n",
       "4                 0.6875                0.6875              0.645833   \n",
       "5                 0.6875                0.6875              0.645833   \n",
       "6                 0.6875                0.6875              0.645833   \n",
       "7                 0.6875                0.6875              0.645833   \n",
       "8                 0.6875                0.6875              0.645833   \n",
       "9                 0.6875                0.6875              0.645833   \n",
       "10                0.6875                0.6875              0.645833   \n",
       "11                0.6875                0.6875              0.645833   \n",
       "12                0.6875                0.6875              0.645833   \n",
       "13                0.6875                0.6875              0.645833   \n",
       "14                0.6875                0.6875              0.645833   \n",
       "15                0.6875                0.6875              0.645833   \n",
       "16                0.6875                0.6875              0.645833   \n",
       "17                0.6875                0.6875              0.645833   \n",
       "18                0.6875                0.6875              0.645833   \n",
       "19                0.6875                0.6875              0.645833   \n",
       "20                0.6875                0.6875              0.645833   \n",
       "21                0.6875                0.6875              0.645833   \n",
       "22                0.6875                0.6875              0.645833   \n",
       "23                0.6875                0.6875              0.645833   \n",
       "24                0.6875                0.6875              0.645833   \n",
       "25                0.6875                0.6875              0.645833   \n",
       "26                0.6875                0.6875              0.645833   \n",
       "27                0.6875                0.6875              0.645833   \n",
       "28                0.6875                0.6875              0.645833   \n",
       "29                0.6875                0.6875              0.645833   \n",
       "30                0.6875                0.6875              0.645833   \n",
       "31                0.6875                0.6875              0.645833   \n",
       "32                0.6875                0.6875              0.645833   \n",
       "33                0.6875                0.6875              0.645833   \n",
       "34                0.6875                0.6875              0.645833   \n",
       "35                0.6875                0.6875              0.645833   \n",
       "36                0.6875                0.6875              0.645833   \n",
       "37                0.6875                0.6875              0.645833   \n",
       "38                0.6875                0.6875              0.645833   \n",
       "39                0.6875                0.6875              0.645833   \n",
       "40                0.6875                0.6875              0.645833   \n",
       "41                0.6875                0.6875              0.645833   \n",
       "42                0.6875                0.6875              0.645833   \n",
       "43                0.6875                0.6875              0.645833   \n",
       "44                0.6875                0.6875              0.645833   \n",
       "45                0.6875                0.6875              0.645833   \n",
       "46                0.6875                0.6875              0.645833   \n",
       "47                0.6875                0.6875              0.645833   \n",
       "48                0.6875                0.6875              0.645833   \n",
       "49                0.6875                0.6875              0.645833   \n",
       "\n",
       "    split3_test_accuracy  split4_test_accuracy  mean_test_accuracy  \\\n",
       "0               0.666667              0.680851             0.67367   \n",
       "1               0.666667              0.680851             0.67367   \n",
       "2               0.666667              0.680851             0.67367   \n",
       "3               0.666667              0.680851             0.67367   \n",
       "4               0.666667              0.680851             0.67367   \n",
       "5               0.666667              0.680851             0.67367   \n",
       "6               0.666667              0.680851             0.67367   \n",
       "7               0.666667              0.680851             0.67367   \n",
       "8               0.666667              0.680851             0.67367   \n",
       "9               0.666667              0.680851             0.67367   \n",
       "10              0.666667              0.680851             0.67367   \n",
       "11              0.666667              0.680851             0.67367   \n",
       "12              0.666667              0.680851             0.67367   \n",
       "13              0.666667              0.680851             0.67367   \n",
       "14              0.666667              0.680851             0.67367   \n",
       "15              0.666667              0.680851             0.67367   \n",
       "16              0.666667              0.680851             0.67367   \n",
       "17              0.666667              0.680851             0.67367   \n",
       "18              0.666667              0.680851             0.67367   \n",
       "19              0.666667              0.680851             0.67367   \n",
       "20              0.666667              0.680851             0.67367   \n",
       "21              0.666667              0.680851             0.67367   \n",
       "22              0.666667              0.680851             0.67367   \n",
       "23              0.666667              0.680851             0.67367   \n",
       "24              0.666667              0.680851             0.67367   \n",
       "25              0.666667              0.680851             0.67367   \n",
       "26              0.666667              0.680851             0.67367   \n",
       "27              0.666667              0.680851             0.67367   \n",
       "28              0.666667              0.680851             0.67367   \n",
       "29              0.666667              0.680851             0.67367   \n",
       "30              0.666667              0.680851             0.67367   \n",
       "31              0.666667              0.680851             0.67367   \n",
       "32              0.666667              0.680851             0.67367   \n",
       "33              0.666667              0.680851             0.67367   \n",
       "34              0.666667              0.680851             0.67367   \n",
       "35              0.666667              0.680851             0.67367   \n",
       "36              0.666667              0.680851             0.67367   \n",
       "37              0.666667              0.680851             0.67367   \n",
       "38              0.666667              0.680851             0.67367   \n",
       "39              0.666667              0.680851             0.67367   \n",
       "40              0.666667              0.680851             0.67367   \n",
       "41              0.666667              0.680851             0.67367   \n",
       "42              0.666667              0.680851             0.67367   \n",
       "43              0.666667              0.680851             0.67367   \n",
       "44              0.666667              0.680851             0.67367   \n",
       "45              0.666667              0.680851             0.67367   \n",
       "46              0.666667              0.680851             0.67367   \n",
       "47              0.666667              0.680851             0.67367   \n",
       "48              0.666667              0.680851             0.67367   \n",
       "49              0.666667              0.680851             0.67367   \n",
       "\n",
       "    std_test_accuracy  rank_test_accuracy  split0_test_precision  \\\n",
       "0            0.015862                   1                    0.0   \n",
       "1            0.015862                   1                    0.0   \n",
       "2            0.015862                   1                    0.0   \n",
       "3            0.015862                   1                    0.0   \n",
       "4            0.015862                   1                    0.0   \n",
       "5            0.015862                   1                    0.0   \n",
       "6            0.015862                   1                    0.0   \n",
       "7            0.015862                   1                    0.0   \n",
       "8            0.015862                   1                    0.0   \n",
       "9            0.015862                   1                    0.0   \n",
       "10           0.015862                   1                    0.0   \n",
       "11           0.015862                   1                    0.0   \n",
       "12           0.015862                   1                    0.0   \n",
       "13           0.015862                   1                    0.0   \n",
       "14           0.015862                   1                    0.0   \n",
       "15           0.015862                   1                    0.0   \n",
       "16           0.015862                   1                    0.0   \n",
       "17           0.015862                   1                    0.0   \n",
       "18           0.015862                   1                    0.0   \n",
       "19           0.015862                   1                    0.0   \n",
       "20           0.015862                   1                    0.0   \n",
       "21           0.015862                   1                    0.0   \n",
       "22           0.015862                   1                    0.0   \n",
       "23           0.015862                   1                    0.0   \n",
       "24           0.015862                   1                    0.0   \n",
       "25           0.015862                   1                    0.0   \n",
       "26           0.015862                   1                    0.0   \n",
       "27           0.015862                   1                    0.0   \n",
       "28           0.015862                   1                    0.0   \n",
       "29           0.015862                   1                    0.0   \n",
       "30           0.015862                   1                    0.0   \n",
       "31           0.015862                   1                    0.0   \n",
       "32           0.015862                   1                    0.0   \n",
       "33           0.015862                   1                    0.0   \n",
       "34           0.015862                   1                    0.0   \n",
       "35           0.015862                   1                    0.0   \n",
       "36           0.015862                   1                    0.0   \n",
       "37           0.015862                   1                    0.0   \n",
       "38           0.015862                   1                    0.0   \n",
       "39           0.015862                   1                    0.0   \n",
       "40           0.015862                   1                    0.0   \n",
       "41           0.015862                   1                    0.0   \n",
       "42           0.015862                   1                    0.0   \n",
       "43           0.015862                   1                    0.0   \n",
       "44           0.015862                   1                    0.0   \n",
       "45           0.015862                   1                    0.0   \n",
       "46           0.015862                   1                    0.0   \n",
       "47           0.015862                   1                    0.0   \n",
       "48           0.015862                   1                    0.0   \n",
       "49           0.015862                   1                    0.0   \n",
       "\n",
       "    split1_test_precision  split2_test_precision  split3_test_precision  \\\n",
       "0                     0.0                    0.0                    0.0   \n",
       "1                     0.0                    0.0                    0.0   \n",
       "2                     0.0                    0.0                    0.0   \n",
       "3                     0.0                    0.0                    0.0   \n",
       "4                     0.0                    0.0                    0.0   \n",
       "5                     0.0                    0.0                    0.0   \n",
       "6                     0.0                    0.0                    0.0   \n",
       "7                     0.0                    0.0                    0.0   \n",
       "8                     0.0                    0.0                    0.0   \n",
       "9                     0.0                    0.0                    0.0   \n",
       "10                    0.0                    0.0                    0.0   \n",
       "11                    0.0                    0.0                    0.0   \n",
       "12                    0.0                    0.0                    0.0   \n",
       "13                    0.0                    0.0                    0.0   \n",
       "14                    0.0                    0.0                    0.0   \n",
       "15                    0.0                    0.0                    0.0   \n",
       "16                    0.0                    0.0                    0.0   \n",
       "17                    0.0                    0.0                    0.0   \n",
       "18                    0.0                    0.0                    0.0   \n",
       "19                    0.0                    0.0                    0.0   \n",
       "20                    0.0                    0.0                    0.0   \n",
       "21                    0.0                    0.0                    0.0   \n",
       "22                    0.0                    0.0                    0.0   \n",
       "23                    0.0                    0.0                    0.0   \n",
       "24                    0.0                    0.0                    0.0   \n",
       "25                    0.0                    0.0                    0.0   \n",
       "26                    0.0                    0.0                    0.0   \n",
       "27                    0.0                    0.0                    0.0   \n",
       "28                    0.0                    0.0                    0.0   \n",
       "29                    0.0                    0.0                    0.0   \n",
       "30                    0.0                    0.0                    0.0   \n",
       "31                    0.0                    0.0                    0.0   \n",
       "32                    0.0                    0.0                    0.0   \n",
       "33                    0.0                    0.0                    0.0   \n",
       "34                    0.0                    0.0                    0.0   \n",
       "35                    0.0                    0.0                    0.0   \n",
       "36                    0.0                    0.0                    0.0   \n",
       "37                    0.0                    0.0                    0.0   \n",
       "38                    0.0                    0.0                    0.0   \n",
       "39                    0.0                    0.0                    0.0   \n",
       "40                    0.0                    0.0                    0.0   \n",
       "41                    0.0                    0.0                    0.0   \n",
       "42                    0.0                    0.0                    0.0   \n",
       "43                    0.0                    0.0                    0.0   \n",
       "44                    0.0                    0.0                    0.0   \n",
       "45                    0.0                    0.0                    0.0   \n",
       "46                    0.0                    0.0                    0.0   \n",
       "47                    0.0                    0.0                    0.0   \n",
       "48                    0.0                    0.0                    0.0   \n",
       "49                    0.0                    0.0                    0.0   \n",
       "\n",
       "    split4_test_precision  mean_test_precision  std_test_precision  \\\n",
       "0                     0.0                  0.0                 0.0   \n",
       "1                     0.0                  0.0                 0.0   \n",
       "2                     0.0                  0.0                 0.0   \n",
       "3                     0.0                  0.0                 0.0   \n",
       "4                     0.0                  0.0                 0.0   \n",
       "5                     0.0                  0.0                 0.0   \n",
       "6                     0.0                  0.0                 0.0   \n",
       "7                     0.0                  0.0                 0.0   \n",
       "8                     0.0                  0.0                 0.0   \n",
       "9                     0.0                  0.0                 0.0   \n",
       "10                    0.0                  0.0                 0.0   \n",
       "11                    0.0                  0.0                 0.0   \n",
       "12                    0.0                  0.0                 0.0   \n",
       "13                    0.0                  0.0                 0.0   \n",
       "14                    0.0                  0.0                 0.0   \n",
       "15                    0.0                  0.0                 0.0   \n",
       "16                    0.0                  0.0                 0.0   \n",
       "17                    0.0                  0.0                 0.0   \n",
       "18                    0.0                  0.0                 0.0   \n",
       "19                    0.0                  0.0                 0.0   \n",
       "20                    0.0                  0.0                 0.0   \n",
       "21                    0.0                  0.0                 0.0   \n",
       "22                    0.0                  0.0                 0.0   \n",
       "23                    0.0                  0.0                 0.0   \n",
       "24                    0.0                  0.0                 0.0   \n",
       "25                    0.0                  0.0                 0.0   \n",
       "26                    0.0                  0.0                 0.0   \n",
       "27                    0.0                  0.0                 0.0   \n",
       "28                    0.0                  0.0                 0.0   \n",
       "29                    0.0                  0.0                 0.0   \n",
       "30                    0.0                  0.0                 0.0   \n",
       "31                    0.0                  0.0                 0.0   \n",
       "32                    0.0                  0.0                 0.0   \n",
       "33                    0.0                  0.0                 0.0   \n",
       "34                    0.0                  0.0                 0.0   \n",
       "35                    0.0                  0.0                 0.0   \n",
       "36                    0.0                  0.0                 0.0   \n",
       "37                    0.0                  0.0                 0.0   \n",
       "38                    0.0                  0.0                 0.0   \n",
       "39                    0.0                  0.0                 0.0   \n",
       "40                    0.0                  0.0                 0.0   \n",
       "41                    0.0                  0.0                 0.0   \n",
       "42                    0.0                  0.0                 0.0   \n",
       "43                    0.0                  0.0                 0.0   \n",
       "44                    0.0                  0.0                 0.0   \n",
       "45                    0.0                  0.0                 0.0   \n",
       "46                    0.0                  0.0                 0.0   \n",
       "47                    0.0                  0.0                 0.0   \n",
       "48                    0.0                  0.0                 0.0   \n",
       "49                    0.0                  0.0                 0.0   \n",
       "\n",
       "    rank_test_precision  split0_test_recall  split1_test_recall  \\\n",
       "0                     1                 0.0                 0.0   \n",
       "1                     1                 0.0                 0.0   \n",
       "2                     1                 0.0                 0.0   \n",
       "3                     1                 0.0                 0.0   \n",
       "4                     1                 0.0                 0.0   \n",
       "5                     1                 0.0                 0.0   \n",
       "6                     1                 0.0                 0.0   \n",
       "7                     1                 0.0                 0.0   \n",
       "8                     1                 0.0                 0.0   \n",
       "9                     1                 0.0                 0.0   \n",
       "10                    1                 0.0                 0.0   \n",
       "11                    1                 0.0                 0.0   \n",
       "12                    1                 0.0                 0.0   \n",
       "13                    1                 0.0                 0.0   \n",
       "14                    1                 0.0                 0.0   \n",
       "15                    1                 0.0                 0.0   \n",
       "16                    1                 0.0                 0.0   \n",
       "17                    1                 0.0                 0.0   \n",
       "18                    1                 0.0                 0.0   \n",
       "19                    1                 0.0                 0.0   \n",
       "20                    1                 0.0                 0.0   \n",
       "21                    1                 0.0                 0.0   \n",
       "22                    1                 0.0                 0.0   \n",
       "23                    1                 0.0                 0.0   \n",
       "24                    1                 0.0                 0.0   \n",
       "25                    1                 0.0                 0.0   \n",
       "26                    1                 0.0                 0.0   \n",
       "27                    1                 0.0                 0.0   \n",
       "28                    1                 0.0                 0.0   \n",
       "29                    1                 0.0                 0.0   \n",
       "30                    1                 0.0                 0.0   \n",
       "31                    1                 0.0                 0.0   \n",
       "32                    1                 0.0                 0.0   \n",
       "33                    1                 0.0                 0.0   \n",
       "34                    1                 0.0                 0.0   \n",
       "35                    1                 0.0                 0.0   \n",
       "36                    1                 0.0                 0.0   \n",
       "37                    1                 0.0                 0.0   \n",
       "38                    1                 0.0                 0.0   \n",
       "39                    1                 0.0                 0.0   \n",
       "40                    1                 0.0                 0.0   \n",
       "41                    1                 0.0                 0.0   \n",
       "42                    1                 0.0                 0.0   \n",
       "43                    1                 0.0                 0.0   \n",
       "44                    1                 0.0                 0.0   \n",
       "45                    1                 0.0                 0.0   \n",
       "46                    1                 0.0                 0.0   \n",
       "47                    1                 0.0                 0.0   \n",
       "48                    1                 0.0                 0.0   \n",
       "49                    1                 0.0                 0.0   \n",
       "\n",
       "    split2_test_recall  split3_test_recall  split4_test_recall  \\\n",
       "0                  0.0                 0.0                 0.0   \n",
       "1                  0.0                 0.0                 0.0   \n",
       "2                  0.0                 0.0                 0.0   \n",
       "3                  0.0                 0.0                 0.0   \n",
       "4                  0.0                 0.0                 0.0   \n",
       "5                  0.0                 0.0                 0.0   \n",
       "6                  0.0                 0.0                 0.0   \n",
       "7                  0.0                 0.0                 0.0   \n",
       "8                  0.0                 0.0                 0.0   \n",
       "9                  0.0                 0.0                 0.0   \n",
       "10                 0.0                 0.0                 0.0   \n",
       "11                 0.0                 0.0                 0.0   \n",
       "12                 0.0                 0.0                 0.0   \n",
       "13                 0.0                 0.0                 0.0   \n",
       "14                 0.0                 0.0                 0.0   \n",
       "15                 0.0                 0.0                 0.0   \n",
       "16                 0.0                 0.0                 0.0   \n",
       "17                 0.0                 0.0                 0.0   \n",
       "18                 0.0                 0.0                 0.0   \n",
       "19                 0.0                 0.0                 0.0   \n",
       "20                 0.0                 0.0                 0.0   \n",
       "21                 0.0                 0.0                 0.0   \n",
       "22                 0.0                 0.0                 0.0   \n",
       "23                 0.0                 0.0                 0.0   \n",
       "24                 0.0                 0.0                 0.0   \n",
       "25                 0.0                 0.0                 0.0   \n",
       "26                 0.0                 0.0                 0.0   \n",
       "27                 0.0                 0.0                 0.0   \n",
       "28                 0.0                 0.0                 0.0   \n",
       "29                 0.0                 0.0                 0.0   \n",
       "30                 0.0                 0.0                 0.0   \n",
       "31                 0.0                 0.0                 0.0   \n",
       "32                 0.0                 0.0                 0.0   \n",
       "33                 0.0                 0.0                 0.0   \n",
       "34                 0.0                 0.0                 0.0   \n",
       "35                 0.0                 0.0                 0.0   \n",
       "36                 0.0                 0.0                 0.0   \n",
       "37                 0.0                 0.0                 0.0   \n",
       "38                 0.0                 0.0                 0.0   \n",
       "39                 0.0                 0.0                 0.0   \n",
       "40                 0.0                 0.0                 0.0   \n",
       "41                 0.0                 0.0                 0.0   \n",
       "42                 0.0                 0.0                 0.0   \n",
       "43                 0.0                 0.0                 0.0   \n",
       "44                 0.0                 0.0                 0.0   \n",
       "45                 0.0                 0.0                 0.0   \n",
       "46                 0.0                 0.0                 0.0   \n",
       "47                 0.0                 0.0                 0.0   \n",
       "48                 0.0                 0.0                 0.0   \n",
       "49                 0.0                 0.0                 0.0   \n",
       "\n",
       "    mean_test_recall  std_test_recall  rank_test_recall  split0_test_f1  \\\n",
       "0                0.0              0.0                 1             0.0   \n",
       "1                0.0              0.0                 1             0.0   \n",
       "2                0.0              0.0                 1             0.0   \n",
       "3                0.0              0.0                 1             0.0   \n",
       "4                0.0              0.0                 1             0.0   \n",
       "5                0.0              0.0                 1             0.0   \n",
       "6                0.0              0.0                 1             0.0   \n",
       "7                0.0              0.0                 1             0.0   \n",
       "8                0.0              0.0                 1             0.0   \n",
       "9                0.0              0.0                 1             0.0   \n",
       "10               0.0              0.0                 1             0.0   \n",
       "11               0.0              0.0                 1             0.0   \n",
       "12               0.0              0.0                 1             0.0   \n",
       "13               0.0              0.0                 1             0.0   \n",
       "14               0.0              0.0                 1             0.0   \n",
       "15               0.0              0.0                 1             0.0   \n",
       "16               0.0              0.0                 1             0.0   \n",
       "17               0.0              0.0                 1             0.0   \n",
       "18               0.0              0.0                 1             0.0   \n",
       "19               0.0              0.0                 1             0.0   \n",
       "20               0.0              0.0                 1             0.0   \n",
       "21               0.0              0.0                 1             0.0   \n",
       "22               0.0              0.0                 1             0.0   \n",
       "23               0.0              0.0                 1             0.0   \n",
       "24               0.0              0.0                 1             0.0   \n",
       "25               0.0              0.0                 1             0.0   \n",
       "26               0.0              0.0                 1             0.0   \n",
       "27               0.0              0.0                 1             0.0   \n",
       "28               0.0              0.0                 1             0.0   \n",
       "29               0.0              0.0                 1             0.0   \n",
       "30               0.0              0.0                 1             0.0   \n",
       "31               0.0              0.0                 1             0.0   \n",
       "32               0.0              0.0                 1             0.0   \n",
       "33               0.0              0.0                 1             0.0   \n",
       "34               0.0              0.0                 1             0.0   \n",
       "35               0.0              0.0                 1             0.0   \n",
       "36               0.0              0.0                 1             0.0   \n",
       "37               0.0              0.0                 1             0.0   \n",
       "38               0.0              0.0                 1             0.0   \n",
       "39               0.0              0.0                 1             0.0   \n",
       "40               0.0              0.0                 1             0.0   \n",
       "41               0.0              0.0                 1             0.0   \n",
       "42               0.0              0.0                 1             0.0   \n",
       "43               0.0              0.0                 1             0.0   \n",
       "44               0.0              0.0                 1             0.0   \n",
       "45               0.0              0.0                 1             0.0   \n",
       "46               0.0              0.0                 1             0.0   \n",
       "47               0.0              0.0                 1             0.0   \n",
       "48               0.0              0.0                 1             0.0   \n",
       "49               0.0              0.0                 1             0.0   \n",
       "\n",
       "    split1_test_f1  split2_test_f1  split3_test_f1  split4_test_f1  \\\n",
       "0              0.0             0.0             0.0             0.0   \n",
       "1              0.0             0.0             0.0             0.0   \n",
       "2              0.0             0.0             0.0             0.0   \n",
       "3              0.0             0.0             0.0             0.0   \n",
       "4              0.0             0.0             0.0             0.0   \n",
       "5              0.0             0.0             0.0             0.0   \n",
       "6              0.0             0.0             0.0             0.0   \n",
       "7              0.0             0.0             0.0             0.0   \n",
       "8              0.0             0.0             0.0             0.0   \n",
       "9              0.0             0.0             0.0             0.0   \n",
       "10             0.0             0.0             0.0             0.0   \n",
       "11             0.0             0.0             0.0             0.0   \n",
       "12             0.0             0.0             0.0             0.0   \n",
       "13             0.0             0.0             0.0             0.0   \n",
       "14             0.0             0.0             0.0             0.0   \n",
       "15             0.0             0.0             0.0             0.0   \n",
       "16             0.0             0.0             0.0             0.0   \n",
       "17             0.0             0.0             0.0             0.0   \n",
       "18             0.0             0.0             0.0             0.0   \n",
       "19             0.0             0.0             0.0             0.0   \n",
       "20             0.0             0.0             0.0             0.0   \n",
       "21             0.0             0.0             0.0             0.0   \n",
       "22             0.0             0.0             0.0             0.0   \n",
       "23             0.0             0.0             0.0             0.0   \n",
       "24             0.0             0.0             0.0             0.0   \n",
       "25             0.0             0.0             0.0             0.0   \n",
       "26             0.0             0.0             0.0             0.0   \n",
       "27             0.0             0.0             0.0             0.0   \n",
       "28             0.0             0.0             0.0             0.0   \n",
       "29             0.0             0.0             0.0             0.0   \n",
       "30             0.0             0.0             0.0             0.0   \n",
       "31             0.0             0.0             0.0             0.0   \n",
       "32             0.0             0.0             0.0             0.0   \n",
       "33             0.0             0.0             0.0             0.0   \n",
       "34             0.0             0.0             0.0             0.0   \n",
       "35             0.0             0.0             0.0             0.0   \n",
       "36             0.0             0.0             0.0             0.0   \n",
       "37             0.0             0.0             0.0             0.0   \n",
       "38             0.0             0.0             0.0             0.0   \n",
       "39             0.0             0.0             0.0             0.0   \n",
       "40             0.0             0.0             0.0             0.0   \n",
       "41             0.0             0.0             0.0             0.0   \n",
       "42             0.0             0.0             0.0             0.0   \n",
       "43             0.0             0.0             0.0             0.0   \n",
       "44             0.0             0.0             0.0             0.0   \n",
       "45             0.0             0.0             0.0             0.0   \n",
       "46             0.0             0.0             0.0             0.0   \n",
       "47             0.0             0.0             0.0             0.0   \n",
       "48             0.0             0.0             0.0             0.0   \n",
       "49             0.0             0.0             0.0             0.0   \n",
       "\n",
       "    mean_test_f1  std_test_f1  rank_test_f1  split0_test_roc_auc  \\\n",
       "0            0.0          0.0             1             0.608081   \n",
       "1            0.0          0.0             1             0.608081   \n",
       "2            0.0          0.0             1             0.608081   \n",
       "3            0.0          0.0             1             0.608081   \n",
       "4            0.0          0.0             1             0.608081   \n",
       "5            0.0          0.0             1             0.608081   \n",
       "6            0.0          0.0             1             0.608081   \n",
       "7            0.0          0.0             1             0.608081   \n",
       "8            0.0          0.0             1             0.608081   \n",
       "9            0.0          0.0             1             0.608081   \n",
       "10           0.0          0.0             1             0.608081   \n",
       "11           0.0          0.0             1             0.608081   \n",
       "12           0.0          0.0             1             0.608081   \n",
       "13           0.0          0.0             1             0.608081   \n",
       "14           0.0          0.0             1             0.608081   \n",
       "15           0.0          0.0             1             0.608081   \n",
       "16           0.0          0.0             1             0.608081   \n",
       "17           0.0          0.0             1             0.608081   \n",
       "18           0.0          0.0             1             0.608081   \n",
       "19           0.0          0.0             1             0.608081   \n",
       "20           0.0          0.0             1             0.608081   \n",
       "21           0.0          0.0             1             0.608081   \n",
       "22           0.0          0.0             1             0.608081   \n",
       "23           0.0          0.0             1             0.608081   \n",
       "24           0.0          0.0             1             0.608081   \n",
       "25           0.0          0.0             1             0.608081   \n",
       "26           0.0          0.0             1             0.608081   \n",
       "27           0.0          0.0             1             0.608081   \n",
       "28           0.0          0.0             1             0.608081   \n",
       "29           0.0          0.0             1             0.608081   \n",
       "30           0.0          0.0             1             0.608081   \n",
       "31           0.0          0.0             1             0.608081   \n",
       "32           0.0          0.0             1             0.608081   \n",
       "33           0.0          0.0             1             0.608081   \n",
       "34           0.0          0.0             1             0.608081   \n",
       "35           0.0          0.0             1             0.608081   \n",
       "36           0.0          0.0             1             0.608081   \n",
       "37           0.0          0.0             1             0.608081   \n",
       "38           0.0          0.0             1             0.608081   \n",
       "39           0.0          0.0             1             0.608081   \n",
       "40           0.0          0.0             1             0.608081   \n",
       "41           0.0          0.0             1             0.608081   \n",
       "42           0.0          0.0             1             0.608081   \n",
       "43           0.0          0.0             1             0.608081   \n",
       "44           0.0          0.0             1             0.608081   \n",
       "45           0.0          0.0             1             0.608081   \n",
       "46           0.0          0.0             1             0.608081   \n",
       "47           0.0          0.0             1             0.608081   \n",
       "48           0.0          0.0             1             0.608081   \n",
       "49           0.0          0.0             1             0.608081   \n",
       "\n",
       "    split1_test_roc_auc  split2_test_roc_auc  split3_test_roc_auc  \\\n",
       "0              0.533333             0.664062             0.464844   \n",
       "1              0.533333             0.664062             0.464844   \n",
       "2              0.533333             0.664062             0.464844   \n",
       "3              0.533333             0.664062             0.464844   \n",
       "4              0.533333             0.664062             0.464844   \n",
       "5              0.533333             0.664062             0.464844   \n",
       "6              0.533333             0.664062             0.464844   \n",
       "7              0.533333             0.664062             0.464844   \n",
       "8              0.533333             0.664062             0.464844   \n",
       "9              0.533333             0.664062             0.464844   \n",
       "10             0.533333             0.664062             0.464844   \n",
       "11             0.533333             0.664062             0.464844   \n",
       "12             0.533333             0.664062             0.464844   \n",
       "13             0.533333             0.664062             0.464844   \n",
       "14             0.533333             0.664062             0.464844   \n",
       "15             0.533333             0.664062             0.464844   \n",
       "16             0.533333             0.664062             0.464844   \n",
       "17             0.533333             0.664062             0.464844   \n",
       "18             0.533333             0.664062             0.464844   \n",
       "19             0.533333             0.664062             0.464844   \n",
       "20             0.533333             0.664062             0.464844   \n",
       "21             0.533333             0.664062             0.464844   \n",
       "22             0.533333             0.664062             0.464844   \n",
       "23             0.533333             0.664062             0.464844   \n",
       "24             0.533333             0.664062             0.464844   \n",
       "25             0.533333             0.664062             0.464844   \n",
       "26             0.533333             0.664062             0.464844   \n",
       "27             0.533333             0.664062             0.464844   \n",
       "28             0.533333             0.664062             0.464844   \n",
       "29             0.533333             0.664062             0.464844   \n",
       "30             0.533333             0.664062             0.464844   \n",
       "31             0.533333             0.664062             0.464844   \n",
       "32             0.533333             0.664062             0.464844   \n",
       "33             0.533333             0.664062             0.464844   \n",
       "34             0.533333             0.664062             0.464844   \n",
       "35             0.533333             0.664062             0.464844   \n",
       "36             0.533333             0.664062             0.464844   \n",
       "37             0.533333             0.664062             0.464844   \n",
       "38             0.533333             0.664062             0.464844   \n",
       "39             0.533333             0.664062             0.464844   \n",
       "40             0.533333             0.664062             0.464844   \n",
       "41             0.533333             0.664062             0.464844   \n",
       "42             0.533333             0.664062             0.464844   \n",
       "43             0.533333             0.664062             0.464844   \n",
       "44             0.533333             0.664062             0.464844   \n",
       "45             0.533333             0.664062             0.464844   \n",
       "46             0.533333             0.664062             0.464844   \n",
       "47             0.533333             0.664062             0.464844   \n",
       "48             0.533333             0.664062             0.464844   \n",
       "49             0.533333             0.664062             0.464844   \n",
       "\n",
       "    split4_test_roc_auc  mean_test_roc_auc  std_test_roc_auc  \\\n",
       "0              0.545833           0.563231          0.067904   \n",
       "1              0.545833           0.563231          0.067904   \n",
       "2              0.545833           0.563231          0.067904   \n",
       "3              0.545833           0.563231          0.067904   \n",
       "4              0.545833           0.563231          0.067904   \n",
       "5              0.545833           0.563231          0.067904   \n",
       "6              0.545833           0.563231          0.067904   \n",
       "7              0.545833           0.563231          0.067904   \n",
       "8              0.545833           0.563231          0.067904   \n",
       "9              0.545833           0.563231          0.067904   \n",
       "10             0.545833           0.563231          0.067904   \n",
       "11             0.545833           0.563231          0.067904   \n",
       "12             0.545833           0.563231          0.067904   \n",
       "13             0.545833           0.563231          0.067904   \n",
       "14             0.545833           0.563231          0.067904   \n",
       "15             0.545833           0.563231          0.067904   \n",
       "16             0.545833           0.563231          0.067904   \n",
       "17             0.545833           0.563231          0.067904   \n",
       "18             0.545833           0.563231          0.067904   \n",
       "19             0.545833           0.563231          0.067904   \n",
       "20             0.545833           0.563231          0.067904   \n",
       "21             0.545833           0.563231          0.067904   \n",
       "22             0.545833           0.563231          0.067904   \n",
       "23             0.545833           0.563231          0.067904   \n",
       "24             0.545833           0.563231          0.067904   \n",
       "25             0.545833           0.563231          0.067904   \n",
       "26             0.545833           0.563231          0.067904   \n",
       "27             0.545833           0.563231          0.067904   \n",
       "28             0.545833           0.563231          0.067904   \n",
       "29             0.545833           0.563231          0.067904   \n",
       "30             0.545833           0.563231          0.067904   \n",
       "31             0.545833           0.563231          0.067904   \n",
       "32             0.545833           0.563231          0.067904   \n",
       "33             0.545833           0.563231          0.067904   \n",
       "34             0.545833           0.563231          0.067904   \n",
       "35             0.545833           0.563231          0.067904   \n",
       "36             0.545833           0.563231          0.067904   \n",
       "37             0.545833           0.563231          0.067904   \n",
       "38             0.545833           0.563231          0.067904   \n",
       "39             0.545833           0.563231          0.067904   \n",
       "40             0.545833           0.563231          0.067904   \n",
       "41             0.545833           0.563231          0.067904   \n",
       "42             0.545833           0.563231          0.067904   \n",
       "43             0.545833           0.563231          0.067904   \n",
       "44             0.545833           0.563231          0.067904   \n",
       "45             0.545833           0.563231          0.067904   \n",
       "46             0.545833           0.563231          0.067904   \n",
       "47             0.545833           0.563231          0.067904   \n",
       "48             0.545833           0.563231          0.067904   \n",
       "49             0.545833           0.563231          0.067904   \n",
       "\n",
       "    rank_test_roc_auc  \n",
       "0                   1  \n",
       "1                   1  \n",
       "2                   1  \n",
       "3                   1  \n",
       "4                   1  \n",
       "5                   1  \n",
       "6                   1  \n",
       "7                   1  \n",
       "8                   1  \n",
       "9                   1  \n",
       "10                  1  \n",
       "11                  1  \n",
       "12                  1  \n",
       "13                  1  \n",
       "14                  1  \n",
       "15                  1  \n",
       "16                  1  \n",
       "17                  1  \n",
       "18                  1  \n",
       "19                  1  \n",
       "20                  1  \n",
       "21                  1  \n",
       "22                  1  \n",
       "23                  1  \n",
       "24                  1  \n",
       "25                  1  \n",
       "26                  1  \n",
       "27                  1  \n",
       "28                  1  \n",
       "29                  1  \n",
       "30                  1  \n",
       "31                  1  \n",
       "32                  1  \n",
       "33                  1  \n",
       "34                  1  \n",
       "35                  1  \n",
       "36                  1  \n",
       "37                  1  \n",
       "38                  1  \n",
       "39                  1  \n",
       "40                  1  \n",
       "41                  1  \n",
       "42                  1  \n",
       "43                  1  \n",
       "44                  1  \n",
       "45                  1  \n",
       "46                  1  \n",
       "47                  1  \n",
       "48                  1  \n",
       "49                  1  "
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train and evaluate a gaussian naive bayesian classifier with default parameters\n",
    "\n",
    "nb_params = {\n",
    "    'var_smoothing': np.logspace(1e-11, 1e-7)\n",
    "}\n",
    "nb_grid = GridSearchCV(GaussianNB(), nb_params, scoring=metrics, refit='f1')\n",
    "nb_grid.fit(trainval_features, trainval_targets)\n",
    "nb_cv_results = pd.DataFrame(nb_grid.cv_results_)\n",
    "nb_cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7a7f5075a890>"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1,1)\n",
    "ax.semilogx(1e-10, 0)\n",
    "plt.scatter(nb_cv_results['param_var_smoothing'], nb_cv_results['mean_test_f1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The two models performs exactly the same on test data, which makes us have to fall back to validation data in determining which models is the best\n",
    "* nb1 is the better of the two for validation data. (Individual metrics should be discussed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7a7f50927c90>"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the confusion matrix for the best NB\n",
    "\n",
    "ConfusionMatrixDisplay.from_estimator(nb_grid, test_features, test_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotFittedError",
     "evalue": "This GaussianNB instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotFittedError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[130], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mRocCurveDisplay\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_estimator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnb1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_targets\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.venv/sklearn/lib/python3.11/site-packages/sklearn/metrics/_plot/roc_curve.py:269\u001b[0m, in \u001b[0;36mRocCurveDisplay.from_estimator\u001b[0;34m(cls, estimator, X, y, sample_weight, drop_intermediate, response_method, pos_label, name, ax, plot_chance_level, chance_level_kw, **kwargs)\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfrom_estimator\u001b[39m(\n\u001b[1;32m    171\u001b[0m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    184\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    185\u001b[0m ):\n\u001b[1;32m    186\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Create a ROC Curve display from an estimator.\u001b[39;00m\n\u001b[1;32m    187\u001b[0m \n\u001b[1;32m    188\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    267\u001b[0m \u001b[38;5;124;03m    >>> plt.show()\u001b[39;00m\n\u001b[1;32m    268\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 269\u001b[0m     y_pred, pos_label, name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_and_get_response_values\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m        \u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresponse_method\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresponse_method\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpos_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpos_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    275\u001b[0m \u001b[43m        \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    276\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    278\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mfrom_predictions(\n\u001b[1;32m    279\u001b[0m         y_true\u001b[38;5;241m=\u001b[39my,\n\u001b[1;32m    280\u001b[0m         y_pred\u001b[38;5;241m=\u001b[39my_pred,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    288\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    289\u001b[0m     )\n",
      "File \u001b[0;32m~/.venv/sklearn/lib/python3.11/site-packages/sklearn/utils/_plotting.py:34\u001b[0m, in \u001b[0;36m_BinaryClassifierCurveDisplayMixin._validate_and_get_response_values\u001b[0;34m(cls, estimator, X, y, response_method, pos_label, name)\u001b[0m\n\u001b[1;32m     30\u001b[0m check_matplotlib_support(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.from_estimator\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     32\u001b[0m name \u001b[38;5;241m=\u001b[39m estimator\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m name\n\u001b[0;32m---> 34\u001b[0m y_pred, pos_label \u001b[38;5;241m=\u001b[39m \u001b[43m_get_response_values_binary\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresponse_method\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresponse_method\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpos_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpos_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m y_pred, pos_label, name\n",
      "File \u001b[0;32m~/.venv/sklearn/lib/python3.11/site-packages/sklearn/utils/_response.py:258\u001b[0m, in \u001b[0;36m_get_response_values_binary\u001b[0;34m(estimator, X, response_method, pos_label)\u001b[0m\n\u001b[1;32m    224\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Compute the response values of a binary classifier.\u001b[39;00m\n\u001b[1;32m    225\u001b[0m \n\u001b[1;32m    226\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    254\u001b[0m \u001b[38;5;124;03m    the metrics.\u001b[39;00m\n\u001b[1;32m    255\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    256\u001b[0m classification_error \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mestimator\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m to be a binary classifier.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 258\u001b[0m \u001b[43mcheck_is_fitted\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    259\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_classifier(estimator):\n\u001b[1;32m    260\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    261\u001b[0m         classification_error \u001b[38;5;241m+\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m Got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimator\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    262\u001b[0m     )\n",
      "File \u001b[0;32m~/.venv/sklearn/lib/python3.11/site-packages/sklearn/utils/validation.py:1461\u001b[0m, in \u001b[0;36mcheck_is_fitted\u001b[0;34m(estimator, attributes, msg, all_or_any)\u001b[0m\n\u001b[1;32m   1458\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m is not an estimator instance.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (estimator))\n\u001b[1;32m   1460\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _is_fitted(estimator, attributes, all_or_any):\n\u001b[0;32m-> 1461\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m NotFittedError(msg \u001b[38;5;241m%\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mtype\u001b[39m(estimator)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m})\n",
      "\u001b[0;31mNotFittedError\u001b[0m: This GaussianNB instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator."
     ]
    }
   ],
   "source": [
    "RocCurveDisplay.from_estimator(nb1, test_features, test_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lars/.venv/sklearn/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/lars/.venv/sklearn/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/lars/.venv/sklearn/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/lars/.venv/sklearn/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/lars/.venv/sklearn/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/lars/.venv/sklearn/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/lars/.venv/sklearn/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/lars/.venv/sklearn/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/lars/.venv/sklearn/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/lars/.venv/sklearn/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/lars/.venv/sklearn/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/lars/.venv/sklearn/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/lars/.venv/sklearn/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/lars/.venv/sklearn/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/lars/.venv/sklearn/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_C</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_accuracy</th>\n",
       "      <th>split1_test_accuracy</th>\n",
       "      <th>split2_test_accuracy</th>\n",
       "      <th>split3_test_accuracy</th>\n",
       "      <th>split4_test_accuracy</th>\n",
       "      <th>mean_test_accuracy</th>\n",
       "      <th>std_test_accuracy</th>\n",
       "      <th>rank_test_accuracy</th>\n",
       "      <th>split0_test_precision</th>\n",
       "      <th>split1_test_precision</th>\n",
       "      <th>split2_test_precision</th>\n",
       "      <th>split3_test_precision</th>\n",
       "      <th>split4_test_precision</th>\n",
       "      <th>mean_test_precision</th>\n",
       "      <th>std_test_precision</th>\n",
       "      <th>rank_test_precision</th>\n",
       "      <th>split0_test_recall</th>\n",
       "      <th>split1_test_recall</th>\n",
       "      <th>split2_test_recall</th>\n",
       "      <th>split3_test_recall</th>\n",
       "      <th>split4_test_recall</th>\n",
       "      <th>mean_test_recall</th>\n",
       "      <th>std_test_recall</th>\n",
       "      <th>rank_test_recall</th>\n",
       "      <th>split0_test_f1</th>\n",
       "      <th>split1_test_f1</th>\n",
       "      <th>split2_test_f1</th>\n",
       "      <th>split3_test_f1</th>\n",
       "      <th>split4_test_f1</th>\n",
       "      <th>mean_test_f1</th>\n",
       "      <th>std_test_f1</th>\n",
       "      <th>rank_test_f1</th>\n",
       "      <th>split0_test_roc_auc</th>\n",
       "      <th>split1_test_roc_auc</th>\n",
       "      <th>split2_test_roc_auc</th>\n",
       "      <th>split3_test_roc_auc</th>\n",
       "      <th>split4_test_roc_auc</th>\n",
       "      <th>mean_test_roc_auc</th>\n",
       "      <th>std_test_roc_auc</th>\n",
       "      <th>rank_test_roc_auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001909</td>\n",
       "      <td>0.000499</td>\n",
       "      <td>0.006020</td>\n",
       "      <td>0.000967</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'C': 0.1}</td>\n",
       "      <td>0.6875</td>\n",
       "      <td>0.6875</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.680851</td>\n",
       "      <td>0.677837</td>\n",
       "      <td>0.009438</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.606061</td>\n",
       "      <td>0.458586</td>\n",
       "      <td>0.470703</td>\n",
       "      <td>0.482422</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.496888</td>\n",
       "      <td>0.055125</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.002192</td>\n",
       "      <td>0.000209</td>\n",
       "      <td>0.007056</td>\n",
       "      <td>0.001347</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'C': 0.5}</td>\n",
       "      <td>0.6875</td>\n",
       "      <td>0.6875</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.680851</td>\n",
       "      <td>0.677837</td>\n",
       "      <td>0.009438</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.480808</td>\n",
       "      <td>0.490909</td>\n",
       "      <td>0.554688</td>\n",
       "      <td>0.513672</td>\n",
       "      <td>0.479167</td>\n",
       "      <td>0.503849</td>\n",
       "      <td>0.028244</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.002025</td>\n",
       "      <td>0.000160</td>\n",
       "      <td>0.005665</td>\n",
       "      <td>0.000373</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{'C': 1.0}</td>\n",
       "      <td>0.6875</td>\n",
       "      <td>0.6875</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.680851</td>\n",
       "      <td>0.677837</td>\n",
       "      <td>0.009438</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.505051</td>\n",
       "      <td>0.480808</td>\n",
       "      <td>0.568359</td>\n",
       "      <td>0.552734</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.504724</td>\n",
       "      <td>0.054186</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time param_C  \\\n",
       "0       0.001909      0.000499         0.006020        0.000967     0.1   \n",
       "1       0.002192      0.000209         0.007056        0.001347     0.5   \n",
       "2       0.002025      0.000160         0.005665        0.000373     1.0   \n",
       "\n",
       "       params  split0_test_accuracy  split1_test_accuracy  \\\n",
       "0  {'C': 0.1}                0.6875                0.6875   \n",
       "1  {'C': 0.5}                0.6875                0.6875   \n",
       "2  {'C': 1.0}                0.6875                0.6875   \n",
       "\n",
       "   split2_test_accuracy  split3_test_accuracy  split4_test_accuracy  \\\n",
       "0              0.666667              0.666667              0.680851   \n",
       "1              0.666667              0.666667              0.680851   \n",
       "2              0.666667              0.666667              0.680851   \n",
       "\n",
       "   mean_test_accuracy  std_test_accuracy  rank_test_accuracy  \\\n",
       "0            0.677837           0.009438                   1   \n",
       "1            0.677837           0.009438                   1   \n",
       "2            0.677837           0.009438                   1   \n",
       "\n",
       "   split0_test_precision  split1_test_precision  split2_test_precision  \\\n",
       "0                    0.0                    0.0                    0.0   \n",
       "1                    0.0                    0.0                    0.0   \n",
       "2                    0.0                    0.0                    0.0   \n",
       "\n",
       "   split3_test_precision  split4_test_precision  mean_test_precision  \\\n",
       "0                    0.0                    0.0                  0.0   \n",
       "1                    0.0                    0.0                  0.0   \n",
       "2                    0.0                    0.0                  0.0   \n",
       "\n",
       "   std_test_precision  rank_test_precision  split0_test_recall  \\\n",
       "0                 0.0                    1                 0.0   \n",
       "1                 0.0                    1                 0.0   \n",
       "2                 0.0                    1                 0.0   \n",
       "\n",
       "   split1_test_recall  split2_test_recall  split3_test_recall  \\\n",
       "0                 0.0                 0.0                 0.0   \n",
       "1                 0.0                 0.0                 0.0   \n",
       "2                 0.0                 0.0                 0.0   \n",
       "\n",
       "   split4_test_recall  mean_test_recall  std_test_recall  rank_test_recall  \\\n",
       "0                 0.0               0.0              0.0                 1   \n",
       "1                 0.0               0.0              0.0                 1   \n",
       "2                 0.0               0.0              0.0                 1   \n",
       "\n",
       "   split0_test_f1  split1_test_f1  split2_test_f1  split3_test_f1  \\\n",
       "0             0.0             0.0             0.0             0.0   \n",
       "1             0.0             0.0             0.0             0.0   \n",
       "2             0.0             0.0             0.0             0.0   \n",
       "\n",
       "   split4_test_f1  mean_test_f1  std_test_f1  rank_test_f1  \\\n",
       "0             0.0           0.0          0.0             1   \n",
       "1             0.0           0.0          0.0             1   \n",
       "2             0.0           0.0          0.0             1   \n",
       "\n",
       "   split0_test_roc_auc  split1_test_roc_auc  split2_test_roc_auc  \\\n",
       "0             0.606061             0.458586             0.470703   \n",
       "1             0.480808             0.490909             0.554688   \n",
       "2             0.505051             0.480808             0.568359   \n",
       "\n",
       "   split3_test_roc_auc  split4_test_roc_auc  mean_test_roc_auc  \\\n",
       "0             0.482422             0.466667           0.496888   \n",
       "1             0.513672             0.479167           0.503849   \n",
       "2             0.552734             0.416667           0.504724   \n",
       "\n",
       "   std_test_roc_auc  rank_test_roc_auc  \n",
       "0          0.055125                  3  \n",
       "1          0.028244                  2  \n",
       "2          0.054186                  1  "
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc_params = {\n",
    "    'C': [0.1, 0.5, 1.0]\n",
    "}\n",
    "svc_grid = GridSearchCV(SVC(), svc_params, scoring=metrics, refit='f1')\n",
    "svc_grid.fit(trainval_features, trainval_targets)\n",
    "svc_cv_results = pd.DataFrame(svc_grid.cv_results_)\n",
    "svc_cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_features' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[133], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Here you should add a collected presentation of all the results to make it easy to make the final \u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# conclusion. I've kept it simple here by only showing the evaluation for the best classifiers of \u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# both type\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdt_grid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfinal_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m evaluate(nb_grid, final_eval\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      7\u001b[0m evaluate(svc_grid, final_eval\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "Cell \u001b[0;32mIn[120], line 8\u001b[0m, in \u001b[0;36mevaluate\u001b[0;34m(model, final_eval)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mevaluate\u001b[39m(model, final_eval\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m      4\u001b[0m \n\u001b[1;32m      5\u001b[0m     \u001b[38;5;66;03m# Store the prediction probabilites and the predictions. We need the probabilities for \u001b[39;00m\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;66;03m# roc_auc_score metric\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m     train_probabilities \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict_proba(\u001b[43mtrain_features\u001b[49m)\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;66;03m# train_predictions = model.predict(train_features)\u001b[39;00m\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;66;03m# This does the same as the statement above without having the model predict again\u001b[39;00m\n\u001b[1;32m     11\u001b[0m     train_predictions \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mclasses_\u001b[38;5;241m.\u001b[39mtake(np\u001b[38;5;241m.\u001b[39margmax(train_probabilities, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_features' is not defined"
     ]
    }
   ],
   "source": [
    "# Here you should add a collected presentation of all the results to make it easy to make the final \n",
    "# conclusion. I've kept it simple here by only showing the evaluation for the best classifiers of \n",
    "# both type\n",
    "\n",
    "evaluate(dt_grid, final_eval=True)\n",
    "evaluate(nb_grid, final_eval=True)\n",
    "evaluate(svc_grid, final_eval=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the metrics shown above we have to conclude that that dt2 is the best classifier for predicting heart failures. Both the confusion matrices and the ROC plots confirm the results. Both classifiers have a significant amount of false negatives, which makes both models complicate to implement in healthcare practice. \n",
    "\n",
    "The results are highly dependent on the random sampling in the data partitions. A more thorough analysis is needed to overcome this issue."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sklearn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
